{"0": {
    "doc": "Introduction to Pragmatic Formal Modeling",
    "title": "Introduction to Pragmatic Formal Modeling",
    "content": ". | Introduction | The modeling and model testing language | I want to run the examples without looking at the learning material! | What does modeling get us? (A Simple Example) . | The Model | Checking the Model | Playing not to lose | Playing to win | . | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/",
    "relUrl": "/"
  },"1": {
    "doc": "Introduction to Pragmatic Formal Modeling",
    "title": "Introduction",
    "content": "A formal model is a mathematical description of a system, generally to be implemented in hardware or software. They are useful for two reasons. Firstly, mathematics, unlike English, is precise and unambiguous. Even if this is where you stop, it forces you to understand the system you are describing. Secondly, mathematically based models can be checked. You can describe success criteria, and if they are violated you can see the exact series of steps that led to that. This is particularly useful for distributed systems, from multiple threads on a computer to thousands of computers in a cloud service. When you think about formal modeling, it’s easy (and intimidating) to jump straight to the most complex use cases. Sure, those algorithm geniuses who design the fundamental algorithms of distributed systems might need it, but what about me? I care about the quality of my work. But I work in industry. Maybe I work in the cloud, coordinating microservices. Maybe I’m a game developer writing the next multiplayer networking library. Maybe I’m building a peer to peer file storage solution. Regardless, the question remains: . How can I model the system I’m building in a way that’s useful, practical, and has good ROI for myself and my company? . For every example on this site, we’re going to try to take a pragmatic approach that mirrors the engineering design lifecycle. We’ll start with UML diagrams and relatively precise descriptions, and then convert them into a formal specification language. Then we’ll see how we can check for design errors, and get concrete examples as to how they occur. Finally we will show how to use the detailed model errors to progressively refine your designs. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/#introduction",
    "relUrl": "/#introduction"
  },"2": {
    "doc": "Introduction to Pragmatic Formal Modeling",
    "title": "The modeling and model testing language",
    "content": "TLA+ is a specification language developed by Leslie Lamport, one of the computer science greats. It has a model checker: TLC, which works in a brute force manner to check every possible state of your modelled system. TLA+ is used in industry. AWS is one of its most enthusiastic users, along with Microsoft and Intel. While it looks very math-y, it is surprisingly accessible and practical. TLA+ was designed as a tool for engineers, not just algorithmists. But current examples tend to fall into one of two categories: toy problems, or complex algorithms. One of my goals with this site is to present examples that show how it can be used in an engineering process for “normal” engineers. My advice is to skim the examples and see if they resonate. Could this help you in your day-to-day? Does it pique your interest? If so, go through the learning material and revisit this post. However if you are mathematically inclined and obsessed with complex distributed system algorithms already, I’d advise you just jump straight to the TLA+ Video Series: Leslie Lamport will be able to sell you better than I can. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/#the-modeling-and-model-testing-language",
    "relUrl": "/#the-modeling-and-model-testing-language"
  },"3": {
    "doc": "Introduction to Pragmatic Formal Modeling",
    "title": "I want to run the examples without looking at the learning material!",
    "content": "Ok, here’s how: First download VSCode TLA+ . For each example you want to run: . | Click Download Code. The file will look like “modelfoo.tla” | Scroll down (or hit Next Section), where you will see a Download Configuration link. Click it. The file will look like “modelfoo.cfg” | Place both files in the same folder. Make sure they have the same name (other than the extension). If necessary rename “modelfoo_small.cfg” to “modelfoo.cfg” | Open the folder in VSCode and open the TLA file | Right click inside the editor and click Check Model with TLC | An output window will open and you will get a result. Or you will get an error, probably because you didn’t rename the .cfg file | . For any example that relies on additional model files, simply download them and place them in the same folder before clicking Check Model with TLC. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/#i-want-to-run-the-examples-without-looking-at-the-learning-material",
    "relUrl": "/#i-want-to-run-the-examples-without-looking-at-the-learning-material"
  },"4": {
    "doc": "Introduction to Pragmatic Formal Modeling",
    "title": "What does modeling get us? (A Simple Example)",
    "content": "We will start with a toy problem, Tic-Tac-Toe, just to demonstrate some of the core benefits of modeling and model checking. This is the only toy problem, so feel free to skip ahead to the practical part. If you want to get a bit more of an intuitive understanding, keep reading. The Model . I advise that you look at the code both in LaTex and code form. The LaTex is generated directly from the code and can let you appreciate the math a bit better. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ---------------------------- MODULE tictactoe ---------------------------- EXTENDS Naturals VARIABLES board, \\* board[1..3][1..3] A 3x3 tic-tac-toe board nextTurn \\* who goes next Pieces == {\"X\", \"O\", \"_\"} \\* \"_\" represents a blank square Init == /\\ nextTurn = \"X\" \\* X always goes first \\* Every space in the board states blank /\\ board = [i \\in 1..3 |-&gt; [j \\in 1..3 |-&gt; \"_\"]] Move(player) == \\E i \\in 1..3: \\E j \\in 1..3: \\* There exists a position on the board /\\ board[i][j] = \"_\" \\* Where the board is currently empty (********************************************************************) (* The future state of board is the same, except a piece is in that *) (* spot *) (********************************************************************) /\\ board' = [board EXCEPT ![i][j] = player] MoveX == /\\ nextTurn = \"X\" \\* Only enabled on X's turn /\\ Move(\"X\") /\\ nextTurn' = \"O\" \\* The future state of next turn is O MoveO == /\\ nextTurn = \"O\" \\* Only enabled on O's turn /\\ Move(\"O\") /\\ nextTurn' = \"X\" \\* The future state of next turn is X \\* Every state, X will move if X's turn, O will move on O's turn Next == MoveX \\/ MoveO \\* A description of every possible game of tic-tac-toe \\* will play until the board fills up, even if someone won Spec == Init /\\ [][Next]_&lt;&lt;board,nextTurn&gt;&gt; (***************************************************************************) (* Invariants: The things we are checking for. *) (***************************************************************************) WinningPositions == { \\* Horizonal wins {&lt;&lt;1,1&gt;&gt;, &lt;&lt;1,2&gt;&gt;, &lt;&lt;1,3&gt;&gt;}, {&lt;&lt;2,1&gt;&gt;, &lt;&lt;2,2&gt;&gt;, &lt;&lt;2,3&gt;&gt;}, {&lt;&lt;3,1&gt;&gt;, &lt;&lt;3,2&gt;&gt;, &lt;&lt;3,3&gt;&gt;}, \\* Vertical wins {&lt;&lt;1,1&gt;&gt;, &lt;&lt;2,1&gt;&gt;, &lt;&lt;3,1&gt;&gt;}, {&lt;&lt;1,2&gt;&gt;, &lt;&lt;2,2&gt;&gt;, &lt;&lt;3,2&gt;&gt;}, {&lt;&lt;1,3&gt;&gt;, &lt;&lt;2,3&gt;&gt;, &lt;&lt;3,3&gt;&gt;}, \\* Diagonal wins {&lt;&lt;1,1&gt;&gt;, &lt;&lt;2,2&gt;&gt;, &lt;&lt;3,3&gt;&gt;}, {&lt;&lt;3,1&gt;&gt;, &lt;&lt;2,2&gt;&gt;, &lt;&lt;1,3&gt;&gt;} } Won(player) == \\* A player has won if there exists a winning position \\E winningPosition \\in WinningPositions: \\* Where all the needed spaces \\A neededSpace \\in winningPosition: \\* are occupied by one player board[neededSpace[1]][neededSpace[2]] = player XHasNotWon == ~Won(\"X\") OHasNotWon == ~Won(\"O\") BoardFilled == \\* There does not exist ~\\E i \\in 1..3, j \\in 1..3: \\* an empty space LET space == board[i][j] IN space = \"_\" \\* It's not a stalemate if one player has won or the board is not filled NotStalemate == \\/ Won(\"X\") \\/ Won(\"O\") \\/ ~BoardFilled ============================================================================= . Essentially, this model describes every game of Tic-Tac-Toe that could be played, including games where someone has already won, but the board isn’t full. The model checker actually shows us how many possible board/move combinations exist: . | Next Section | Download Configuration | . | State Name | Total States | Distinct States | . | Init | 1 | 1 | . | MoveX | 9963 | 2907 | . | MoveO | 9144 | 3138 | . It ends when there are no more spaces left to fill. None of the Next actions are activated, so the system “deadlocks.” Sometimes this behavior is an error, but for us it’s a feature. You can configure how to treat it. Checking the Model . All right, that’s kind of cool, but so what? Say that it would be really bad if O were to win. We can check a model against the OHasNotWon invariant to make sure it’s impossible for O to win. Let’s run that now. | Next Section | Download Configuration | . Oh no, it is possible for O to win. Invariant OHasNotWon is violated. | 1. Initial predicate . | board . | : ___ | : ___ | : ___ | . | nextTurn . | : X | . | . | 2. MoveX . | board . | : X__ | : ___ | : ___ | . | nextTurn . | : O | . | . | 3. MoveO . | board . | : XO_ | : ___ | : ___ | . | nextTurn . | : X | . | . | 4. MoveX . | board . | : XOX | : ___ | : ___ | . | nextTurn . | : O | . | . | 5. MoveO . | board . | : XOX | : _O_ | : ___ | . | nextTurn . | : X | . | . | 6. MoveX . | board . | : XOX | : XO_ | : ___ | . | nextTurn . | : O | . | . | 7. MoveO . | board . | : XOX | : XO_ | : _O_ | . | nextTurn . | : X | . | . | . Now the interesting thing is not that O can win Tic-Tac-Toe. We probably knew that. But the model checker uses Breadth-First-Search, so not only is this a possible O victory, there are no faster victories. What’s also interesting is how clearly it is presented. The data above is EXACTLY what comes out of the model checker, prettied up with generic css and a bit of annotation. Look how much clearer it is than a standard code debugger. Because we’re not debugging code, we’re debugging logic. Let’s see what happens when X wins. | Next Section | Download Configuration | . X can also win. Invariant XHasNotWon is violated. | 1. Initial predicate . | board . | : ___ | : ___ | : ___ | . | nextTurn . | : X | . | . | 2. MoveX . | board . | : X__ | : ___ | : ___ | . | nextTurn . | : O | . | . | 3. MoveO . | board . | : XO_ | : ___ | : ___ | . | nextTurn . | : X | . | . | 4. MoveX . | board . | : XO_ | : X__ | : ___ | . | nextTurn . | : O | . | . | 5. MoveO . | board . | : XOO | : X__ | : ___ | . | nextTurn . | : X | . | . | 6. MoveX X can win in 5 moves, because X goes first . | board . | : XOO | : X__ | : X__ | . | nextTurn . | : O | . | . | . Finally, let’s look at a stalemate. In those past wins, it looked like the other player wasn’t trying very hard. That’s because we saw the fastest possible wins. Let’s see a potential stalemate: . | Next Section | Download Configuration | . Stalemate is also a thing that can happen in Tic-Tac-Toe. Invariant NotStalemate is violated. | 1. Initial predicate . | board . | : ___ | : ___ | : ___ | . | nextTurn . | : X | . | . | 2. MoveX . | board . | : X__ | : ___ | : ___ | . | nextTurn . | : O | . | . | 3. MoveO . | board . | : XO_ | : ___ | : ___ | . | nextTurn . | : X | . | . | 4. MoveX . | board . | : XOX | : ___ | : ___ | . | nextTurn . | : O | . | . | 5. MoveO . | board . | : XOX | : O__ | : ___ | . | nextTurn . | : X | . | . | 6. MoveX . | board . | : XOX | : OX_ | : ___ | . | nextTurn . | : O | . | . | 7. MoveO . | board . | : XOX | : OX_ | : O__ | . | nextTurn . | : X | . | . | 8. MoveX . | board . | : XOX | : OXX | X is about to win : O__ | . | nextTurn . | : O | . | . | 9. MoveO . | board . | : XOX | : OXX | O must block : O_O | . | nextTurn . | : X | . | . | 10. MoveX So that a stalemate occurs . | board . | : XOX | : OXX | : OXO | . | nextTurn . | : O | . | . | . So O blocked an X win here, but there is no intelligence yet. There is another world where O didn’t block X, and it was an X win. This is just one of the possible stalemates. So in our current system it will be possible for O to win. What can we do to fix that? . Playing not to lose . Let’s imagine it is really important that O never win. If they do, the casino you work for loses millions of dollars (why they introduced high-stakes Tic-Tac-Toe is above our pay grade). O will still play every possible game available to it. But the casino is X, meaning we can change its strategy. How do we do that? We put stricter limits on what is considered an allowable move for X: . | The previous version of MoveX let X be put into any unfilled space. | In this updated version, a programmer read the WikiHow on “How to Play Tic-Tac-Toe” and made a best attempt at a strategy. | . We need to prove the O will not win if this strategy is used. We do this by encoding it to TLA+ and running the same check (to see the full implementation, click Download Code or Download PDF): . | Next Section | Download Code | Download PDF | . Show Code Show LaTex ---------------------------- MODULE tictactoexstrat ---------------------------- MoveX == /\\ nextTurn = \"X\" \\* Only enabled on X's turn /\\ ~Won(\"O\") \\* And X has not won \\* This specifies the spots X will move on X's turn /\\ \\/ /\\ BoardEmpty /\\ StartInCorner \\/ /\\ ~BoardEmpty \\* If it's not the start /\\ \\/ /\\ CanWin /\\ Win \\/ /\\ ~CanWin /\\ \\/ /\\ CanBlockWin /\\ BlockWin \\/ /\\ ~CanBlockWin /\\ \\/ /\\ CanTakeCenter /\\ TakeCenter \\/ /\\ ~CanTakeCenter /\\ \\/ /\\ CanSetupWin /\\ SetupWin \\/ /\\ ~CanSetupWin /\\ MoveToEmpty(\"X\") \\* No more strategies. Pick spot /\\ nextTurn' = \"O\" \\* The future state of next turn is O ============================================================================= . Let’s see what happens when we set it up with invariant OHasNotWon: . | Next Section | Download Configuration | . | State Name | Total States | Distinct States | . | Init | 1 | 1 | . | MoveX | 800 | 382 | . | MoveO | 648 | 488 | . We didn’t get an error trace! Normally that’s a cause for suspicion; did we mess up the test? But by building incrementally we can have more confidence: we’ve seen this test fail. So we did it! O wil never win. So what exactly does that mean? . The strategy isn’t optimal (i.e. wins in the smallest number of moves) or deterministic. For any given turn it may allow multiple moves. The TLC model checker tested all of those moves and ensured that O would never win, no matter which of those moves we pick. This is true no matter what O does. We will call all moves allowed by the strategy Strategy Moves. If we wanted to maximize winning, we could run a machine learning algorithm that tries to predict which move would lead to victory. It doesn’t even need to be completely logical, it could try to psych out its opponent, or realize that people wearing red shirts are more likely to move left. As long as it only picks moves that are Strategy Moves we will never lose. Combining Proven Safety With AI in Tic-Tac-Toe | | Legal Space Legal Space Legal Space Legal Space Not Legal Space Not Legal Space Legal Space Legal Space Legal Space | O X | Strategy Space Strategy Space AI Chosen Space All Moves All Moves Legal Moves Legal Moves Strategy Moves Strategy Moves AI Chosen Move: AI Chosen Space AI Chosen Space AI Chosen Space AI Chosen Space This is a silly example. But combining machine learning with logical safeguards designed and tested with TLA+ has a lot of potential. TLA+ is logical modeling; it can’t give you statistical optimization or tell you how many 9s of reliability you will get. But it can let you update algorithms confidently, knowing that critical parameters will be met. Playing to win . “So you stopped us from losing,” says your boss, “but that was yesterday, and anyway, we’re a company of winners.” “Right on it boss,” you respond, because you know what to do next. To prove that our system is going to win, we have to first describe winning. Let’s start with what we already know. Won(\"X\") is true when X has Won []Won(\"X\") means always Won(\"X\"). But at the start of the game you haven’t won. This would fail. We need a new operator. &lt;&gt;Won(\"X\") means Won(\"X\") must EVENTUALLY be true . This is what’s called a Temporal Property, a property that is measured across steps, and we can test for it. X eventually winning sounds exactly like what we want. If a little thing called “Eventual Consistency” is important to you, don’t worry, you’ll see this again! . So let’s test our code. We get an error, but it’s unlike any we’ve seen before. What is a Stuttering Step? Well, so far we’ve been thinking about this one state after another. But another valid thing that can happen is nothing. And nothing can happen forever. There’s a world where one of the participants just walks away from the game board, which means X will never win. How cool is it that our modeling tool can point that out to us? . But don’t worry, our casino won’t allow that to happen. If a player can take a move, they will eventually take a move. We say that formally with the concept of Fairness. Weak Fairness (represented as WF) roughly means that if a move can be made, and that fact doesn’t change, the move will eventually be made. We define it below. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ---------------------------- MODULE tictactoexwin ---------------------------- XMustEventuallyWin == &lt;&gt;Won(\"X\") Spec == Init /\\ [][Next]_vars /\\ WF_vars(Next) ============================================================================= . Note: Fairness isn’t something we are checking for, it’s a property of how the system works. Great, let’s run it again. | Next Section | Download Configuration | . We run into a stalemate. Which means that X won’t always eventually win. | 1. Initial predicate . | board . | : ___ | : ___ | : ___ | . | nextTurn . | : X | . | . | 2. MoveX . | board . | : X__ | : ___ | : ___ | . | nextTurn . | : O | . | . | 3. MoveO . | board . | : XO_ | : ___ | : ___ | . | nextTurn . | : X | . | . | 4. MoveX . | board . | : XO_ | : _X_ | : ___ | . | nextTurn . | : O | . | . | 5. MoveO Click here to see X in a interesting position . | board . | : XO_ | : _X_ | : __O | . | nextTurn . | : X | . | . | 6. MoveX then click here to see X set up the win . | board . | : XO_ | : _XX | : __O | . | nextTurn . | : O | . | . | 7. MoveO which is sadly foiled . | board . | : XO_ | : OXX | : __O | . | nextTurn . | : X | . | . | 8. MoveX . | board . | : XOX | : OXX | : __O | . | nextTurn . | : O | . | . | 9. MoveO . | board . | : XOX | : OXX | : O_O | . | nextTurn . | : X | . | . | 10. MoveX While a stalemate still occurs, look how much harder X fought . | board . | : XOX | : OXX | : OXO | . | nextTurn . | : O | . | . | . So we didn’t succeed. X does not always eventually win. The house may not always win, but it never loses. We can live with that. But if you figured out an algorithm to make X always win, this is a way to prove it. Tic-Tac-Toe is a solved problem, and there is no such algorithm, but don’t let that limit you. | Next: Coordinating a Database and Blob Store | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/#what-does-modeling-get-us-a-simple-example",
    "relUrl": "/#what-does-modeling-get-us-a-simple-example"
  },"5": {
    "doc": "(Implementing New Requirements) Significant improvement",
    "title": "(Implementing New Requirements) Significant improvement",
    "content": ". | Refining the design . | Storage Cleaner Run | Assumptions | . | Modeling the design | Verifying Storage Cleaner | A quick fix | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/storage-cleaner-improved/",
    "relUrl": "/database-blob/storage-cleaner-improved/"
  },"6": {
    "doc": "(Implementing New Requirements) Significant improvement",
    "title": "Refining the design",
    "content": "How do we prevent the cleaner from deleting items just as they are being written? Well, the common sense solution is to check the creation time. We should only start cleaning a key after a safe window of time has passed since its creation. Let’s call it 2 hours. Storage Cleaner Run . | | Storage CleanerStorage CleanerDatabaseDatabaseBlob StoreBlob Store | Gets batch of keys that have been created more than or exactly 2 hours ago | Returns batch of keys | Queries for unused keys | Returns unused keys | Batch deletes unused keys | Returns statusalt[any failure] | | Repeats from beginning Assumptions . We are making one main assumption: that all of our clocks are accurate within a reasonable margin of error (5 minutes is generous), and our code errs on the side of not deleting based on those margins. While you can’t always make assumptions about clock time in distributed systems, in this case our time frames are so large (hours) that it’s probably not a bad assumption. Note: this doesn’t mean a program will necessarily check its clock. It could stall and then resume what it’s doing an hour later. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/storage-cleaner-improved/#refining-the-design",
    "relUrl": "/database-blob/storage-cleaner-improved/#refining-the-design"
  },"7": {
    "doc": "(Implementing New Requirements) Significant improvement",
    "title": "Modeling the design",
    "content": "Now we have to introduce a concept of time in the model. You might think we’ve been using time throughout this whole tutorial, but actually, we were just using ordering. We will need to add the concept of creation time to the blob store. Keep in mind that the state diagram has not changed. Note: This isn’t adding functionality. We’re just modeling details that have become relevant. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ---------------------------- MODULE storagecleanerimproved ---------------------------- EXTENDS Naturals, Sequences, FiniteSets CONSTANTS USERIDS, SERVERS, METADATAS, IMAGES, UUIDS, CLEANERS VARIABLES (***********************************************************************) (* Implementation variables *) (***********************************************************************) databaseState, blobStoreState, serverStates, cleanerStates, \\* We just added a time variable here time, \\* Natural number representing the number of hours that have passed (***********************************************************************) (* Observability variables *) (***********************************************************************) operations vars == &lt;&lt;databaseState, blobStoreState, serverStates, operations, cleanerStates, time&gt;&gt; cleanerVars == &lt;&lt;cleanerStates&gt;&gt; (***************************************************************************) (* Strong Typing *) (***************************************************************************) UserIdVal == USERIDS \\union {\"UNSET\"} MetadataVal == METADATAS \\union {\"UNSET\"} ImageVal == IMAGES \\union {\"UNSET\"} UUIDVal == UUIDS \\union {\"UNSET\"} DatabaseRecord == [ metadata: MetadataVal, imageId: UUIDVal ] \\* A blob store record is modeled to store creation time BlobStoreRecord == [ image: ImageVal, created: Nat ] \\union {[ status |-&gt; \"UNSET\", image |-&gt; \"UNSET\" ]} \\* It can still be unset ServerStateVal == [ state: { \"waiting\", \"started_write\", \"wrote_blob\", \"started_read\", \"read_metadata\" }, userId: UserIdVal, metadata: MetadataVal, imageId: UUIDVal, image: ImageVal ] CleanerStateVal == [ state: { \"waiting\", \"got_blob_keys\", \"got_unused_keys\", \"deleting_keys\" }, blobKeys: SUBSET UUIDS, unusedBlobKeys: SUBSET UUIDS ] OperationValue == [type: {\"READ\", \"WRITE\"}, userId: UserIdVal, metadata: MetadataVal, image:ImageVal] TypeOk == /\\ databaseState \\in [USERIDS -&gt; DatabaseRecord] \\* Blob store is updated to store records. Can be a record or unset /\\ blobStoreState \\in [UUIDS -&gt; BlobStoreRecord] /\\ serverStates \\in [SERVERS -&gt; ServerStateVal] /\\ cleanerStates \\in [CLEANERS -&gt; CleanerStateVal] /\\ operations \\in Seq(OperationValue) /\\ time \\in Nat \\* Time is represented as a natural number Init == /\\ databaseState = [u \\in USERIDS |-&gt; [metadata |-&gt; \"UNSET\", imageId |-&gt; \"UNSET\"]] /\\ blobStoreState = [u \\in UUIDS |-&gt; [status |-&gt; \"UNSET\", image |-&gt; \"UNSET\"]] /\\ serverStates = [s \\in SERVERS |-&gt; [state |-&gt; \"waiting\", userId |-&gt; \"UNSET\", metadata |-&gt; \"UNSET\", imageId |-&gt; \"UNSET\", image |-&gt; \"UNSET\" ]] /\\ cleanerStates = [c \\in CLEANERS |-&gt; [ state |-&gt; \"waiting\", blobKeys |-&gt; {}, unusedBlobKeys |-&gt; {} ]] /\\ operations = &lt;&lt;&gt;&gt; /\\ time = 0 \\* Time starts at 0 (***************************************************************************) (* State Machine *) (***************************************************************************) TimePasses == /\\ time' = time + 1 /\\ UNCHANGED &lt;&lt;serverStates, databaseState, blobStoreState, operations, cleanerStates&gt;&gt; (***************************************************************************) (* Server Writes *) (***************************************************************************) ServerStartWrite(s) == /\\ serverStates[s].state = \"waiting\" /\\ \\E u \\in USERIDS, m \\in METADATAS, i \\in IMAGES: /\\ serverStates' = [serverStates EXCEPT ![s].state =\"started_write\", ![s].userId = u, ![s].metadata = m, ![s].image = i] /\\ operations' = Append(operations, [ type |-&gt; \"WRITE\", userId |-&gt; u, metadata |-&gt; m, image |-&gt; i ]) /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState, cleanerStates&gt;&gt; /\\ UNCHANGED time ServerWriteBlob(s) == LET currentState == serverStates[s] IN /\\ currentState.state = \"started_write\" /\\ \\E id \\in UUIDS: /\\ blobStoreState[id] = [status |-&gt; \"UNSET\", image |-&gt; \"UNSET\"] /\\ blobStoreState' = [blobStoreState EXCEPT ![id] = [ image |-&gt; currentState.image, created |-&gt; time ]] /\\ serverStates' = [serverStates EXCEPT ![s].state =\"wrote_blob\", ![s].imageId = id] /\\ UNCHANGED &lt;&lt;databaseState, operations&gt;&gt; /\\ UNCHANGED cleanerVars /\\ UNCHANGED time ServerWriteMetadataAndReturn(s) == LET currentState == serverStates[s] IN /\\ currentState.state = \"wrote_blob\" /\\ databaseState' = [databaseState EXCEPT ![currentState.userId] = [ metadata |-&gt; currentState.metadata, imageId |-&gt; currentState.imageId] ] /\\ serverStates' = [serverStates EXCEPT ![s].state =\"waiting\", ![s].userId =\"UNSET\", ![s].metadata = \"UNSET\", ![s].image = \"UNSET\", ![s].imageId = \"UNSET\"] /\\ UNCHANGED &lt;&lt;blobStoreState, operations&gt;&gt; /\\ UNCHANGED cleanerVars /\\ UNCHANGED time ServerFailWrite(s) == /\\ serverStates[s].state \\in {\"started_write\", \"wrote_blob\"} /\\ serverStates' = [serverStates EXCEPT ![s].state =\"waiting\", ![s].userId =\"UNSET\", ![s].metadata = \"UNSET\", ![s].image = \"UNSET\", ![s].imageId = \"UNSET\"] /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState, operations&gt;&gt; /\\ UNCHANGED cleanerVars /\\ UNCHANGED time (***************************************************************************) (* Server Reads *) (***************************************************************************) ServerStartRead(s) == /\\ serverStates[s].state = \"waiting\" /\\ \\E u \\in USERIDS: serverStates' = [serverStates EXCEPT ![s].state =\"started_read\", ![s].userId =u] /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; /\\ UNCHANGED operations /\\ UNCHANGED cleanerVars /\\ UNCHANGED time ServerReadMetadata(s) == LET currentState == serverStates[s] IN /\\ currentState.state = \"started_read\" /\\ databaseState[currentState.userId].metadata # \"UNSET\" /\\ serverStates' = [serverStates EXCEPT ![s].state =\"read_metadata\", ![s].metadata = databaseState[currentState.userId].metadata, ![s].imageId = databaseState[currentState.userId].imageId] /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; /\\ UNCHANGED operations /\\ UNCHANGED cleanerVars /\\ UNCHANGED time ServerReadMetadataAndReturnEmpty(s) == LET currentState == serverStates[s] IN /\\ currentState.state = \"started_read\" /\\ databaseState[currentState.userId].metadata = \"UNSET\" /\\ serverStates' = [serverStates EXCEPT ![s].state =\"waiting\", ![s].userId =\"UNSET\", ![s].metadata = \"UNSET\", ![s].image = \"UNSET\", ![s].imageId = \"UNSET\"] /\\ operations' = Append(operations, (***********************************************) (* Returns an empty record *) (***********************************************) [ type |-&gt; \"READ\", userId |-&gt; currentState.userId, metadata |-&gt; \"UNSET\", image |-&gt; \"UNSET\" ]) /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; /\\ UNCHANGED cleanerVars /\\ UNCHANGED time ServerReadBlobAndReturn(s) == LET currentState == serverStates[s] IN /\\ currentState.state = \"read_metadata\" /\\ operations' = Append(operations, [ type |-&gt; \"READ\", userId |-&gt; currentState.userId, metadata |-&gt; currentState.metadata, \\* Looks up image by imageId image |-&gt; blobStoreState[currentState.imageId].image ]) /\\ serverStates' = [serverStates EXCEPT ![s].state =\"waiting\", ![s].userId =\"UNSET\", ![s].metadata = \"UNSET\", ![s].image = \"UNSET\", ![s].imageId = \"UNSET\"] /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; /\\ UNCHANGED cleanerVars /\\ UNCHANGED time (***************************************************************************) (* Cleaner States *) (***************************************************************************) (***************************************************************************) (* This is the main change in the logic. *) (***************************************************************************) CleanerStartGetBlobKeys(c) == LET current == cleanerStates[c] IN /\\ current.state = \"waiting\" /\\ cleanerStates' = [ cleanerStates EXCEPT ![c].state = \"got_blob_keys\", \\* All keys in blockstore ![c].blobKeys = { k \\in UUIDS: LET earliestDeletionTime == blobStoreState[k].created + 2 IN \\* That are not unset /\\ blobStoreState[k] # [ status |-&gt; \"UNSET\", image |-&gt; \"UNSET\"] \\* It must have been created 2 or more hours ago /\\ earliestDeletionTime =&lt; time } ] /\\ UNCHANGED &lt;&lt;serverStates, databaseState, blobStoreState, operations&gt;&gt; /\\ UNCHANGED time CleanerGetUnusedKeys(c) == LET current == cleanerStates[c] IN /\\ current.state = \"got_blob_keys\" /\\ cleanerStates' = [ cleanerStates EXCEPT ![c].state = \"got_unused_keys\", ![c].unusedBlobKeys = {k \\in current.blobKeys: \\A u \\in USERIDS: databaseState[u].imageId # k} ] /\\ UNCHANGED &lt;&lt;serverStates, databaseState, blobStoreState, operations&gt;&gt; /\\ UNCHANGED time CleanerDeletingKeys(c) == LET current == cleanerStates[c] IN /\\ current.state \\in {\"got_unused_keys\", \"deleting_keys\"} /\\ Cardinality(current.unusedBlobKeys) # 0 /\\ \\E k \\in current.unusedBlobKeys: /\\ blobStoreState' = [blobStoreState EXCEPT ![k] = [status |-&gt; \"UNSET\", image |-&gt; \"UNSET\"]] /\\ cleanerStates' = [ cleanerStates EXCEPT ![c].unusedBlobKeys = current.unusedBlobKeys \\ {k} ] /\\ UNCHANGED &lt;&lt;serverStates, databaseState, operations&gt;&gt; /\\ UNCHANGED time CleanerFinished(c) == LET current == cleanerStates[c] IN /\\ current.state = \"deleting_keys\" /\\ Cardinality(current.unusedBlobKeys) = 0 /\\ cleanerStates' = [ cleanerStates EXCEPT ![c].state = \"waiting\", ![c].blobKeys = {}, ![c].unusedBlobKeys = {} ] /\\ UNCHANGED &lt;&lt;serverStates, databaseState, blobStoreState, operations&gt;&gt; /\\ UNCHANGED time CleanerFail(c) == LET current == cleanerStates[c] IN /\\ current.state \\in {\"got_blob_keys\", \"got_unused_keys\", \"deleting_keys\"} /\\ cleanerStates' = [ cleanerStates EXCEPT ![c].state = \"waiting\", ![c].blobKeys = {}, ![c].unusedBlobKeys = {} ] /\\ UNCHANGED &lt;&lt;serverStates, databaseState, blobStoreState, operations&gt;&gt; /\\ UNCHANGED time (***************************************************************************) (* Specification / Next *) (***************************************************************************) Next == \\* Time can pass now \\/ TimePasses \\/ \\E s \\in SERVERS: \\/ ServerStartWrite(s) \\/ ServerWriteBlob(s) \\/ ServerWriteMetadataAndReturn(s) \\/ ServerFailWrite(s) \\/ ServerStartRead(s) \\/ ServerReadMetadata(s) \\/ ServerReadMetadataAndReturnEmpty(s) \\/ ServerReadBlobAndReturn(s) \\/ \\E c \\in CLEANERS: \\/ CleanerStartGetBlobKeys(c) \\/ CleanerGetUnusedKeys(c) \\/ CleanerDeletingKeys(c) \\/ CleanerFinished(c) \\/ CleanerFail(c) Spec == Init /\\ [][Next]_vars (***************************************************************************) (* Invariants *) (***************************************************************************) \\* Note that the success criteria hasn't changed this whole time ConsistentReads == \\/ operations = &lt;&lt;&gt;&gt; \\/ \\A i \\in 1..Len(operations): LET readOp == operations[i] IN \\/ /\\ readOp.type = \"READ\" /\\ \\/ \\E j \\in 1..i: LET writeOp == operations[j] IN /\\ writeOp.type = \"WRITE\" /\\ readOp.userId = writeOp.userId /\\ readOp.metadata = writeOp.metadata /\\ readOp.image = writeOp.image \\/ /\\ readOp.metadata = \"UNSET\" /\\ readOp.image = \"UNSET\" \\/ readOp.type = \"WRITE\" NoOrphanFiles == ~\\E k \\in UUIDS: /\\ blobStoreState[k] # [status |-&gt; \"UNSET\", image |-&gt; \"UNSET\"] /\\ \\A u \\in USERIDS: databaseState[u].imageId # k (***************************************************************************) (* Properties *) (***************************************************************************) EventuallyNoOrphanFiles == &lt;&gt;NoOrphanFiles AlwaysEventuallyNoOrphanFiles == []EventuallyNoOrphanFiles StopAfter3Operations == /\\ Len(operations) &lt;= 3 /\\ time &lt;= 2 StopAfter5Operations == Len(operations) &lt;= 5 ============================================================================= . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/storage-cleaner-improved/#modeling-the-design",
    "relUrl": "/database-blob/storage-cleaner-improved/#modeling-the-design"
  },"8": {
    "doc": "(Implementing New Requirements) Significant improvement",
    "title": "Verifying Storage Cleaner",
    "content": "We’re going to start off with the slightly larger model (two servers and two cleaners), since the last test didn’t show behavioral differences. Might as well perform the more rigorous test. | Next Section | Download Configuration | . Invariant ConsistentReads is violated. | 1. Initial predicate . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: UNSET | status: UNSET | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: UNSET | imageId: UNSET | . | . | operations : | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | . | s1 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | . | . | time : 0 | . | 2. ServerStartWrite Server s1 starts write at time 0 . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: UNSET | status: UNSET | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | . | s1 . | metadata: m1 | imageId: UNSET | image: i1 | state: started_write | userId: u1 | . | . | time : 0 | . | 3. ServerWriteBlob and successfully writes blob with id 1 . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: i1 | created: 0 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | . | s1 . | metadata: m1 | imageId: ui1 | image: i1 | state: wrote_blob | userId: u1 | . | . | time : 0 | . | 4. TimePasses Server s1 hangs at this point for 2 hours . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: i1 | created: 0 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | . | s1 . | metadata: m1 | imageId: ui1 | image: i1 | state: wrote_blob | userId: u1 | . | . | time : 1 | . | 5. TimePasses . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: i1 | created: 0 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | . | s1 . | metadata: m1 | imageId: ui1 | image: i1 | state: wrote_blob | userId: u1 | . | . | time : 2 | . | 6. ServerStartRead Server s2 starts to read a record for this user . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: i1 | created: 0 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: started_read | userId: u1 | . | s1 . | metadata: m1 | imageId: ui1 | image: i1 | state: wrote_blob | userId: u1 | . | . | time : 2 | . | 7. CleanerStartGetBlobKeys The cleaner starts and gets the blob id 1 because 2 hours has passed . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: i1 | created: 0 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: got_blob_keys | blobKeys: ui1 | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: started_read | userId: u1 | . | s1 . | metadata: m1 | imageId: ui1 | image: i1 | state: wrote_blob | userId: u1 | . | . | time : 2 | . | 8. CleanerGetUnusedKeys Blob id 1 is not in database, because write did not complete . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: i1 | created: 0 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: got_unused_keys | blobKeys: ui1 | unusedBlobKeys: ui1 | . | . | databaseState . | u1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: started_read | userId: u1 | . | s1 . | metadata: m1 | imageId: ui1 | image: i1 | state: wrote_blob | userId: u1 | . | . | time : 2 | . | 9. ServerWriteMetadataAndReturn Server s1 finishes writing . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: i1 | created: 0 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: got_unused_keys | blobKeys: ui1 | unusedBlobKeys: ui1 | . | . | databaseState . | u1 . | metadata: m1 | imageId: ui1 | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: started_read | userId: u1 | . | s1 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | . | . | time : 2 | . | 10. ServerReadMetadata Server s2 reads the record under the assumption nothing is wrong . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: i1 | created: 0 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: got_unused_keys | blobKeys: ui1 | unusedBlobKeys: ui1 | . | . | databaseState . | u1 . | metadata: m1 | imageId: ui1 | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: m1 | imageId: ui1 | image: UNSET | state: read_metadata | userId: u1 | . | s1 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | . | . | time : 2 | . | 11. CleanerDeletingKeys The cleaner deletes blob with id 1 . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: UNSET | status: UNSET | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: got_unused_keys | blobKeys: ui1 | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: m1 | imageId: ui1 | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: m1 | imageId: ui1 | image: UNSET | state: read_metadata | userId: u1 | . | s1 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | . | . | time : 2 | . | 12. ServerReadBlobAndReturn Server s2 reads an invalid blob . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: UNSET | status: UNSET | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: got_unused_keys | blobKeys: ui1 | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: m1 | imageId: ui1 | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | metadata : m1 | image : UNSET | userId : u1 | type : READ | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | . | s1 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | . | . | time : 2 | . | . The error we saw previously is gone, implying we fixed the design flaw we hoped to fix. This new error is much more complex. It requires the Server to stall at just the wrong time and be out of commission for 2 hours. This is pretty unlikely; in fact, it’s unlikely enough that some companies might be okay with it. But the fix is obvious: kill the servers after 1 hour of stalling or less. Chances are we were going to do it anyway in implementation, but let’s model it to get the extra assurance. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/storage-cleaner-improved/#verifying-storage-cleaner",
    "relUrl": "/database-blob/storage-cleaner-improved/#verifying-storage-cleaner"
  },"9": {
    "doc": "(Implementing New Requirements) Significant improvement",
    "title": "A quick fix",
    "content": "All the changes in the model are in the server behavior. Despite the large number of changes, all we’re really saying is that if less than an hour has passed since the server request started, it can proceed to the next state. Otherwise, it proceeds to the restart state. This can be reflected in an updated state diagram for Server writes: . WaitingStartWriteWriteMetadataServerRestartFailWriteWriteBlobAndReturnAssigns start timetimeout casetimeout casetimeout case This is reflected in the code below. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ---------------------------- MODULE storagecleanerimproved ---------------------------- (***************************************************************************) (* Server Restart *) (***************************************************************************) ServerRestart(s) == LET currentState == serverStates[s] IN LET terminationTime == (currentState.start + 1) IN /\\ currentState.state # \"waiting\" \\* Server must be active \\* This is the only state a server can reach if past termination time /\\ time =&gt; terminationTime /\\ serverStates' = [serverStates EXCEPT ![s].state =\"waiting\", ![s].userId =\"UNSET\", ![s].metadata = \"UNSET\", ![s].image = \"UNSET\", ![s].imageId = \"UNSET\"] /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState, operations&gt;&gt; /\\ UNCHANGED cleanerVars /\\ UNCHANGED time (***************************************************************************) (* Server Writes *) (***************************************************************************) ServerStartWrite(s) == /\\ serverStates[s].state = \"waiting\" /\\ \\E u \\in USERIDS, m \\in METADATAS, i \\in IMAGES: /\\ serverStates' = [serverStates EXCEPT ![s].state =\"started_write\", ![s].userId = u, ![s].metadata = m, ![s].image = i, \\* The time a write request starts ![s].start = time ] /\\ operations' = Append(operations, [ type |-&gt; \"WRITE\", userId |-&gt; u, metadata |-&gt; m, image |-&gt; i ]) \\* Cleaner state needs to be added as unchanged for all server operations /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState, cleanerStates&gt;&gt; /\\ UNCHANGED time ServerWriteBlob(s) == LET currentState == serverStates[s] IN LET terminationTime == (currentState.start + 1) IN /\\ time &lt; terminationTime \\* Can only start this state if server is live /\\ currentState.state = \"started_write\" /\\ \\E id \\in UUIDS: /\\ blobStoreState[id] = [status |-&gt; \"UNSET\", image |-&gt; \"UNSET\"] /\\ blobStoreState' = [blobStoreState EXCEPT ![id] = [ image |-&gt; currentState.image, created |-&gt; time ]] /\\ serverStates' = [serverStates EXCEPT ![s].state =\"wrote_blob\", ![s].imageId = id] /\\ UNCHANGED &lt;&lt;databaseState, operations&gt;&gt; /\\ UNCHANGED cleanerVars /\\ UNCHANGED time ServerWriteMetadataAndReturn(s) == LET currentState == serverStates[s] IN LET terminationTime == (currentState.start + 1) IN /\\ time &lt; terminationTime \\* Can only start this state if server is live /\\ currentState.state = \"wrote_blob\" /\\ databaseState' = [databaseState EXCEPT ![currentState.userId] = [ metadata |-&gt; currentState.metadata, imageId |-&gt; currentState.imageId] ] /\\ serverStates' = [serverStates EXCEPT ![s].state =\"waiting\", ![s].userId =\"UNSET\", ![s].metadata = \"UNSET\", ![s].image = \"UNSET\", ![s].imageId = \"UNSET\"] /\\ UNCHANGED &lt;&lt;blobStoreState, operations&gt;&gt; /\\ UNCHANGED cleanerVars /\\ UNCHANGED time ServerFailWrite(s) == LET currentState == serverStates[s] IN LET terminationTime == (currentState.start + 1) IN /\\ time &lt; terminationTime \\* Can only start this state if server is live /\\ serverStates[s].state \\in {\"started_write\", \"wrote_blob\"} /\\ serverStates' = [serverStates EXCEPT ![s].state =\"waiting\", ![s].userId =\"UNSET\", ![s].metadata = \"UNSET\", ![s].image = \"UNSET\", ![s].imageId = \"UNSET\"] /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState, operations&gt;&gt; /\\ UNCHANGED cleanerVars /\\ UNCHANGED time (***************************************************************************) (* Server Reads *) (***************************************************************************) ServerStartRead(s) == LET currentState == serverStates[s] IN /\\ serverStates[s].state = \"waiting\" /\\ \\E u \\in USERIDS: serverStates' = [serverStates EXCEPT ![s].state =\"started_read\", ![s].userId = u, \\* The time a read request starts ![s].start = time ] /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; /\\ UNCHANGED operations /\\ UNCHANGED cleanerVars /\\ UNCHANGED time ServerReadMetadata(s) == LET currentState == serverStates[s] IN LET terminationTime == (currentState.start + 1) IN /\\ time &lt; terminationTime \\* Can only start this state if server is live /\\ currentState.state = \"started_read\" /\\ databaseState[currentState.userId].metadata # \"UNSET\" /\\ serverStates' = [serverStates EXCEPT ![s].state =\"read_metadata\", ![s].metadata = databaseState[currentState.userId].metadata, ![s].imageId = databaseState[currentState.userId].imageId] /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; /\\ UNCHANGED operations /\\ UNCHANGED cleanerVars /\\ UNCHANGED time ServerReadMetadataAndReturnEmpty(s) == LET currentState == serverStates[s] IN LET terminationTime == (currentState.start + 1) IN /\\ time &lt; terminationTime \\* Can only start this state if server is live /\\ currentState.state = \"started_read\" /\\ databaseState[currentState.userId].metadata = \"UNSET\" /\\ serverStates' = [serverStates EXCEPT ![s].state =\"waiting\", ![s].userId =\"UNSET\", ![s].metadata = \"UNSET\", ![s].image = \"UNSET\", ![s].imageId = \"UNSET\"] /\\ operations' = Append(operations, [ type |-&gt; \"READ\", userId |-&gt; currentState.userId, metadata |-&gt; \"UNSET\", image |-&gt; \"UNSET\" ]) /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; /\\ UNCHANGED cleanerVars /\\ UNCHANGED time ServerReadBlobAndReturn(s) == LET currentState == serverStates[s] IN LET terminationTime == (currentState.start + 1) IN /\\ time &lt; terminationTime \\* Can only start this state if server is live /\\ currentState.state = \"read_metadata\" /\\ operations' = Append(operations, [ type |-&gt; \"READ\", userId |-&gt; currentState.userId, metadata |-&gt; currentState.metadata, image |-&gt; blobStoreState[currentState.imageId].image ]) /\\ serverStates' = [serverStates EXCEPT ![s].state =\"waiting\", ![s].userId =\"UNSET\", ![s].metadata = \"UNSET\", ![s].image = \"UNSET\", ![s].imageId = \"UNSET\"] /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; /\\ UNCHANGED cleanerVars /\\ UNCHANGED time ============================================================================= . Looks good, right? Let’s test it. | Next Section | . Close but no cigar. Invariant ConsistentReads is violated. | 1. Initial predicate Let's see what's going on here . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: UNSET | status: UNSET | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: UNSET | imageId: UNSET | . | . | operations : | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 0 | . | s1 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 0 | . | . | time : 0 | . | 2. TimePasses . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: UNSET | status: UNSET | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: UNSET | imageId: UNSET | . | . | operations : | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 0 | . | s1 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 0 | . | . | time : 1 | . | 3. ServerStartWrite . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: UNSET | status: UNSET | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 0 | . | s1 . | metadata: m1 | imageId: UNSET | image: i1 | state: started_write | userId: u1 | start: 1 | . | . | time : 1 | . | 4. ServerWriteBlob . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: i1 | created: 1 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 0 | . | s1 . | metadata: m1 | imageId: ui1 | image: i1 | state: wrote_blob | userId: u1 | start: 1 | . | . | time : 1 | . | 5. ServerWriteMetadataAndReturn A server successfully writes . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: i1 | created: 1 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: m1 | imageId: ui1 | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 0 | . | s1 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 1 | . | . | time : 1 | . | 6. TimePasses . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: i1 | created: 1 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: m1 | imageId: ui1 | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 0 | . | s1 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 1 | . | . | time : 2 | . | 7. TimePasses 2 hours pass . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: i1 | created: 1 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: m1 | imageId: ui1 | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 0 | . | s1 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 1 | . | . | time : 3 | . | 8. ServerStartWrite A server starts to update that same record . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: UNSET | status: UNSET | . | ui1 . | image: i1 | created: 1 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: m1 | imageId: ui1 | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 0 | . | s1 . | metadata: m1 | imageId: UNSET | image: i1 | state: started_write | userId: u1 | start: 3 | . | . | time : 3 | . | 9. ServerWriteBlob . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: i1 | created: 3 | . | ui1 . | image: i1 | created: 1 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: m1 | imageId: ui1 | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 0 | . | s1 . | metadata: m1 | imageId: ui2 | image: i1 | state: wrote_blob | userId: u1 | start: 3 | . | . | time : 3 | . | 10. ServerStartRead A read is starting at the same time. No worries, we've handled this . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: i1 | created: 3 | . | ui1 . | image: i1 | created: 1 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: m1 | imageId: ui1 | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: started_read | userId: u1 | start: 3 | . | s1 . | metadata: m1 | imageId: ui2 | image: i1 | state: wrote_blob | userId: u1 | start: 3 | . | . | time : 3 | . | 11. ServerReadMetadata Reads data that is about to change: image id is ui1 . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: i1 | created: 3 | . | ui1 . | image: i1 | created: 1 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: m1 | imageId: ui1 | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: m1 | imageId: ui1 | image: UNSET | state: read_metadata | userId: u1 | start: 3 | . | s1 . | metadata: m1 | imageId: ui2 | image: i1 | state: wrote_blob | userId: u1 | start: 3 | . | . | time : 3 | . | 12. ServerWriteMetadataAndReturn Write finishes, removing ui1 from the database . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: i1 | created: 3 | . | ui1 . | image: i1 | created: 1 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: m1 | imageId: ui2 | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: m1 | imageId: ui1 | image: UNSET | state: read_metadata | userId: u1 | start: 3 | . | s1 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 3 | . | . | time : 3 | . | 13. CleanerStartGetBlobKeys The cleaner pounces and deletes ui1 . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: i1 | created: 3 | . | ui1 . | image: i1 | created: 1 | . | . | cleanerStates . | c2 . | state: got_blob_keys | blobKeys: ui1 | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: m1 | imageId: ui2 | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: m1 | imageId: ui1 | image: UNSET | state: read_metadata | userId: u1 | start: 3 | . | s1 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 3 | . | . | time : 3 | . | 14. CleanerGetUnusedKeys . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: i1 | created: 3 | . | ui1 . | image: i1 | created: 1 | . | . | cleanerStates . | c2 . | state: got_unused_keys | blobKeys: ui1 | unusedBlobKeys: ui1 | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: m1 | imageId: ui2 | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: m1 | imageId: ui1 | image: UNSET | state: read_metadata | userId: u1 | start: 3 | . | s1 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 3 | . | . | time : 3 | . | 15. CleanerDeletingKeys . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: i1 | created: 3 | . | ui1 . | image: UNSET | status: UNSET | . | . | cleanerStates . | c2 . | state: got_unused_keys | blobKeys: ui1 | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: m1 | imageId: ui2 | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: m1 | imageId: ui1 | image: UNSET | state: read_metadata | userId: u1 | start: 3 | . | s1 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 3 | . | . | time : 3 | . | 16. ServerReadBlobAndReturn The reader tries to read ui1 and fails . | blobStoreState . | ui3 . | image: UNSET | status: UNSET | . | ui2 . | image: i1 | created: 3 | . | ui1 . | image: UNSET | status: UNSET | . | . | cleanerStates . | c2 . | state: got_unused_keys | blobKeys: ui1 | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | u1 . | metadata: m1 | imageId: ui2 | . | . | operations . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | metadata : m1 | image : i1 | userId : u1 | type : WRITE | . | . | metadata : m1 | image : UNSET | userId : u1 | type : READ | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 3 | . | s1 . | metadata: UNSET | imageId: UNSET | image: UNSET | state: waiting | userId: UNSET | start: 3 | . | . | time : 3 | . | . We’ve gotten closer, and our error is even more obscure. Now it requires an interaction of Storage Cleaner, a Read Server, and a Write Server. But there’s a relatively simple fix. Note: This was the first error that I did not expect. But it is exciting that TLA+ wouldn’t let me get away with it! . | Next: (Implementing New Requirements) A working update | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/storage-cleaner-improved/#a-quick-fix",
    "relUrl": "/database-blob/storage-cleaner-improved/#a-quick-fix"
  },"10": {
    "doc": "(Implementing New Requirements) A working update",
    "title": "(Implementing New Requirements) A working update",
    "content": ". | A last fix . | Storage Cleaner Run | . | Modeling the design | Verifying Storage Cleaner | Great! But how many 9s will it have? | A brief retrospective | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/storage-cleaner-working/",
    "relUrl": "/database-blob/storage-cleaner-working/"
  },"11": {
    "doc": "(Implementing New Requirements) A working update",
    "title": "A last fix",
    "content": "Our remaining problem is that Read operations can hang for an hour and thus have references to images that are out of date and have been deleted. We can fix this by introducing a delay of 1 hour between getting the unused keys and deleting them. Storage Cleaner Run . | | Storage CleanerStorage CleanerDatabaseDatabaseBlob StoreBlob Store | Gets batch of keys that have been created more than or exactly 2 hours ago | Returns batch of keys | Queries for unused keys | Returns unused keys | | Waits for at least 1 hour | Batch deletes unused keys | Returns statusalt[any failure] | | Repeats from beginning ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/storage-cleaner-working/#a-last-fix",
    "relUrl": "/database-blob/storage-cleaner-working/#a-last-fix"
  },"12": {
    "doc": "(Implementing New Requirements) A working update",
    "title": "Modeling the design",
    "content": "This is a relatively simple update to Cleaner. The relevant snippet is shown below. Click Download Code or Download PDF to see the entire program. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ---------------------------- MODULE storagecleaner ---------------------------- CleanerGetUnusedKeys(c) == LET current == cleanerStates[c] IN /\\ current.state = \"got_blob_keys\" /\\ cleanerStates' = [ cleanerStates EXCEPT ![c].state = \"got_unused_keys\", ![c].unusedBlobKeys = {k \\in current.blobKeys: \\A u \\in USERIDS: databaseState[u].imageId # k}, \\* Mark the time the unused keys were retrieved ![c].unusedKeyTime = time ] /\\ UNCHANGED &lt;&lt;serverStates, databaseState, blobStoreState, operations&gt;&gt; /\\ UNCHANGED time CleanerDeletingKeys(c) == LET current == cleanerStates[c] IN \\* Keys get deleted a minimum 1 hour after they are valid \\* This gives reads time to die LET earliestDeleteTime == current.unusedKeyTime + 1 IN /\\ time &gt;= earliestDeleteTime /\\ current.state \\in {\"got_unused_keys\", \"deleting_keys\"} /\\ Cardinality(current.unusedBlobKeys) # 0 /\\ \\E k \\in current.unusedBlobKeys: \\* Pick a key to delete /\\ blobStoreState' = [blobStoreState EXCEPT ![k] = [status |-&gt; \"UNSET\", image |-&gt; \"UNSET\"]] /\\ cleanerStates' = [ cleanerStates EXCEPT ![c].unusedBlobKeys = current.unusedBlobKeys \\ {k} ] /\\ UNCHANGED &lt;&lt;serverStates, databaseState, operations&gt;&gt; /\\ UNCHANGED time ============================================================================= . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/storage-cleaner-working/#modeling-the-design",
    "relUrl": "/database-blob/storage-cleaner-working/#modeling-the-design"
  },"13": {
    "doc": "(Implementing New Requirements) A working update",
    "title": "Verifying Storage Cleaner",
    "content": "This is the largest simulation we can comfortably run. We’ve seen errors that require at least a cleaner and two servers, so we know we can’t go any smaller. SPECIFICATION Spec CONSTANTS \\* Defined as symmetry sets to make the problem tractable SERVERS = {s1, s2} CLEANERS = {c1, c2} METADATAS = {m1, m2} USERIDS = {u1} IMAGES = {i1, i2} UUIDS = {ui1, ui2, ui3} CONSTRAINT StopAfter3Operations INVARIANT TypeOk ConsistentReads PROPERTY AlwaysEventuallyNoOrphanFiles . After an hour, the model checker returns successfully. | Next Section | Download Configuration | . | State Name | Total States | Distinct States | . | All States | 251341344 | 38079782 | . Because this same model caught a number of obscure bugs previously, we can feel reasonably confident in the fact that it passed now. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/storage-cleaner-working/#verifying-storage-cleaner",
    "relUrl": "/database-blob/storage-cleaner-working/#verifying-storage-cleaner"
  },"14": {
    "doc": "(Implementing New Requirements) A working update",
    "title": "Great! But how many 9s will it have?",
    "content": "Now that we’ve gone through the modeling task and tested correctness, it might be tempting to say that it will work 100% of the time in practice. That’s obviously not true, but going through the modeling process can help us with estimation. First we need to understand the metric(s) we’ve been testing. In this case, the metric is data consistency. And what we want is a lower bound of per request reliability. For each read/write operation, what is the likelihood of a consistent read response or consistency being maintained on write? . Let’s say we trust our model, which means we assign a 100% likelihood of every behavior we model working. What’s left? Our assumptions. Here are the assumptions we’ve made. We can assign per request probabilities that they will malfunction: . | Our clocks are accurate enough to handle hour time frames: . | The likelihood of cloud services (blob store and server management solution) having their time off by an hour is absurdly low. | Let’s guess 99.9999999999% it will not occur in any given request. | We’ll be pessimistic and assume clock inaccuracies will cause request failure. | . | Servers will not hang for &gt; 1 hour: . | Assume servers have 99.9% uptime and requests are distributed evenly: 99.9% chance a request is not delayed. | Assume our server monitoring solution has 99.9% uptime. | Assume servers fail independently (which is less representative the more applications are clustered on one physical machine or in one region). | 99.9999% chance that any given request won’t hang. | We’ll be pessimistic and assume any server that hangs and is not killed will cause request failure. | . | . Let’s take a look at some implicit assumptions we made: . | Our database does not corrupt records: . | Heroku Postgres has 99.999999999% durability, so let’s use their number. | . | Our blob store does not corrupt / lose objects: . | Amazon S3 has 99.999999999% durability. | . | Our software is coded perfectly: . | We cannot account for this. | . | . Now let’s be clear, this is a back-of-the-envelope calculation. Measurement is the only way to be confident in your statistical properties. Probability of Success = Clocks are accurate and Servers will not hang for &gt; 1 hour and Database does not corrupt record and Blob store does not corrupt object . Probability of Success = 12-9s * 6-9s * 11-9s * 11-9s = 99.99989% . Approximately 5-6 nines of reliability depending on how you round. That means out of every hundred thousand to one million requests, we’d expect one to be corrupted. That’s not fantastic, but we’ve been pessimistic, and it’s mostly driven by our unresponsiveness calculation. Let’s be a little more realistic. | Servers will not hang for &gt; 1 hour . | Assume servers have 99.9% uptime. | Assume only 10% of the downtime is due to a hang. | Assume requests will only be accepted during the first 10% of hang downtime. | Assume servers fail independently. | 99.999% chance a request will not hang. | Assume our server monitoring solution has 99.9% uptime. | 99.999999% chance for any given request that it won’t be on an unresponsive server. | . | . Probability of Success = 12-9s * 8-9s * 11-9s * 11-9s = 99.999998% . Approximately 7-8 nines of reliability. That means every 10 - 100 million requests we’d expect one to be corrupted. That feels like an acceptable lower bound of consistency, although we would still hope to do better in practice. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/storage-cleaner-working/#great-but-how-many-9s-will-it-have",
    "relUrl": "/database-blob/storage-cleaner-working/#great-but-how-many-9s-will-it-have"
  },"15": {
    "doc": "(Implementing New Requirements) A working update",
    "title": "A brief retrospective",
    "content": "That was a long road, but hopefully an interesting one. Some insights: . | It was possible to evolve the model with relatively minimal changes from step to step. | It was possible to add a whole actor type to the model Storage Cleaner while leaving Server states mostly unchanged. | We added detail to the model as needed to implement our solution. | Adding detail to a model is different than adding functionality: you can simply describe what is already present as it becomes relevant. | Creating a model with assumptions helps estimation. | The model checker was able to catch errors that would otherwise have been caught in production. | The details the model checker provided on error were equivalent or superior to what you could get from an observability solution. | . We can now confidently code this design using the TLA template as a specification. This doesn’t alleviate the need for unit, integration, and system tests. However, it does give you guidance as to what is critical to unit and integration test during the development process. It can also provide guidance for inspection and naming. Coding it, testing it, and deploying it to production are left as an exercise for the reader. | Cache invalidation | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/storage-cleaner-working/#a-brief-retrospective",
    "relUrl": "/database-blob/storage-cleaner-working/#a-brief-retrospective"
  },"16": {
    "doc": "(Verifying Correctness) A working solution",
    "title": "(Verifying Correctness) A working solution",
    "content": ". | Designing the working solution . | Write Profile | Read Profile | Assumptions | . | Modeling the working solution | Verifying the solution . | Single Server | Two Servers | Final large test | Summary | . | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/working/",
    "relUrl": "/database-blob/working/"
  },"17": {
    "doc": "(Verifying Correctness) A working solution",
    "title": "Designing the working solution",
    "content": "The problem we faced in the last solution was that the images were overwriting each other in the blob store. To perform a write, the blob was overwritten, leaving the system in an inconsistent state that would be returned by the read. The solution to this is simple: We generate a UUID for image, store it, and then associate it with the database record. That way the database record and image change together in a transactional manner. Write Profile . | | ClientClientServerServerDatabaseDatabaseBlob StoreBlob Store | Submits request | | Generates UUID for image | Writes blob, with UUID as key | Returns status | Writes record with userId as keyRecord contains metadata andUUID of image | Returns statusalt[any failure] | Returns fail / timeout | Returns successRead Profile . | | ClientClientServerServerDatabaseDatabaseBlob StoreBlob Store | Submits request | Reads database record with userId as key | Returns statusalt[metadata not present in database] | Returns empty record | Reads blob, with stored UUID as key | Returns statusalt[any unhandled failure] | Returns fail / timeout | Returns success Assumptions . We assume the UUID is always unique. This isn’t strictly true. The likelihood of each UUID being non-unique is 1/(2.71 quintillion). However, for the purpose of our model, we treat the probability as 0 and move on. Note: Deciding on what assumptions to make will be harder when the probability of failure is more likely. For example, a 1/(1 billon) event would happen to Facebook many times a day. It is critical to track your assumptions and back them up with observability/monitoring or other techniques. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/working/#designing-the-working-solution",
    "relUrl": "/database-blob/working/#designing-the-working-solution"
  },"18": {
    "doc": "(Verifying Correctness) A working solution",
    "title": "Modeling the working solution",
    "content": "The state machine is unchanged, but the state definitions will be updated. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ---------------------------- MODULE working ---------------------------- EXTENDS Naturals, Sequences CONSTANTS USERIDS, SERVERS, METADATAS, IMAGES, \\* This constant is added to allow us to assign UUIDs as blob store keys UUIDS VARIABLES databaseState, blobStoreState, serverStates, operations vars == &lt;&lt;databaseState, blobStoreState, serverStates, operations&gt;&gt; (***************************************************************************) (* Strong Typing *) (***************************************************************************) UserIdVal == USERIDS \\union {\"UNSET\"} MetadataVal == METADATAS \\union {\"UNSET\"} ImageVal == IMAGES \\union {\"UNSET\"} UUIDVal == UUIDS \\union {\"UNSET\"} \\* added UUID type (***************************************************************************) (* Describes a database record. We need this now that it has to keep track *) (* of which image UUID it is associated with. *) (***************************************************************************) DatabaseRecord == [ metadata: MetadataVal, imageId: UUIDVal ] (***************************************************************************) (* Describes all possible states a server can be in. Unchanged since last *) (* example. *) (***************************************************************************) ServerStateVal == [ state: { \\* current: \"waiting\", \\* next: StartWrite or StartRead \\* after: StartWrite \"started_write\", \\* next: WriteBlob or FailWrite \\* after: WriteBlob \"wrote_blob\", \\* next: WriteMetadataAndReturn or FailWrite \\* after: StartRead \"started_read\", \\* next: ReadMetadata \\* after: ReadMetadata, ReadMetadataAndReturnEmpty \"read_metadata\" \\* next: ReadBlobAndReturn }, userId: UserIdVal, metadata: MetadataVal, imageId: UUIDVal, \\* Need to track imageId to perform a lookup image: ImageVal ] \\* This is an observability value, and we are still measuring the same thing \\* No changes are needed OperationValue == [type: {\"READ\", \"WRITE\"}, userId: UserIdVal, metadata: MetadataVal, image:ImageVal] TypeOk == \\* Database state modified to hold database records /\\ databaseState \\in [USERIDS -&gt; DatabaseRecord] \\* Blob store uses UUIDs as keys rather than userIds /\\ blobStoreState \\in [UUIDS -&gt; ImageVal] /\\ serverStates \\in [SERVERS -&gt; ServerStateVal] /\\ operations \\in Seq(OperationValue) Init == \\* Database record needs to be initialized differently /\\ databaseState = [u \\in USERIDS |-&gt; [metadata |-&gt; \"UNSET\", imageId |-&gt; \"UNSET\"]] \\* Blob store is initialized with UUIDS /\\ blobStoreState = [u \\in UUIDS |-&gt; \"UNSET\"] /\\ serverStates = [s \\in SERVERS |-&gt; [state |-&gt; \"waiting\", userId |-&gt; \"UNSET\", metadata |-&gt; \"UNSET\", imageId |-&gt; \"UNSET\", image |-&gt; \"UNSET\" ]] /\\ operations = &lt;&lt;&gt;&gt; (***************************************************************************) (* State Machine: All of the states are functions of s (server), because *) (* the only actively modeled actors in this system are our servers, but *) (* there can be multiple working simultaneously. *) (***************************************************************************) (***************************************************************************) (* Writes *) (***************************************************************************) StartWrite(s) == /\\ serverStates[s].state = \"waiting\" /\\ \\E u \\in USERIDS, m \\in METADATAS, i \\in IMAGES: /\\ serverStates' = [serverStates EXCEPT ![s].state =\"started_write\", \\* Set values for the upcoming write ![s].userId = u, ![s].metadata = m, ![s].image = i] \\* Record the write for observability /\\ operations' = Append(operations, [ type |-&gt; \"WRITE\", userId |-&gt; u, metadata |-&gt; m, image |-&gt; i ]) /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; WriteBlob(s) == LET currentState == serverStates[s] IN /\\ currentState.state = \"started_write\" /\\ \\E id \\in UUIDS: (*******************************************************************) (* Guarantees a unique Id to simulate UUID. Note: If we run out of *) (* unset UUIDs, our system will just stop writing. We need to look *) (* out for this and ensure the set of UUIDs is large enough. *) (*******************************************************************) /\\ blobStoreState[id] = \"UNSET\" \\* /\\ blobStoreState' = [blobStoreState EXCEPT ![id] = currentState.image ] \\* Track Id to write to database /\\ serverStates' = [serverStates EXCEPT ![s].state =\"wrote_blob\", ![s].imageId = id] /\\ UNCHANGED &lt;&lt;databaseState, operations&gt;&gt; \\* Writing the database is now the last part of a write operation WriteMetadataAndReturn(s) == LET currentState == serverStates[s] IN /\\ currentState.state = \"wrote_blob\" /\\ databaseState' = [databaseState EXCEPT ![currentState.userId] = [ metadata |-&gt; currentState.metadata, \\* Store imageId in database for read imageId |-&gt; currentState.imageId] ] /\\ serverStates' = [serverStates EXCEPT ![s].state =\"waiting\", ![s].userId =\"UNSET\", ![s].metadata = \"UNSET\", ![s].image = \"UNSET\", ![s].imageId = \"UNSET\"] /\\ UNCHANGED &lt;&lt;blobStoreState, operations&gt;&gt; FailWrite(s) == /\\ serverStates[s].state \\in {\"started_write\", \"wrote_blob\"} /\\ serverStates' = [serverStates EXCEPT ![s].state =\"waiting\", ![s].userId =\"UNSET\", ![s].metadata = \"UNSET\", ![s].image = \"UNSET\", ![s].imageId = \"UNSET\"] /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState, operations&gt;&gt; (***************************************************************************) (* Reads *) (***************************************************************************) StartRead(s) == \\* Reading only starts when a server is waiting /\\ serverStates[s].state = \"waiting\" /\\ \\E u \\in USERIDS: serverStates' = [serverStates EXCEPT ![s].state =\"started_read\", ![s].userId =u] /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; /\\ UNCHANGED operations \\* If database record is present ReadMetadata(s) == LET currentState == serverStates[s] IN /\\ currentState.state = \"started_read\" \\* Represents reading the metadata while the database record is set /\\ databaseState[currentState.userId].metadata # \"UNSET\" /\\ serverStates' = [serverStates EXCEPT ![s].state =\"read_metadata\", ![s].metadata = databaseState[currentState.userId].metadata, \\* Reads imageId from database ![s].imageId = databaseState[currentState.userId].imageId] /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; /\\ UNCHANGED operations \\* If database record is not present ReadMetadataAndReturnEmpty(s) == LET currentState == serverStates[s] IN /\\ currentState.state = \"started_read\" \\* Represents reading the metadata while the database record is unset /\\ databaseState[currentState.userId].metadata = \"UNSET\" /\\ serverStates' = [serverStates EXCEPT ![s].state =\"waiting\", ![s].userId =\"UNSET\", ![s].metadata = \"UNSET\", ![s].image = \"UNSET\", ![s].imageId = \"UNSET\"] /\\ operations' = Append(operations, (***********************************************) (* Returns an empty record *) (***********************************************) [ type |-&gt; \"READ\", userId |-&gt; currentState.userId, metadata |-&gt; \"UNSET\", image |-&gt; \"UNSET\" ]) /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; ReadBlobAndReturn(s) == LET currentState == serverStates[s] IN /\\ currentState.state = \"read_metadata\" /\\ operations' = Append(operations, [ type |-&gt; \"READ\", userId |-&gt; currentState.userId, metadata |-&gt; currentState.metadata, \\* Looks up image by imageId image |-&gt; blobStoreState[currentState.imageId] ]) /\\ serverStates' = [serverStates EXCEPT ![s].state =\"waiting\", ![s].userId =\"UNSET\", ![s].metadata = \"UNSET\", ![s].image = \"UNSET\", ![s].imageId = \"UNSET\"] /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; (***************************************************************************) (* Specification / Next *) (***************************************************************************) Next == \\* For every step, pick a server and have it advance one state \\E s \\in SERVERS: \\/ StartWrite(s) \\/ WriteBlob(s) \\* New step \\/ WriteMetadataAndReturn(s) \\* New step \\/ FailWrite(s) \\/ StartRead(s) \\/ ReadMetadata(s) \\* New step \\/ ReadMetadataAndReturnEmpty(s) \\* New step \\/ ReadBlobAndReturn(s) Spec == Init /\\ [][Next]_vars (***************************************************************************) (* Invariants *) (***************************************************************************) \\* Note that the success criteria hasn't changed this whole time ConsistentReads == \\* If there are no operations, they are consistent \\/ operations = &lt;&lt;&gt;&gt; \\/ \\A i \\in 1..Len(operations): \\* For every read operation LET readOp == operations[i] IN \\/ /\\ readOp.type = \"READ\" \\* There must exist a write operation /\\ \\/ \\E j \\in 1..i: LET writeOp == operations[j] IN /\\ writeOp.type = \"WRITE\" \\* With the same data /\\ readOp.userId = writeOp.userId /\\ readOp.metadata = writeOp.metadata /\\ readOp.image = writeOp.image \\/ \\* Ignore unset reads /\\ readOp.metadata = \"UNSET\" /\\ readOp.image = \"UNSET\" \\/ readOp.type = \"WRITE\" \\* Ignore writes (***************************************************************************) (* This is used for model checker configuration so the simulation doesn't *) (* go on forever. *) (***************************************************************************) StopAfter3Operations == Len(operations) &lt;= 3 StopAfter5Operations == Len(operations) &lt;= 5 ============================================================================= . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/working/#modeling-the-working-solution",
    "relUrl": "/database-blob/working/#modeling-the-working-solution"
  },"19": {
    "doc": "(Verifying Correctness) A working solution",
    "title": "Verifying the solution",
    "content": "Single Server . We’re pretty confident this solution is going to work, but we’ve been confident before. We’ll start our test using just a single server, s1. SPECIFICATION Spec CONSTANTS SERVERS = {s1} METADATAS = {m1, m2} USERIDS = {u1} IMAGES = {i1, i2} UUIDS = {ui1, ui2, ui3, ui4, ui5} CONSTRAINT StopAfter3Operations INVARIANT TypeOk ConsistentReads . We also limit our total operations (Read or Write) to 3. That might not sound like much, but it’s caught all our errors so far. But this time, instead of errors, we get back a state space: . | Next Section | Download Configuration | . | State Name | Total States | Distinct States | . | Init | 1 | 1 | . | StartWrite | 81904 | 4844 | . | WriteBlob | 16300 | 16300 | . | WriteMetadataAndReturn | 16300 | 5040 | . | FailWrite | 21144 | 14224 | . | StartRead | 20476 | 20476 | . | ReadMetadata | 15000 | 15000 | . | ReadMetadataAndReturnEmpty | 5476 | 451 | . | ReadBlobAndReturn | 15000 | 760 | . This is all the states that were tested by the checker. And it worked! We’re not done yet, though; this is just a single server. Let’s see what happens when we throw a second one in the mix. Two Servers . We are now testing with two servers, s1, and s2. We are again stopping after 3 operations. SPECIFICATION Spec CONSTANTS SERVERS = {s1, s2} METADATAS = {m1, m2} USERIDS = {u1} IMAGES = {i1, i2} UUIDS = {ui1, ui2, ui3, ui4, ui5} CONSTRAINT StopAfter3Operations . This test passes too! . | Next Section | Download Configuration | . | State Name | Total States | Distinct States | . | Init | 1 | 1 | . | StartWrite | 1064288 | 29892 | . | WriteBlob | 287040 | 166620 | . | WriteMetadataAndReturn | 287040 | 59500 | . | FailWrite | 373296 | 42664 | . | StartRead | 266072 | 184372 | . | ReadMetadata | 206560 | 146800 | . | ReadMetadataAndReturnEmpty | 59512 | 1571 | . | ReadBlobAndReturn | 365600 | 4100 | . Note how the number of states has expanded drastically. This is to be expected; two servers can interact in a lot more ways than one server. So the two tests that have been guiding our entire development have passed! Are we done now? Not quite. Final large test . Before we can be really confident, we have to run a larger test. We’re going with 4 servers this time, and way more types of images and metadata. We’re also going up to 10 operations. This is overall a much more representative test. Why didn’t we start with it? . CONSTANTS SERVERS = {s1, s2, s3} METADATAS = {m1, m2, m3} USERIDS = {u1, u2, u3, u4, u5} IMAGES = {i1, i2, i3} UUIDS = {ui1, ui2} CONSTRAINT StopAfter10Operations . The state space grows exponentially on the number of constants. The previous tests completed in seconds. This test completed in hours. It’s easy to make a test that will take days. The recommended technique is to start small and work your way up. Finally, do a large test on a powerful machine. The TLA+ toolbox can even spin up fast cloud workers. If you get failures with small tests, a large test isn’t going to be any better. But if all your small tests are passing, it’s time to really stress test the solution. In general, running the biggest test you can afford to wait for is the right answer (unless you know particular details about your system that would make expanding the test unnecessary). Here is the final state space. Look how large it is: . | Next Section | Download Configuration | . | State Name | Total States | Distinct States | . | All States | 2281234 | 728303 | . Precise state profiling needed to be turned off just so this model would run. Summary . Now we can be confident in our solution. And this is how it will remain forever, perfect and untouched! I bet no one is going to want to add features. Oh wait… . | Next: (Adding Requirements) A more cost efficent solution | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/working/#verifying-the-solution",
    "relUrl": "/database-blob/working/#verifying-the-solution"
  },"20": {
    "doc": "(Start of Process) The naive first draft",
    "title": "(Start of Process) The naive first draft",
    "content": ". | Solution design . | Write Profile | Read Profile | Design Decisions | . | Solution modeling | Logically debugging the solution . | Starting small | Increasing the size of the simulation | . | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/naive/",
    "relUrl": "/database-blob/naive/"
  },"21": {
    "doc": "(Start of Process) The naive first draft",
    "title": "Solution design",
    "content": "Let’s start by writing the hackathon solution to this problem (but specify it with way too much detail). We will describe what’s going on using a UML Sequence Diagram. Write Profile . This represents a client, most likely a website, submitting multi-part form data consisting of a profile image and JSON metadata describing the contents of the profile. | | ClientClientServerServerDatabaseDatabaseBlob StoreBlob Store | Submits request | Writes metadata with userId as key | Returns status | Writes/overwrites blob with userId as key | Returns statusalt[any failure] | Returns fail / timeout | Returns success Read Profile . This represents a client, most likely a website, requesting a user profile, receiving JSON containing the profile metadata and a base64 encoded version of the profile image. | | ClientClientServerServerDatabaseDatabaseBlob StoreBlob Store | Submits request | Reads metadata with userId as key | Returns status | Reads blob with userId as key | Returns statusalt[any failure] | Returns fail / timeout | Returns success Design Decisions . Let’s talk about a couple design decisions made here. One is reasonable, but the other two will backfire. The reasonable one is as follows: If any failure happens during the process, we return a fail message to the client or timeout. While we could attempt to retry certain failures, the server itself can die any time during the process. The client and our consistency model are going to need to handle this case no matter what. There are schools of thought that say this is how you should always build your system: see Crash-Only software. This can make designing and testing software simpler and safer but is certainly not a one-size fits all solution. The two that will backfire: . | We are using the userId as the key for the metadata and the blob, so that we can trivially get / set / overwrite all the necessary information. | We are writing to the database prior to writing to the blob store. | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/naive/#solution-design",
    "relUrl": "/database-blob/naive/#solution-design"
  },"22": {
    "doc": "(Start of Process) The naive first draft",
    "title": "Solution modeling",
    "content": "When modeling in TLA+, generally you construct one or more state machines, which will then be run with simulated concurrency. It can be helpful to draw state diagrams to help you code. What we are modeling is a state machine that describes the behavior of a Server. WaitingStartWriteWriteMetadataFailWriteWriteBlobAndReturnStartReadReadMetadataReadBlobAndReturn Now it’s time to model the system formally. I’ve written the narrative into the comments, so even if you don’t know TLA+, please read the comments in order. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ---------------------------- MODULE naive ---------------------------- EXTENDS Naturals, Sequences (***************************************************************************) (* Our \"Test Data\". Each of these is a set of ids, relevant only in that *) (* they are distinct from each other. *) (***************************************************************************) CONSTANTS USERIDS, \\* A set of userIds to test with (one per user) SERVERS, \\* A set of serverIds (each one will \"create\" a new server) METADATAS, \\* A set of metadata versions. IMAGES \\* A set of image versions. (***************************************************************************) (* Our variables update each step and represent the state of our modeled *) (* system. *) (***************************************************************************) VARIABLES (***********************************************************************) (* These variables are relevant to the implementation. *) (***********************************************************************) databaseState, \\* databaseState[key] = What is stored for this key blobStoreState, \\* blobStoreState[key] = What is stored for this key serverStates, \\* serverStates[serverId] = What the server is doing (***********************************************************************) (* This variable is used to observe the state of the system to *) (* check if it's doing the right thing. Think of it like the *) (* test harness. *) (***********************************************************************) \\* Represents all the write requests and read responses sent to/from \\* the system. operations (***************************************************************************) (* Represents every variable in this model. *) (***************************************************************************) vars == &lt;&lt;databaseState, blobStoreState, serverStates, operations&gt;&gt; (***************************************************************************) (* You strongly type math with math. Here is where we say which types are *) (* allowed for all our variables. TypeOk is set as an Invariant, which *) (* means we expect it always to be true. It will fail if false, *) (* effectively giving us type checking. *) (* The declarations that follow are part of TypeOk, separated to make it *) (* clearer. *) (***************************************************************************) (***************************************************************************) (* Allows all the values to also be UNSET, which is a distinct value not *) (* to be confused for the others. *) (***************************************************************************) UserIdVal == USERIDS \\union {\"UNSET\"} MetadataVal == METADATAS \\union {\"UNSET\"} ImageVal == IMAGES \\union {\"UNSET\"} (***************************************************************************) (* Describes all possible states a server can be in. *) (***************************************************************************) ServerStateVal == [ state: { \\* current: \"waiting\", \\* next: StartWrite or StartRead \\* after: StartWrite \"started_write\", \\* next: WriteMetadata or FailWrite \\* after: WriteMetadata \"wrote_metadata\", \\* next: WriteBlobAndReturn or FailWrite \\* after: StartRead \"started_read\", \\* next: ReadMetadata \\* after: ReadMetadata \"read_metadata\" \\* next: ReadBlobAndReturn }, userId: UserIdVal, metadata: MetadataVal, image: ImageVal ] (***************************************************************************) (* Represents an action that occured on the API boundary. Used for *) (* observability. *) (***************************************************************************) OperationValue == [type: {\"READ\", \"WRITE\"}, userId: UserIdVal, metadata: MetadataVal, image:ImageVal] (***************************************************************************) (* The full type specification for all variables in the system *) (***************************************************************************) TypeOk == (***********************************************************************) (* The database state contains a mapping of userIds to metadatas. *) (* It can also be \"UNSET\", representing a case where there is no *) (* metadata. *) (* Note: we make this specific to our problem. If this were a more *) (* general problem, it might look like: *) (* databaseState \\in [KEYS -&gt; RECORDS]. *) (***********************************************************************) /\\ databaseState \\in [USERIDS -&gt; MetadataVal] (***********************************************************************) (* The blob store state contains a mapping of userIds to images. *) (* Note: we make this specific to our problem. If this was a more *) (* general problem, it might look like: *) (* blobStoreState \\in [KEYS -&gt; BLOBS]. *) (***********************************************************************) /\\ blobStoreState \\in [USERIDS -&gt; ImageVal] (***********************************************************************) (* The serverStates store the current states for each server, allowing *) (* us to build a state machine describing our system. Implemented as a *) (* mapping between servers and all their possible states. *) (***********************************************************************) /\\ serverStates \\in [SERVERS -&gt; ServerStateVal] /\\ operations \\in Seq(OperationValue) (***************************************************************************) (* When the model starts, everything begins unset. Unlike standard testing *) (* every possible state will be explored, so we don't need to initialize *) (* for specific scenarios. *) (***************************************************************************) Init == /\\ databaseState = [u \\in USERIDS |-&gt; \"UNSET\"] /\\ blobStoreState = [u \\in USERIDS |-&gt; \"UNSET\"] /\\ serverStates = [s \\in SERVERS |-&gt; [state |-&gt; \"waiting\", userId |-&gt; \"UNSET\", metadata |-&gt; \"UNSET\", image |-&gt; \"UNSET\" ]] /\\ operations = &lt;&lt;&gt;&gt; (***************************************************************************) (* State Machine: All of the states are functions of s (server), because *) (* the only actively modeled actors in this system are our servers, but *) (* there can be multiple working simultainiously. *) (***************************************************************************) StartWrite(s) == \\* Writing only starts when a server is waiting /\\ serverStates[s].state = \"waiting\" \\* This will try every combination of userId, metadata and image (one at \\* a time). We store this throughout the state lifecycle. Next states will \\* refer to this /\\ \\E u \\in USERIDS, m \\in METADATAS, i \\in IMAGES: \\* serverStates' means the next state of serverStates /\\ serverStates' = [serverStates EXCEPT \\* update only server s ![s].state =\"started_write\", \\* update state \\* set values for the upcoming write ![s].userId = u, ![s].metadata = m, ![s].image = i] \\* Record the write for observability /\\ operations' = Append(operations, \\* This is created with \"record\" symantics, \\* which is why |-&gt; not = is used [ type |-&gt; \"WRITE\", userId |-&gt; u, metadata |-&gt; m, image |-&gt; i ]) \\* We need to list every unchanged variable. \\* Not changing is a behavior too. /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; WriteMetadata(s) == \\* Represents a successful database write \\* Established an alias to make code more compact LET currentState == serverStates[s] IN \\* Metadata writing happens directly after write is started /\\ currentState.state = \"started_write\" \\* Database is transactional/consistent. We can therefore model this \\* happening in one step /\\ databaseState' = [databaseState EXCEPT ![currentState.userId] = currentState.metadata ] /\\ serverStates' = [serverStates EXCEPT \\* This is how the state advances ![s].state =\"wrote_metadata\"] /\\ UNCHANGED &lt;&lt;blobStoreState, operations&gt;&gt; WriteBlobAndReturn(s) == \\* Represents a successful blob store write LET currentState == serverStates[s] IN \\* Metadata writing happens directly after write is started /\\ currentState.state = \"wrote_metadata\" \\* Blob store has read after write consistency. We can therefore \\* model it happening in one step /\\ blobStoreState' = [blobStoreState EXCEPT ![currentState.userId] = currentState.image ] /\\ serverStates' = [serverStates EXCEPT \\* update only server s \\* Process done once blob is written ![s].state =\"waiting\"] /\\ UNCHANGED &lt;&lt;databaseState, operations&gt;&gt; FailWrite(s) == (***********************************************************************) (* In our model, a server can only fail if it is writing. We don't *) (* need to do this, but it cuts down state space we don't care about. *) (* We are worried about writes failing in a bad spot causing errors in *) (* future reads and writes. We don't model spontaneous read failures. *) (***********************************************************************) \\* Will only get to this state if writing /\\ serverStates[s].state \\in {\"started_write\", \"wrote_metadata\"} /\\ serverStates' = [serverStates EXCEPT ![s].state =\"waiting\", ![s].userId =\"UNSET\", ![s].metadata = \"UNSET\", ![s].image = \"UNSET\"] (***********************************************************************) (* Nothing happens with the database and blob store. Everything this *) (* server did stays done, anything left undone stays undone. *) (***********************************************************************) /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState, operations&gt;&gt; (***************************************************************************) (* We model reading in detail because reading and writing are occurring at *) (* the same time, and may interact with each other in unexpected ways. *) (***************************************************************************) StartRead(s) == \\* Reading only starts when a server is waiting /\\ serverStates[s].state = \"waiting\" /\\ \\E u \\in USERIDS: \\* When we start reading we pick a user id serverStates' = [serverStates EXCEPT \\* update only server s ![s].state =\"started_read\", ![s].userId =u] \\* Reading doesn't changed stored state /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; /\\ UNCHANGED operations ReadMetadata(s) == LET currentState == serverStates[s] IN \\* Once the read has started, the first thing we do is Read Metadata /\\ currentState.state = \"started_read\" /\\ serverStates' = [serverStates EXCEPT \\* update only server s ![s].state =\"read_metadata\", (***********************************************) (* Assembles the read request from whatever is *) (* in the database for that user. *) (***********************************************) ![s].metadata = databaseState[currentState.userId]] \\* Reading doesn't changed stored state /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; /\\ UNCHANGED operations ReadBlobAndReturn(s) == LET currentState == serverStates[s] IN \\* Blob is read after metadata is read /\\ currentState.state = \"read_metadata\" /\\ serverStates' = [serverStates EXCEPT \\* update only server s ![s].state =\"waiting\", (***********************************************) (* Assembles the read request from whatever is *) (* in the database for that user. *) (***********************************************) ![s].image = blobStoreState[currentState.userId]] /\\ operations' = Append(operations, (***********************************************) (* Read returns the state it built up during *) (* the read process. *) (***********************************************) [ type |-&gt; \"READ\", userId |-&gt; currentState.userId, metadata |-&gt; currentState.metadata, image |-&gt; blobStoreState[currentState.userId] ]) \\* Reading doesn't changed stored state /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; (***************************************************************************) (* The Next section determines what states will be chosen on every step. *) (***************************************************************************) Next == \\* For every step, pick a server and have it advance one state \\E s \\in SERVERS: \\/ StartWrite(s) \\/ WriteMetadata(s) \\/ WriteBlobAndReturn(s) \\/ FailWrite(s) \\/ StartRead(s) \\/ ReadMetadata(s) \\/ ReadBlobAndReturn(s) (***************************************************************************) (* The Spec describes what the describe system DOES. *) (* First it starts in the Init state. *) (* Then for every step use Next state: represented as []Next. *) (* In temporal logic [] means \"for all states.\" *) (* However let's imagine this is part of a larger system; sometimes this *) (* system will do nothing. That is represented by [Next]_vars, meaning: *) (* Next \\/ UNCHANGED vars. *) (* See learning material for a better explaination of temporal logic *) (* operators. *) (* Note: The spec in this case describes what the system DOES, not what it *) (* should do. Basically this is our system under test, and we describe *) (* Invariants (below) and properties (discussed later) to alert us if the *) (* system does something wrong/unexpected *) (***************************************************************************) Spec == Init /\\ [][Next]_vars (***************************************************************************) (* Invariants: These are things that should always be true about the *) (* system. If they become false during any step, an error will occur with *) (* a trace that shows you the series of steps that let it to be violated. *) (* This is very powerful. *) (* The first invariant we saw was TypeOk: the types are expected to always *) (* conform to the expected type system, and if not we want to know why. *) (***************************************************************************) ConsistentReads == \\* If there are no operations, they are consistent \\/ operations = &lt;&lt;&gt;&gt; \\/ \\A i \\in 1..Len(operations): \\* For every read operation LET readOp == operations[i] IN \\/ /\\ readOp.type = \"READ\" \\* There must exist a write operation /\\ \\/ \\E j \\in 1..i: LET writeOp == operations[j] IN /\\ writeOp.type = \"WRITE\" \\* With the same data /\\ readOp.userId = writeOp.userId /\\ readOp.metadata = writeOp.metadata /\\ readOp.image = writeOp.image \\/ \\* Ignore unset reads /\\ readOp.metadata = \"UNSET\" /\\ readOp.image = \"UNSET\" \\/ readOp.type = \"WRITE\" \\* Ignore writes (***************************************************************************) (* One of the best things about invariants is that if they were ever going *) (* to be tripped, you'll hear about it. Unlike testing, where sometimes a *) (* confluence of events leads to a test passing when it shouldn't, the *) (* model checker will try every possible state, so if it ever messes up, *) (* you'll know. *) (***************************************************************************) (***************************************************************************) (* This is used for model checker configuration so the simulation doesn't *) (* go on forever. *) (***************************************************************************) StopAfter3Operations == Len(operations) &lt;= 3 ============================================================================= . It should be noted that ConsistentReads is a relatively weak success criteria. All it says is that anything returned by Read must have been written in one go. It doesn’t say how recently it needs to have been written. It doesn’t say that reads couldn’t go backward in time and regress. Yet this invariant is sufficient to catch all the flaws that will arise in this design. We don’t need to model every aspect of the system, only the aspects we are concerned about. In this case it is making sure the blob store is consistent with the database. Common sense may be used to say that the design keeps the storage up to date. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/naive/#solution-modeling",
    "relUrl": "/database-blob/naive/#solution-modeling"
  },"23": {
    "doc": "(Start of Process) The naive first draft",
    "title": "Logically debugging the solution",
    "content": "Starting small . Remember the CONSTANTS section above? Now it is time to define them. CONSTANTS SERVERS = {s1} METADATAS = {m1, m2} USERIDS = {u1} IMAGES = {i1, i2} . As you can see, each of the constants is a set. What really matters is the cardinality (size) of each set. By only having one server and one user, we are testing on a very small version of our problem. It’s good to start small, and then expand the tests as your small tests succeed. Note that we have two metadatas and two images. If we only had one, it would be as though there were only a single profile and single image that could be uploaded. That would likely lead to a lot of tests passing that really shouldn’t. Determining the size of the simulation is a bit of an art, but if it doesn’t work for a single server and a single userId, we know we’re in trouble. And oh no! We’re in trouble. When you run the model, the error trace shows up in the model checker UI as shown below. Don’t bother reading it in detail, because we have a better way of exploring it. For our purposes we will be visualizing the model checker errors as shown below. The writing with a lighter font weight (and right aligned on desktop) are notes describing the failure and part of the narrative. | Next Section | Download Configuration | . Invariant ConsistentReads is violated. | 1. Initial predicate . | blobStoreState . | u1 . | : UNSET | . | . | databaseState . | u1 . | : UNSET | . | . | operations : | serverStates . | s1 . | state: waiting | userId: UNSET | metadata: UNSET | image: UNSET | . | . | . | 2. StartWrite . | blobStoreState . | u1 . | : UNSET | . | . | databaseState . | u1 . | : UNSET | . | . | operations . | . | userId : u1 | metadata : m1 | image : i1 | type : WRITE | . | . | serverStates . | s1 . | state: started_write | userId: u1 | metadata: m1 | image: i1 | . | . | . | 3. WriteMetadata . | blobStoreState . | u1 . | : UNSET | . | . | databaseState . | u1 . | : m1 | . | . | operations . | . | userId : u1 | metadata : m1 | image : i1 | type : WRITE | . | . | serverStates . | s1 . | state: wrote_metadata | userId: u1 | metadata: m1 | image: i1 | . | . | . | 4. FailWrite This failure left the system in a potentially bad state . | blobStoreState . | u1 . | : UNSET | . | . | databaseState . | u1 . | : m1 | . | . | operations . | . | userId : u1 | metadata : m1 | image : i1 | type : WRITE | . | . | serverStates . | s1 . | state: waiting | userId: UNSET | metadata: UNSET | image: UNSET | . | . | . | 5. StartRead . | blobStoreState . | u1 . | : UNSET | . | . | databaseState . | u1 . | : m1 | . | . | operations . | . | userId : u1 | metadata : m1 | image : i1 | type : WRITE | . | . | serverStates . | s1 . | state: started_read | userId: u1 | metadata: UNSET | image: UNSET | . | . | . | 6. ReadMetadata . | blobStoreState . | u1 . | : UNSET | . | . | databaseState . | u1 . | : m1 | . | . | operations . | . | userId : u1 | metadata : m1 | image : i1 | type : WRITE | . | . | serverStates . | s1 . | state: read_metadata | userId: u1 | metadata: m1 | image: UNSET | . | . | . | 7. ReadBlobAndReturn This is where the invariant was no longer true . | blobStoreState . | u1 . | : UNSET | . | . | databaseState . | u1 . | : m1 | . | . | operations . | This was the write that was only partially written . | userId : u1 | metadata : m1 | image : i1 | type : WRITE | . | This incomplete write state was read, causing failure . | userId : u1 | metadata : m1 | image : UNSET | type : READ | . | . | serverStates . | s1 . | state: waiting | userId: u1 | metadata: m1 | image: UNSET | . | . | . | . So we know we have at least one design flaw. If a Write fails after the database has been written to, but before the blob store has been written to, the next reads will be corrupted. This is true even if there is a single server. We will try to address this flaw in the next session. Increasing the size of the simulation . Normally after a failure, you’d attempt to correct your design before running another simulation. But I’m curious if the system fails faster or in a different way when there are multiple servers. CONSTANTS SERVERS = {s1, s2} METADATAS = {m1, m2} USERIDS = {u1} IMAGES = {i1, i2} . | Next Section | Download Configuration | . Invariant ConsistentReads is violated. | 1. Initial predicate . | blobStoreState . | u1 . | : UNSET | . | . | databaseState . | u1 . | : UNSET | . | . | operations : | serverStates . | s2 . | state: waiting | userId: UNSET | metadata: UNSET | image: UNSET | . | s1 . | state: waiting | userId: UNSET | metadata: UNSET | image: UNSET | . | . | . | 2. StartWrite s1 has started writing . | blobStoreState . | u1 . | : UNSET | . | . | databaseState . | u1 . | : UNSET | . | . | operations . | . | userId : u1 | metadata : m1 | image : i1 | type : WRITE | . | . | serverStates . | s2 . | state: waiting | userId: UNSET | metadata: UNSET | image: UNSET | . | s1 . | state: started_write | userId: u1 | metadata: m1 | image: i1 | . | . | . | 3. WriteMetadata and written metadata . | blobStoreState . | u1 . | : UNSET | . | . | databaseState . | u1 . | : m1 | . | . | operations . | . | userId : u1 | metadata : m1 | image : i1 | type : WRITE | . | . | serverStates . | s2 . | state: waiting | userId: UNSET | metadata: UNSET | image: UNSET | . | s1 . | state: wrote_metadata | userId: u1 | metadata: m1 | image: i1 | . | . | . | 4. StartRead then s2 starts reading . | blobStoreState . | u1 . | : UNSET | . | . | databaseState . | u1 . | : m1 | . | . | operations . | . | userId : u1 | metadata : m1 | image : i1 | type : WRITE | . | . | serverStates . | s2 . | state: started_read | userId: u1 | metadata: UNSET | image: UNSET | . | s1 . | state: wrote_metadata | userId: u1 | metadata: m1 | image: i1 | . | . | . | 5. ReadMetadata reads valid metadata . | blobStoreState . | u1 . | : UNSET | . | . | databaseState . | u1 . | : m1 | . | . | operations . | . | userId : u1 | metadata : m1 | image : i1 | type : WRITE | . | . | serverStates . | s2 . | state: read_metadata | userId: u1 | metadata: m1 | image: UNSET | . | s1 . | state: wrote_metadata | userId: u1 | metadata: m1 | image: i1 | . | . | . | 6. ReadBlobAndReturn and unwritten image . | blobStoreState . | u1 . | : UNSET | . | . | databaseState . | u1 . | : m1 | . | . | operations . | . | userId : u1 | metadata : m1 | image : i1 | type : WRITE | . | . | userId : u1 | metadata : m1 | image : UNSET | type : READ | . | . | serverStates . | s2 . | state: waiting | userId: u1 | metadata: m1 | image: UNSET | . | s1 . | state: wrote_metadata | userId: u1 | metadata: m1 | image: i1 | . | . | . | . Good thing we ran this simulation. Even in the absence of failure, there is a race condition that can lead to incomplete data being returned. Looks like we have some work to do! . | Next: (Progressive Refinement) An improved solution | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/naive/#logically-debugging-the-solution",
    "relUrl": "/database-blob/naive/#logically-debugging-the-solution"
  },"24": {
    "doc": "(Adding Requirements) A more cost efficent solution",
    "title": "(Adding Requirements) A more cost efficent solution",
    "content": " ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/cost-efficent/",
    "relUrl": "/database-blob/cost-efficent/"
  },"25": {
    "doc": "(Adding Requirements) A more cost efficent solution",
    "title": "The new requirements hit",
    "content": "You’ve hit the big time. Absolute perfection. You’ve just built the database blob store coordinator to beat them all. Nothing is going to bring you down… until your boss walks into your office. “I just talked to Jim in DevOps,” she says ominously, “and we’re getting hosed on our data storage costs. Apparently this last update writes a new object every time someone updates their profile. Even if they update it again, all the old stuff sits around.” . “But it’s way more correct this way,” you respond defensively. “I modeled and verified it. That means I’m right, I win the conversation. Good day sir/madam.” . “Not so fast, bucko,” she retorts. “You know what I always say: ‘Time is money, money is money, and cloud storage costs are money.’ You’re going to have to figure it out.” . “But please, boss,” you plaintively mewl, “I just got this working correctly. I proved it and everything. Running that last test took twelve hours. Who knows what will happen if I go mucking about in there?!” . She looks at you with a mixture of contempt and pity. “Don’t you know one of the best characteristics of formal models is that you can build on existing models, make them more robust, and use them to verify change?” . A realization hits you. You underestimated her technical skills due to her alignment with company priorities and the profit motive. She was absolutely correct: modeling is very useful for evolving designs. Duly chastened, you get back to work, and we go back to using a collective pronoun. “One more thing”, says our boss with an evil glint in her eye. “Team Ninja-Dragon is integrating their latest sprint. The Server codebase is frozen. You won’t be able to add any more functionality on that component.” . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/cost-efficent/#the-new-requirements-hit",
    "relUrl": "/database-blob/cost-efficent/#the-new-requirements-hit"
  },"26": {
    "doc": "(Adding Requirements) A more cost efficent solution",
    "title": "Updated system components",
    "content": "So we have to implement data cleanup without adding functionality to the Server. This means we need to create a new microservice, the Storage Cleaner. It will need to be able to read from the Database and Blob Store to find orphaned files, then delete them from the Blob Store. It will likely be triggered periodically, perhaps by a cloudwatch alarm; however, at large enough scale it may stay on permanently. The component diagram looks like this: . Blob StoreBlob ReadBlob WriteDatabaseMetadata ReadMetadata WriteStorage CleanersTime triggered activationServersCreate or Update Profile (userId)Read Profile (userId)usesusesdeletesusesusesusesuses We have two main design considerations at this point: . | We will have to plan for more than one Storage Cleaner to be active simultaneously. They could be run in a replica set, or delays could cause triggered instances to overlap. | We will need to ensure that the behavior of Storage Cleaner doesn’t break the invariants we tested previously. | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/cost-efficent/#updated-system-components",
    "relUrl": "/database-blob/cost-efficent/#updated-system-components"
  },"27": {
    "doc": "(Adding Requirements) A more cost efficent solution",
    "title": "A formal definition of success",
    "content": "Before starting work, it’s good to understand the definition of success. Because of our previous modeling work, we can now state it formally. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ---------------------------- MODULE success ---------------------------- NoOrphanFiles == \\* There does not exist a key ~\\E k \\in UUIDS: \\* That is in the block store /\\ blobStoreState[k] # \"UNSET\" \\* And not in database /\\ \\A u \\in USERIDS: databaseState[u].imageId # k AlwaysNoOrphanFiles == []NoOrphanFiles \\* At some point in the future there will be no orphan files \\* If it's true ever, it is True EventuallyNoOrphanFiles == &lt;&gt;NoOrphanFiles \\* Always, at some point in the future, there will be no orphan files \\* This is how we test eventual consistency. It can't just happen once \\* It must always happen AlwaysEventuallyNoOrphanFiles == []EventuallyNoOrphanFiles ============================================================================= . Ideally, we’d like to never have an orphan file. Let’s test that really quick. | Next Section | . AlwaysNoOrphanFiles is violated. | 1. Initial predicate . | blobStoreState . | i2 . | : UNSET | . | i1 . | : UNSET | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: UNSET | imageId: UNSET | . | . | operations : | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | state: waiting | userId: UNSET | image: UNSET | . | s1 . | metadata: UNSET | imageId: UNSET | state: waiting | userId: UNSET | image: UNSET | . | . | . | 2. ServerStartWrite . | blobStoreState . | i2 . | : UNSET | . | i1 . | : UNSET | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | state: waiting | userId: UNSET | image: UNSET | . | s1 . | metadata: m1 | imageId: UNSET | state: started_write | userId: ui1 | image: u1 | . | . | . | 3. ServerWriteBlob All it takes to fail is a blob to be written . | blobStoreState . | i2 . | : UNSET | . | i1 . | : u1 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | state: waiting | userId: UNSET | image: UNSET | . | s1 . | metadata: m1 | imageId: i1 | state: wrote_blob | userId: ui1 | image: u1 | . | . | . | . Failing on the first write sounds like a bad success criteria. Instead we’ll go with AlwaysEventuallyNoOrphanFiles as our definition of success. | Next: (Implementing New Requirements) A naive update | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/cost-efficent/#a-formal-definition-of-success",
    "relUrl": "/database-blob/cost-efficent/#a-formal-definition-of-success"
  },"28": {
    "doc": "(Implementing New Requirements) A naive update",
    "title": "(Implementing New Requirements) A naive update",
    "content": ". | Updating the design . | Storage Cleaner Run | . | Modeling the design | Verifying the design . | Summary | . | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/storage-cleaner-naive/",
    "relUrl": "/database-blob/storage-cleaner-naive/"
  },"29": {
    "doc": "(Implementing New Requirements) A naive update",
    "title": "Updating the design",
    "content": "The Storage Cleaner is going to to query the blob store and get a batch of keys. It will then query the database in one query and find all the images that are missing a database entry. Then it will delete those unused keys using a batch API call. Storage Cleaner Run . | | Storage CleanerStorage CleanerDatabaseDatabaseBlob StoreBlob Store | Gets batch of keys | Returns batch of keys | Queries for unused keys | Returns unused keys | Batch deletes unused keys | Returns statusalt[any failure] | | Repeats from beginning ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/storage-cleaner-naive/#updating-the-design",
    "relUrl": "/database-blob/storage-cleaner-naive/#updating-the-design"
  },"30": {
    "doc": "(Implementing New Requirements) A naive update",
    "title": "Modeling the design",
    "content": "This is the first example in our modeling tasks in which the model will not match the solution 1-1. | Relaxing a constraint: While the design calls for batches, for simplicity’s sake we will model it as if the entire blob store keyset can fit into one batch. This hides the complexity of figuring out which items have already been checked and how large of a batch size to use; we can either handle these considerations in implementation or model them separately. In this model, we will need to handle new keys being added after we query for keys, as well as the deletion process failing before all key are deleted. This should also alert us to problems that may be introduced by batching. Note: This design decision is a judgment call that may or may not be correct, but it holds for the current examples. | Enhancing a constraint: Deleting from the blob store will be modeled as a one by one operation, even though it is submitted in one API call. This is because blob stores don’t provide transactions. A batch delete may happen over the course of time. | . The Storage Cleaner state diagram looks like this: . WaitingCleanerStartGetBlobKeysCleanerGetUnusedKeysCleanerFailCleanerDeletingKeysCleanerFinished Only the core additions to the spec are shown here. Click Download Code or Download PDF to see the whole thing. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ---------------------------- MODULE storagecleanernaive ---------------------------- (***************************************************************************) (* Cleaner States *) (***************************************************************************) CleanerStartGetBlobKeys(c) == LET current == cleanerStates[c] IN \\* Starts only from waiting /\\ current.state = \"waiting\" /\\ cleanerStates' = [ cleanerStates EXCEPT ![c].state = \"got_blob_keys\", \\* All keys that are set in blockstore ![c].blobKeys = {k \\in UUIDS: blobStoreState[k] # \"UNSET\"} ] /\\ UNCHANGED &lt;&lt;serverStates, databaseState, blobStoreState, operations&gt;&gt; CleanerGetUnusedKeys(c) == LET current == cleanerStates[c] IN \\* From blob keys, get unused keys from database /\\ current.state = \"got_blob_keys\" /\\ cleanerStates' = [ cleanerStates EXCEPT ![c].state = \"got_unused_keys\", ![c].unusedBlobKeys = {k \\in current.blobKeys: \\* Keys in blob keys \\A u \\in USERIDS: \\* That are not in the database databaseState[u].imageId # k} ] /\\ UNCHANGED &lt;&lt;serverStates, databaseState, blobStoreState, operations&gt;&gt; CleanerDeletingKeys(c) == LET current == cleanerStates[c] IN \\* When we have unused keys, keep deleting /\\ current.state \\in {\"got_unused_keys\", \"deleting_keys\"} /\\ Cardinality(current.unusedBlobKeys) # 0 /\\ \\E k \\in current.unusedBlobKeys: \\* Pick a key to delete /\\ blobStoreState' = [blobStoreState EXCEPT ![k] = \"UNSET\"] /\\ cleanerStates' = [ cleanerStates EXCEPT \\* Remove the key from set ![c].unusedBlobKeys = current.unusedBlobKeys \\ {k} ] /\\ UNCHANGED &lt;&lt;serverStates, databaseState, operations&gt;&gt; CleanerFinished(c) == LET current == cleanerStates[c] IN /\\ current.state = \"deleting_keys\" \\* When we have no more unused keys to delete, finish /\\ Cardinality(current.unusedBlobKeys) = 0 /\\ cleanerStates' = [ cleanerStates EXCEPT ![c].state = \"waiting\", ![c].blobKeys = {}, ![c].unusedBlobKeys = {} ] /\\ UNCHANGED &lt;&lt;serverStates, databaseState, blobStoreState, operations&gt;&gt; CleanerFail(c) == LET current == cleanerStates[c] IN \\* Cleaner can fail from any active state /\\ current.state \\in {\"got_blob_keys\", \"got_unused_keys\", \"deleting_keys\"} (************************************************************************) (* Failure represented by cleaner losing state. Any partial operations *) (* stay partially finished. *) (************************************************************************) /\\ cleanerStates' = [ cleanerStates EXCEPT ![c].state = \"waiting\", ![c].blobKeys = {}, ![c].unusedBlobKeys = {} ] /\\ UNCHANGED &lt;&lt;serverStates, databaseState, blobStoreState, operations&gt;&gt; (***************************************************************************) (* Specification / Next *) (***************************************************************************) Next == \\* For every step, we either trigger a server or cleaner to take a step \\/ \\E s \\in SERVERS: \\/ ServerStartWrite(s) \\/ ServerWriteBlob(s) \\/ ServerWriteMetadataAndReturn(s) \\/ ServerFailWrite(s) \\/ ServerStartRead(s) \\/ ServerReadMetadata(s) \\/ ServerReadMetadataAndReturnEmpty(s) \\/ ServerReadBlobAndReturn(s) \\/ \\E c \\in CLEANERS: \\* All the steps a cleaner can take \\/ CleanerStartGetBlobKeys(c) \\/ CleanerGetUnusedKeys(c) \\/ CleanerDeletingKeys(c) \\/ CleanerFinished(c) \\/ CleanerFail(c) Spec == Init /\\ [][Next]_vars (***************************************************************************) (* Invariants *) (***************************************************************************) NoOrphanFiles == \\* There does not exist a key ~\\E k \\in UUIDS: \\* That is in the block store /\\ blobStoreState[k] # \"UNSET\" \\* And not in the database /\\ \\A u \\in USERIDS: databaseState[u].imageId # k ============================================================================= . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/storage-cleaner-naive/#modeling-the-design",
    "relUrl": "/database-blob/storage-cleaner-naive/#modeling-the-design"
  },"31": {
    "doc": "(Implementing New Requirements) A naive update",
    "title": "Verifying the design",
    "content": "Let’s start small and see what happens: . CONSTANTS SERVERS = {s1} CLEANERS = {c1} . | Next Section | Download Configuration | . Invariant ConsistentReads is violated. | 1. Initial predicate . | blobStoreState . | i2 . | : UNSET | . | i1 . | : UNSET | . | . | cleanerStates . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: UNSET | imageId: UNSET | . | . | operations : | serverStates . | s1 . | metadata: UNSET | imageId: UNSET | state: waiting | userId: UNSET | image: UNSET | . | . | . | 2. ServerStartWrite . | blobStoreState . | i2 . | : UNSET | . | i1 . | : UNSET | . | . | cleanerStates . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | serverStates . | s1 . | metadata: m1 | imageId: UNSET | state: started_write | userId: ui1 | image: u1 | . | . | . | 3. ServerWriteBlob Our server wrote an image . | blobStoreState . | i2 . | : UNSET | . | i1 . | : u1 | . | . | cleanerStates . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | serverStates . | s1 . | metadata: m1 | imageId: i1 | state: wrote_blob | userId: ui1 | image: u1 | . | . | . | 4. CleanerStartGetBlobKeys Our cleaner starts . | blobStoreState . | i2 . | : UNSET | . | i1 . | : u1 | . | . | cleanerStates . | c1 . | state: got_blob_keys | blobKeys: i1 | unusedBlobKeys: | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | serverStates . | s1 . | metadata: m1 | imageId: i1 | state: wrote_blob | userId: ui1 | image: u1 | . | . | . | 5. CleanerGetUnusedKeys and notices that the written image isn't in the database . | blobStoreState . | i2 . | : UNSET | . | i1 . | : u1 | . | . | cleanerStates . | c1 . | state: got_unused_keys | blobKeys: i1 | unusedBlobKeys: i1 | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | serverStates . | s1 . | metadata: m1 | imageId: i1 | state: wrote_blob | userId: ui1 | image: u1 | . | . | . | 6. ServerWriteMetadataAndReturn The server completes the write, thinking everything's fine . | blobStoreState . | i2 . | : UNSET | . | i1 . | : u1 | . | . | cleanerStates . | c1 . | state: got_unused_keys | blobKeys: i1 | unusedBlobKeys: i1 | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: m1 | imageId: i1 | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | serverStates . | s1 . | metadata: UNSET | imageId: UNSET | state: waiting | userId: UNSET | image: UNSET | . | . | . | 7. ServerStartRead A read starts for the same user . | blobStoreState . | i2 . | : UNSET | . | i1 . | : u1 | . | . | cleanerStates . | c1 . | state: got_unused_keys | blobKeys: i1 | unusedBlobKeys: i1 | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: m1 | imageId: i1 | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | serverStates . | s1 . | metadata: UNSET | imageId: UNSET | state: started_read | userId: ui1 | image: UNSET | . | . | . | 8. ServerReadMetadata . | blobStoreState . | i2 . | : UNSET | . | i1 . | : u1 | . | . | cleanerStates . | c1 . | state: got_unused_keys | blobKeys: i1 | unusedBlobKeys: i1 | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: m1 | imageId: i1 | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | serverStates . | s1 . | metadata: m1 | imageId: i1 | state: read_metadata | userId: ui1 | image: UNSET | . | . | . | 9. CleanerDeletingKeys But oh no, the cleaner deleted the key . | blobStoreState . | i2 . | : UNSET | . | i1 . | : UNSET | . | . | cleanerStates . | c1 . | state: got_unused_keys | blobKeys: i1 | unusedBlobKeys: | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: m1 | imageId: i1 | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | serverStates . | s1 . | metadata: m1 | imageId: i1 | state: read_metadata | userId: ui1 | image: UNSET | . | . | . | 10. ServerReadBlobAndReturn Leading to a corrupted read . | blobStoreState . | i2 . | : UNSET | . | i1 . | : UNSET | . | . | cleanerStates . | c1 . | state: got_unused_keys | blobKeys: i1 | unusedBlobKeys: | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: m1 | imageId: i1 | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | metadata : m1 | userId : ui1 | image : UNSET | type : READ | . | . | serverStates . | s1 . | metadata: UNSET | imageId: UNSET | state: waiting | userId: UNSET | image: UNSET | . | . | . | . Let’s try it again with two servers and two cleaners to see if we get different behavior. CONSTANTS SERVERS = {s1, s2} CLEANERS = {c1, c2} . | Next Section | Download Configuration | . Same behavior. Invariant ConsistentReads is violated. | 1. Initial predicate . | blobStoreState . | i2 . | : UNSET | . | i1 . | : UNSET | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: UNSET | imageId: UNSET | . | . | operations : | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | state: waiting | userId: UNSET | image: UNSET | . | s1 . | metadata: UNSET | imageId: UNSET | state: waiting | userId: UNSET | image: UNSET | . | . | . | 2. ServerStartWrite . | blobStoreState . | i2 . | : UNSET | . | i1 . | : UNSET | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | state: waiting | userId: UNSET | image: UNSET | . | s1 . | metadata: m1 | imageId: UNSET | state: started_write | userId: ui1 | image: u1 | . | . | . | 3. ServerWriteBlob . | blobStoreState . | i2 . | : UNSET | . | i1 . | : u1 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | state: waiting | userId: UNSET | image: UNSET | . | s1 . | metadata: m1 | imageId: i1 | state: wrote_blob | userId: ui1 | image: u1 | . | . | . | 4. ServerStartRead . | blobStoreState . | i2 . | : UNSET | . | i1 . | : u1 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: waiting | blobKeys: | unusedBlobKeys: | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | state: started_read | userId: ui1 | image: UNSET | . | s1 . | metadata: m1 | imageId: i1 | state: wrote_blob | userId: ui1 | image: u1 | . | . | . | 5. CleanerStartGetBlobKeys . | blobStoreState . | i2 . | : UNSET | . | i1 . | : u1 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: got_blob_keys | blobKeys: i1 | unusedBlobKeys: | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | state: started_read | userId: ui1 | image: UNSET | . | s1 . | metadata: m1 | imageId: i1 | state: wrote_blob | userId: ui1 | image: u1 | . | . | . | 6. CleanerGetUnusedKeys . | blobStoreState . | i2 . | : UNSET | . | i1 . | : u1 | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: got_unused_keys | blobKeys: i1 | unusedBlobKeys: i1 | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | state: started_read | userId: ui1 | image: UNSET | . | s1 . | metadata: m1 | imageId: i1 | state: wrote_blob | userId: ui1 | image: u1 | . | . | . | 7. CleanerDeletingKeys . | blobStoreState . | i2 . | : UNSET | . | i1 . | : UNSET | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: got_unused_keys | blobKeys: i1 | unusedBlobKeys: | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: UNSET | imageId: UNSET | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | state: started_read | userId: ui1 | image: UNSET | . | s1 . | metadata: m1 | imageId: i1 | state: wrote_blob | userId: ui1 | image: u1 | . | . | . | 8. ServerWriteMetadataAndReturn . | blobStoreState . | i2 . | : UNSET | . | i1 . | : UNSET | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: got_unused_keys | blobKeys: i1 | unusedBlobKeys: | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: m1 | imageId: i1 | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | state: started_read | userId: ui1 | image: UNSET | . | s1 . | metadata: UNSET | imageId: UNSET | state: waiting | userId: UNSET | image: UNSET | . | . | . | 9. ServerReadMetadata . | blobStoreState . | i2 . | : UNSET | . | i1 . | : UNSET | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: got_unused_keys | blobKeys: i1 | unusedBlobKeys: | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: m1 | imageId: i1 | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | serverStates . | s2 . | metadata: m1 | imageId: i1 | state: read_metadata | userId: ui1 | image: UNSET | . | s1 . | metadata: UNSET | imageId: UNSET | state: waiting | userId: UNSET | image: UNSET | . | . | . | 10. ServerReadBlobAndReturn Same corrupted read . | blobStoreState . | i2 . | : UNSET | . | i1 . | : UNSET | . | . | cleanerStates . | c2 . | state: waiting | blobKeys: | unusedBlobKeys: | . | c1 . | state: got_unused_keys | blobKeys: i1 | unusedBlobKeys: | . | . | databaseState . | ui3 . | metadata: UNSET | imageId: UNSET | . | ui2 . | metadata: UNSET | imageId: UNSET | . | ui1 . | metadata: m1 | imageId: i1 | . | . | operations . | . | metadata : m1 | userId : ui1 | image : u1 | type : WRITE | . | . | metadata : m1 | userId : ui1 | image : UNSET | type : READ | . | . | serverStates . | s2 . | metadata: UNSET | imageId: UNSET | state: waiting | userId: UNSET | image: UNSET | . | s1 . | metadata: UNSET | imageId: UNSET | state: waiting | userId: UNSET | image: UNSET | . | . | . | . Adding more servers and cleaners didn’t change the failure mode. We’ve likely hit upon the essential failure of this design. Summary . Clearly this solution isn’t going to work as is. It can delete images that were part of records being created at that moment. Normal cleanup systems don’t do that; normally they wait a little while… . | Next: (Implementing New Requirements) Significant improvement | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/storage-cleaner-naive/#verifying-the-design",
    "relUrl": "/database-blob/storage-cleaner-naive/#verifying-the-design"
  },"32": {
    "doc": "(Progressive Refinement) An improved solution",
    "title": "(Progressive Refinement) An improved solution",
    "content": ". | Refining the design . | Write Profile | Read Profile | . | Updating our model | Checking our improved design . | Starting small | Testing multiple servers | Summary | . | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/improved/",
    "relUrl": "/database-blob/improved/"
  },"33": {
    "doc": "(Progressive Refinement) An improved solution",
    "title": "Refining the design",
    "content": "Okay, so the big problem seems to be that the database is written before the blob store. This allows records to be read before they are ready. It also allows the system to fail in a state in which records that should not be readable are readable. Let’s update our design such that: . | The blob store is written before the database. | If the metadata isn’t present in the database, the server returns an empty record. | . This should fix both of the problems we saw before. Write Profile . | | ClientClientServerServerDatabaseDatabaseBlob StoreBlob Store | Submits request | Writes/overwrites blob, with userId as key | Returns status | Writes metadata with userId as key | Returns statusalt[any failure] | Returns fail / timeout | Returns successRead Profile . | | ClientClientServerServerDatabaseDatabaseBlob StoreBlob Store | Submits request | Reads metadata with userId as key | Returns statusalt[metadata not present in database] | Returns empty record | Reads blob, with userId as key | Returns statusalt[any unhandled failure] | Returns fail / timeout | Returns success ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/improved/#refining-the-design",
    "relUrl": "/database-blob/improved/#refining-the-design"
  },"34": {
    "doc": "(Progressive Refinement) An improved solution",
    "title": "Updating our model",
    "content": "We can refine our existing model to implement this behavior. First we update the state machine: . WaitingStartWriteWriteBlobFailWriteWriteMetadataAndReturnStartReadReadMetadataReadMetadataAndReturnEmptyReadBlobAndReturn Then we update the formal specification. Note: Comments have changed to reflect the narrative. See the previous page for more comprehensive comments. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ---------------------------- MODULE improved ---------------------------- EXTENDS Naturals, Sequences CONSTANTS USERIDS, SERVERS, METADATAS, IMAGES VARIABLES databaseState, blobStoreState, serverStates, operations vars == &lt;&lt;databaseState, blobStoreState, serverStates, operations&gt;&gt; (***************************************************************************) (* Strong Typing *) (***************************************************************************) UserIdVal == USERIDS \\union {\"UNSET\"} MetadataVal == METADATAS \\union {\"UNSET\"} ImageVal == IMAGES \\union {\"UNSET\"} (***************************************************************************) (* Describes all possible states a server can be in. *) (***************************************************************************) ServerStateVal == [ state: { \\* current: \"waiting\", \\* next: StartWrite or StartRead \\* after: StartWrite \"started_write\", \\* next: WriteBlob or FailWrite \\* after: WriteBlob \"wrote_blob\", \\* next: WriteMetadataAndReturn or FailWrite \\* after: StartRead \"started_read\", \\* next: ReadMetadata \\* after: ReadMetadata, ReadMetadataAndReturnEmpty \"read_metadata\" \\* next: ReadBlobAndReturn }, userId: UserIdVal, metadata: MetadataVal, image: ImageVal ] OperationValue == [type: {\"READ\", \"WRITE\"}, userId: UserIdVal, metadata: MetadataVal, image:ImageVal] TypeOk == /\\ databaseState \\in [USERIDS -&gt; MetadataVal] /\\ blobStoreState \\in [USERIDS -&gt; ImageVal] /\\ serverStates \\in [SERVERS -&gt; ServerStateVal] /\\ operations \\in Seq(OperationValue) Init == /\\ databaseState = [u \\in USERIDS |-&gt; \"UNSET\"] /\\ blobStoreState = [u \\in USERIDS |-&gt; \"UNSET\"] /\\ serverStates = [s \\in SERVERS |-&gt; [state |-&gt; \"waiting\", userId |-&gt; \"UNSET\", metadata |-&gt; \"UNSET\", image |-&gt; \"UNSET\" ]] /\\ operations = &lt;&lt;&gt;&gt; (***************************************************************************) (* State Machine: All of the states are functions of s (server), because *) (* the only actively modeled actors in this system are our servers, but *) (* there can be multiple working simultaneously. *) (***************************************************************************) (***************************************************************************) (* Writes *) (***************************************************************************) StartWrite(s) == /\\ serverStates[s].state = \"waiting\" /\\ \\E u \\in USERIDS, m \\in METADATAS, i \\in IMAGES: /\\ serverStates' = [serverStates EXCEPT ![s].state =\"started_write\", \\* Set values for the upcoming write ![s].userId = u, ![s].metadata = m, ![s].image = i] \\* Record the write for observability /\\ operations' = Append(operations, [ type |-&gt; \"WRITE\", userId |-&gt; u, metadata |-&gt; m, image |-&gt; i ]) /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; WriteBlob(s) == LET currentState == serverStates[s] IN /\\ currentState.state = \"started_write\" /\\ blobStoreState' = [blobStoreState EXCEPT ![currentState.userId] = currentState.image ] /\\ serverStates' = [serverStates EXCEPT ![s].state =\"wrote_blob\"] /\\ UNCHANGED &lt;&lt;databaseState, operations&gt;&gt; \\* Writing the database is now the last part of a write operation WriteMetadataAndReturn(s) == LET currentState == serverStates[s] IN /\\ currentState.state = \"wrote_blob\" /\\ databaseState' = [databaseState EXCEPT ![currentState.userId] = currentState.metadata] /\\ serverStates' = [serverStates EXCEPT ![s].state =\"waiting\"] /\\ UNCHANGED &lt;&lt;blobStoreState, operations&gt;&gt; FailWrite(s) == /\\ serverStates[s].state \\in {\"started_write\", \"wrote_blob\"} /\\ serverStates' = [serverStates EXCEPT ![s].state =\"waiting\", ![s].userId =\"UNSET\", ![s].metadata = \"UNSET\", ![s].image = \"UNSET\"] /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState, operations&gt;&gt; (***************************************************************************) (* Reads *) (***************************************************************************) StartRead(s) == \\* Reading only starts when a server is waiting /\\ serverStates[s].state = \"waiting\" /\\ \\E u \\in USERIDS: serverStates' = [serverStates EXCEPT ![s].state =\"started_read\", ![s].userId =u] /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; /\\ UNCHANGED operations \\* If database record is present ReadMetadata(s) == LET currentState == serverStates[s] IN /\\ currentState.state = \"started_read\" \\* Represents reading the metadata while the database record is set /\\ databaseState[currentState.userId] # \"UNSET\" /\\ serverStates' = [serverStates EXCEPT ![s].state =\"read_metadata\", ![s].metadata = databaseState[currentState.userId]] /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; /\\ UNCHANGED operations \\* If database record is not present ReadMetadataAndReturnEmpty(s) == LET currentState == serverStates[s] IN /\\ currentState.state = \"started_read\" \\* Represents reading the metadata while the database record is unset /\\ databaseState[currentState.userId] = \"UNSET\" /\\ serverStates' = [serverStates EXCEPT ![s].state =\"waiting\"] /\\ operations' = Append(operations, (***********************************************) (* Returns an empty record *) (***********************************************) [ type |-&gt; \"READ\", userId |-&gt; currentState.userId, metadata |-&gt; \"UNSET\", image |-&gt; \"UNSET\" ]) /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; ReadBlobAndReturn(s) == LET currentState == serverStates[s] IN /\\ currentState.state = \"read_metadata\" /\\ serverStates' = [serverStates EXCEPT ![s].state =\"waiting\", ![s].image = blobStoreState[currentState.userId]] /\\ operations' = Append(operations, [ type |-&gt; \"READ\", userId |-&gt; currentState.userId, metadata |-&gt; currentState.metadata, image |-&gt; blobStoreState[currentState.userId] ]) /\\ UNCHANGED &lt;&lt;databaseState, blobStoreState&gt;&gt; (***************************************************************************) (* Specification / Next *) (***************************************************************************) Next == \\* For every step, pick a server and have it advance one state \\E s \\in SERVERS: \\/ StartWrite(s) \\/ WriteBlob(s) \\* New step \\/ WriteMetadataAndReturn(s) \\* New step \\/ FailWrite(s) \\/ StartRead(s) \\/ ReadMetadata(s) \\* New step \\/ ReadMetadataAndReturnEmpty(s) \\* New step \\/ ReadBlobAndReturn(s) Spec == Init /\\ [][Next]_vars (***************************************************************************) (* Invariants *) (***************************************************************************) ConsistentReads == \\* If there are no operations, they are consistent \\/ operations = &lt;&lt;&gt;&gt; \\/ \\A i \\in 1..Len(operations): \\* For every read operation LET readOp == operations[i] IN \\/ /\\ readOp.type = \"READ\" \\* There must exist a write operation /\\ \\/ \\E j \\in 1..i: LET writeOp == operations[j] IN /\\ writeOp.type = \"WRITE\" \\* With the same data /\\ readOp.userId = writeOp.userId /\\ readOp.metadata = writeOp.metadata /\\ readOp.image = writeOp.image \\/ \\* Ignore unset reads /\\ readOp.metadata = \"UNSET\" /\\ readOp.image = \"UNSET\" \\/ readOp.type = \"WRITE\" \\* Ignore writes (***************************************************************************) (* This is used for model checker configuration so the simulation doesn't *) (* go on forever. *) (***************************************************************************) StopAfter3Operations == Len(operations) &lt;= 3 ============================================================================= . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/improved/#updating-our-model",
    "relUrl": "/database-blob/improved/#updating-our-model"
  },"35": {
    "doc": "(Progressive Refinement) An improved solution",
    "title": "Checking our improved design",
    "content": "Starting small . Let’s start with our our single server case again. | Next Section | Download Configuration | . Single server still errors. Invariant ConsistentReads is violated. | 1. Initial predicate . | blobStoreState . | u1 . | : UNSET | . | . | databaseState . | u1 . | : UNSET | . | . | operations : | serverStates . | s1 . | state: waiting | userId: UNSET | metadata: UNSET | image: UNSET | . | . | . | 2. StartWrite . | blobStoreState . | u1 . | : UNSET | . | . | databaseState . | u1 . | : UNSET | . | . | operations . | . | userId : u1 | metadata : m2 | image : i1 | type : WRITE | . | . | serverStates . | s1 . | state: started_write | userId: u1 | metadata: m2 | image: i1 | . | . | . | 3. WriteBlob . | blobStoreState . | u1 . | : i1 | . | . | databaseState . | u1 . | : UNSET | . | . | operations . | . | userId : u1 | metadata : m2 | image : i1 | type : WRITE | . | . | serverStates . | s1 . | state: wrote_blob | userId: u1 | metadata: m2 | image: i1 | . | . | . | 4. WriteMetadataAndReturn Successfully completed write: metadata m2, image i1 . | blobStoreState . | u1 . | : i1 | . | . | databaseState . | u1 . | : m2 | . | . | operations . | . | userId : u1 | metadata : m2 | image : i1 | type : WRITE | . | . | serverStates . | s1 . | state: waiting | userId: u1 | metadata: m2 | image: i1 | . | . | . | 5. StartWrite . | blobStoreState . | u1 . | : i1 | . | . | databaseState . | u1 . | : m2 | . | . | operations . | . | userId : u1 | metadata : m2 | image : i1 | type : WRITE | . | . | userId : u1 | metadata : m1 | image : i2 | type : WRITE | . | . | serverStates . | s1 . | state: started_write | userId: u1 | metadata: m1 | image: i2 | . | . | . | 6. WriteBlob . | blobStoreState . | u1 . | : i2 | . | . | databaseState . | u1 . | : m2 | . | . | operations . | . | userId : u1 | metadata : m2 | image : i1 | type : WRITE | . | . | userId : u1 | metadata : m1 | image : i2 | type : WRITE | . | . | serverStates . | s1 . | state: wrote_blob | userId: u1 | metadata: m1 | image: i2 | . | . | . | 7. FailWrite Failed write after writing blob. Inconsistent data: metadata m2, image i2 . | blobStoreState . | u1 . | : i2 | . | . | databaseState . | u1 . | : m2 | . | . | operations . | . | userId : u1 | metadata : m2 | image : i1 | type : WRITE | . | . | userId : u1 | metadata : m1 | image : i2 | type : WRITE | . | . | serverStates . | s1 . | state: waiting | userId: UNSET | metadata: UNSET | image: UNSET | . | . | . | 8. StartRead . | blobStoreState . | u1 . | : i2 | . | . | databaseState . | u1 . | : m2 | . | . | operations . | . | userId : u1 | metadata : m2 | image : i1 | type : WRITE | . | . | userId : u1 | metadata : m1 | image : i2 | type : WRITE | . | . | serverStates . | s1 . | state: started_read | userId: u1 | metadata: UNSET | image: UNSET | . | . | . | 9. ReadMetadata . | blobStoreState . | u1 . | : i2 | . | . | databaseState . | u1 . | : m2 | . | . | operations . | . | userId : u1 | metadata : m2 | image : i1 | type : WRITE | . | . | userId : u1 | metadata : m1 | image : i2 | type : WRITE | . | . | serverStates . | s1 . | state: read_metadata | userId: u1 | metadata: m2 | image: UNSET | . | . | . | 10. ReadBlobAndReturn Return inconsistent data: metadata m2, image i2 . | blobStoreState . | u1 . | : i2 | . | . | databaseState . | u1 . | : m2 | . | . | operations . | . | userId : u1 | metadata : m2 | image : i1 | type : WRITE | . | . | userId : u1 | metadata : m1 | image : i2 | type : WRITE | . | . | userId : u1 | metadata : m2 | image : i2 | type : READ | . | . | serverStates . | s1 . | state: waiting | userId: u1 | metadata: m2 | image: i2 | . | . | . | . We don’t have a perfectly working solution yet, but notice that the previous solution failed in 7 steps, whereas this solution failed in 10. Generally, the more steps that need to occur before failure, the more unlikely the failure—but not always. Let’s take a closer look at the steps. In this case, the single server needed to write successfully, then write unsuccessfully, then read. In the previous one, the server just needed to write unsuccessfully, then read. But once we spell it out, that doesn’t increase our confidence. Of course users are going to write multiple times, over days, so effectively all we need is a write failure for an error to occur. Testing multiple servers . It may be informative to see how multiple servers fail. | Next Section | Download Configuration | . Invariant ConsistentReads is violated. | 1. Initial predicate . | blobStoreState . | u1 . | : UNSET | . | . | databaseState . | u1 . | : UNSET | . | . | operations : | serverStates . | s2 . | state: waiting | userId: UNSET | metadata: UNSET | image: UNSET | . | s1 . | state: waiting | userId: UNSET | metadata: UNSET | image: UNSET | . | . | . | 2. StartWrite . | blobStoreState . | u1 . | : UNSET | . | . | databaseState . | u1 . | : UNSET | . | . | operations . | . | userId : u1 | metadata : m2 | image : i1 | type : WRITE | . | . | serverStates . | s2 . | state: waiting | userId: UNSET | metadata: UNSET | image: UNSET | . | s1 . | state: started_write | userId: u1 | metadata: m2 | image: i1 | . | . | . | 3. WriteBlob . | blobStoreState . | u1 . | : i1 | . | . | databaseState . | u1 . | : UNSET | . | . | operations . | . | userId : u1 | metadata : m2 | image : i1 | type : WRITE | . | . | serverStates . | s2 . | state: waiting | userId: UNSET | metadata: UNSET | image: UNSET | . | s1 . | state: wrote_blob | userId: u1 | metadata: m2 | image: i1 | . | . | . | 4. WriteMetadataAndReturn Successfully completed write: metadata m2, image i1 . | blobStoreState . | u1 . | : i1 | . | . | databaseState . | u1 . | : m2 | . | . | operations . | . | userId : u1 | metadata : m2 | image : i1 | type : WRITE | . | . | serverStates . | s2 . | state: waiting | userId: UNSET | metadata: UNSET | image: UNSET | . | s1 . | state: waiting | userId: u1 | metadata: m2 | image: i1 | . | . | . | 5. StartWrite . | blobStoreState . | u1 . | : i1 | . | . | databaseState . | u1 . | : m2 | . | . | operations . | . | userId : u1 | metadata : m2 | image : i1 | type : WRITE | . | . | userId : u1 | metadata : m1 | image : i2 | type : WRITE | . | . | serverStates . | s2 . | state: waiting | userId: UNSET | metadata: UNSET | image: UNSET | . | s1 . | state: started_write | userId: u1 | metadata: m1 | image: i2 | . | . | . | 6. WriteBlob Overwrote blob with image i2. Haven't wrote metadata . | blobStoreState . | u1 . | : i2 | . | . | databaseState . | u1 . | : m2 | . | . | operations . | . | userId : u1 | metadata : m2 | image : i1 | type : WRITE | . | . | userId : u1 | metadata : m1 | image : i2 | type : WRITE | . | . | serverStates . | s2 . | state: waiting | userId: UNSET | metadata: UNSET | image: UNSET | . | s1 . | state: wrote_blob | userId: u1 | metadata: m1 | image: i2 | . | . | . | 7. StartRead . | blobStoreState . | u1 . | : i2 | . | . | databaseState . | u1 . | : m2 | . | . | operations . | . | userId : u1 | metadata : m2 | image : i1 | type : WRITE | . | . | userId : u1 | metadata : m1 | image : i2 | type : WRITE | . | . | serverStates . | s2 . | state: started_read | userId: u1 | metadata: UNSET | image: UNSET | . | s1 . | state: wrote_blob | userId: u1 | metadata: m1 | image: i2 | . | . | . | 8. ReadMetadata . | blobStoreState . | u1 . | : i2 | . | . | databaseState . | u1 . | : m2 | . | . | operations . | . | userId : u1 | metadata : m2 | image : i1 | type : WRITE | . | . | userId : u1 | metadata : m1 | image : i2 | type : WRITE | . | . | serverStates . | s2 . | state: read_metadata | userId: u1 | metadata: m2 | image: UNSET | . | s1 . | state: wrote_blob | userId: u1 | metadata: m1 | image: i2 | . | . | . | 9. ReadBlobAndReturn Return inconsistent data: metadata m2, image i2 . | blobStoreState . | u1 . | : i2 | . | . | databaseState . | u1 . | : m2 | . | . | operations . | . | userId : u1 | metadata : m2 | image : i1 | type : WRITE | . | . | userId : u1 | metadata : m1 | image : i2 | type : WRITE | . | . | userId : u1 | metadata : m2 | image : i2 | type : READ | . | . | serverStates . | s2 . | state: waiting | userId: u1 | metadata: m2 | image: i2 | . | s1 . | state: wrote_blob | userId: u1 | metadata: m1 | image: i2 | . | . | . | . Now it fails in 9 steps rather than 6. But again, all it needs is a successful write to happen before the simultaneous read and write. The error hasn’t fundamentally changed that much. Summary . So we’ve eliminated one class of error: the kind in which the blob store is unset and returned in a read. The problem now is that the blob store and the metadata can get out of sync. This can happen because of either a failure while writing, or one server writing while another one is reading. We’re not done yet. But I have a hunch we can make it work. | Next: (Verifying Correctness) A working solution | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/improved/#checking-our-improved-design",
    "relUrl": "/database-blob/improved/#checking-our-improved-design"
  },"36": {
    "doc": "Coordinating a Database and Blob Store",
    "title": "Coordinating a Database and Blob Store",
    "content": ". | Introduction | Modeling the problem | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/",
    "relUrl": "/database-blob/"
  },"37": {
    "doc": "Coordinating a Database and Blob Store",
    "title": "Introduction",
    "content": "Let’s start with something that millions of engineers do each year: coordinating databases and blob stores (like Amazon S3, Azure Blob, GCP Cloud Storage). Why might we need to do this? . You have a site with users. You want each user to have a profile image. How do you do this? The easiest way is to store the user metadata and the image in your database. You can do this transactionally: either the metadata and the image are both stored, or neither is stored. This way you don’t have to worry about inconsistent cases where the image is stored, but the user isn’t, or the user is stored, but the image isn’t. In practice, this approach doesn’t scale easily or cheaply. Transactional databases are typically the performance bottleneck in a system, and you don’t want to take up their storage, read, and write capacity unnecessarily. What if users need to add more media beyond just a profile picture? This can quickly become an expensive prospect. Blob stores, on the other hand, are relatively cheap and highly scaleable and can easily hold as many files as you’d practically need. They also don’t consume database CPU cycles. Just one problem: they aren’t tied in with the database’s transaction coordinator. You as the programmer need to figure out an application level solution to link the database and blob stores, so when a request comes in for a user and their profile picture, you can return it. This is a simple and common distributed system, which makes it a perfect place to start. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/#introduction",
    "relUrl": "/database-blob/#introduction"
  },"38": {
    "doc": "Coordinating a Database and Blob Store",
    "title": "Modeling the problem",
    "content": "We have three components in this system that we must consider: the Database, the Blob Store and the Servers. Note we consider the Database and the Blob Store each as individual entities. If we were to look at their implementation, we would potentially see shards and replication over a number of instances. However, the designers of those products expose interfaces with particular properties that can hide this complexity. | Database: Allow ACID Transactions. The important part for us is that the full database update either will succeed or fail; we don’t need to account for a partial completion of the update. | Blob Store: All the main blob stores have Read After Write consistency. This means that as soon as a write returns successfully, all subsequent reads will return the new value. This shouldn’t be taken for granted in eventually consistent systems; it may take time after a write is completed to be sure that value will be returned in all cases. Additionally, all the blob stores are atomic on writes, meaning we don’t have to account for files being partially uploaded and left in an invalid state that clients could read. | . The Servers, however, are our responsibility. They use the read and write interfaces exposed by the data stores however our application is written to use them. Note the plural in Servers: we have to deal with the fact that multiple instances of our application are running simultaneously. We are assuming a single thread per Server, processing a single request at a time. Although in practice many threads could be on a single Server, it is logically equivalent to the case where there are multiple Servers each with one thread. We can model this with the UML Component Diagram below: . Blob StoreBlob ReadBlob WriteDatabaseMetadata ReadMetadata WriteServersCreate or Update Profile (userId)Read Profile (userId)usesusesusesuses We are implementing two interfaces with our server: Write Profile and Read Profile. | Create or Update Profile (userId): leads to one of the following post conditions: . | The database contains metadata about the profile. The blob store contains the profile image. There is some way to link the two. | The API call fails in such a way that both datastores are left in a consistent state that does not disrupt Read Profile or prevent a successful retry. | . | Read Profile (userId): For a given profile, both the metadata and the profile image are returned. It is unacceptable to return one without the other. Returning None is acceptable when a good result is impossible, but unacceptable otherwise. | . Note that we are not modelling the clients of these APIs. However, the consistency guarantees set out above would allow someone else to do so. | Next: (Start of Process) The naive first draft | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/database-blob/#modeling-the-problem",
    "relUrl": "/database-blob/#modeling-the-problem"
  },"39": {
    "doc": "Working cache invalidation",
    "title": "Working cache invalidation",
    "content": ". | Designing a working solution . | Working cache invalidation | . | Modeling | Verification | Retrospective | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/working-cache-invalidation/",
    "relUrl": "/caching/working-cache-invalidation/"
  },"40": {
    "doc": "Working cache invalidation",
    "title": "Designing a working solution",
    "content": "We need to account for inflight cache fill requests. Let’s remind ourselves what we know about them: . | They are triggered in response to a read request. | They happen synchronously or at least near realtime so a response can be sent back to the client. | . From a design perspective, then, we can set certain parameters: . | No key corresponding to an inflight request will be evicted, as it is needed to respond to an active request. Therefore the key belongs in the cache. | We should process invalidation messages for keys corresponding to inflight requests. We know the key will be added to the cache soon, so it may be relevant. | . Working cache invalidation . | | WriterWriterDatabaseDatabaseCache Invalidation QueueCache Invalidation QueueCacheCache | Updates data | Adds updated key andversioned data to queue | Polls queue | Returns invalidation itemalt[Key not in Cache] | | Does nothingalt[Key in cache fill requests] | | Adds key and data frominvalidation message to cachealt[Key in Cache] | | Does nothingalt[Cache data olderthan invalidation] | | Replaces old versionwith data from message ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/working-cache-invalidation/#designing-a-working-solution",
    "relUrl": "/caching/working-cache-invalidation/#designing-a-working-solution"
  },"41": {
    "doc": "Working cache invalidation",
    "title": "Modeling",
    "content": "We do have one modeling consideration. We mentioned that keys could be evicted at any time, which accounted for server crashes as well as caching policy. We can model a server crash as a cache fill failure followed by an eviction. Therefore, we can already account for this scenario without needing to extend our current model. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ----------------------------- MODULE cacheinvalidationv3 ----------------------------- CacheHandleInvalidationMessage == /\\ \\E message \\in invalidationQueue: /\\ \\/ /\\ cache[message.key] \\in CacheHit \\* Message needs to be newer than the cache /\\ cache[message.key].version &lt; message.version \\* Or not in the cache, but with a pending fill request \\/ /\\ cache[message.key] \\in CacheMiss /\\ cacheFillStates[message.key].state # \"inactive\" \\* Update item in cache /\\ cache' = [cache EXCEPT ![message.key] = [ type |-&gt; \"hit\", \\* Update to version in invalidation message version |-&gt; message.version ]] \\* Remove message from queue because handled /\\ invalidationQueue' = invalidationQueue \\ {message} /\\ UNCHANGED &lt;&lt;cacheFillStates, database, counter&gt;&gt; CacheIgnoreInvalidationMessage == /\\ \\E message \\in invalidationQueue: \\* Dequeue invalidation queue in any order \\* Ignore invalidation messages for messages not in cache /\\ \\/ /\\ cache[message.key] \\in CacheMiss \\* and a fill is not occurring /\\ cacheFillStates[message.key].state = \"inactive\" \\* Or when the cache already has the same or larger version \\/ /\\ cache[message.key] \\notin CacheMiss /\\ cache[message.key].version &gt;= message.version \\* Remove message from queue to ignore /\\ invalidationQueue' = invalidationQueue \\ {message} /\\ counter' = counter + 1 /\\ UNCHANGED &lt;&lt;cacheFillStates, database, cache&gt;&gt; CacheEvict(k) == /\\ cache[k] \\in CacheHit \\* A key with a pending request will not be evicted /\\ cacheFillStates[k].state = \"inactive\" /\\ cache' = [cache EXCEPT ![k] = [type |-&gt; \"miss\"]] /\\ counter' = counter + 1 /\\ UNCHANGED &lt;&lt;database, cacheFillStates, invalidationQueue&gt;&gt; ============================================================================= \\* Modification History \\* Last modified Wed Jun 15 13:08:32 MST 2022 by elliotswart \\* Created Tue Jun 14 20:36:02 MST 2022 by elliotswart . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/working-cache-invalidation/#modeling",
    "relUrl": "/caching/working-cache-invalidation/#modeling"
  },"42": {
    "doc": "Working cache invalidation",
    "title": "Verification",
    "content": "We run a larger test on this model. SPECIFICATION Spec CONSTANTS KEYS = {k1, k2} INVARIANT TypeOk PROPERTY AlwaysEventuallyDatabaseAndCacheConsistent CONSTRAINT DatabaseRecordsDoNotExceedMaxVersion . And it passes: . | Next Section | Download Configuration | . | State Name | Total States | Distinct States | . | Init | 1 | 1 | . | DatabaseUpdate | 50885754 | 4832447 | . | CacheStartReadThroughFill | 5265822 | 2651080 | . | DatabaseRespondToCacheFill | 11230605 | 5633443 | . | CacheCompleteFill | 13332315 | 4578998 | . | CacheIgnoreFill | 11931301 | 0 | . | CacheHandleInvalidationMessage | 73569738 | 5147961 | . | CacheIgnoreInvalidationMessage | 53779966 | 1995678 | . | CacheEvict | 10224889 | 1057390 | . We trust this result more because we have seen earlier versions of the system fail in rational ways against the same invariants and properties. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/working-cache-invalidation/#verification",
    "relUrl": "/caching/working-cache-invalidation/#verification"
  },"43": {
    "doc": "Working cache invalidation",
    "title": "Retrospective",
    "content": "There are a couple of key modeling takeaways from this series: . | Implementing another module: We used the exact same cacherequirements module for the 4 iterations of our caches. Not only does this follow do not repeat yourself (DRY) principals, but it also shows how we can maintain requirement consistency across many implementations. While this was a simple example, it is possible to import much more subtle requirement modules such as “linearizable” and map them into your specific module. They can then provide Invariants and Properties that let you know if your solution is working correctly. | Compactness of specifications: The entire set of requirements and common data properties was 50 lines long with extensive comments. The final working cache specification was 220 lines long. This modeled and tested reasonably sophisticated cache invalidation logic. This is much less verbose and time-consuming than implementing the logic and tests in a standard programming languages. This is part of why formal modeling is a great next step after whiteboarding or diagramming. The output is small enough to be read, critiqued and tested in one sitting. | Fairness: While it can be tempting just to write WF_vars(Next) as part of your specification, you often need to break it up further. If we were to write that, evictions would HAVE to occur, or worse Database updates would HAVE to happen, meaning that we would not necessarily be able to catch temporal property violations. Without fairness, the cache could simply never update, which would break eventual consistency. That circumstance is something we have to prevent in code and/or with monitoring solutions. We can represent that effort as WF_vars(CacheFairness), providing fairness to all operations that MUST eventually occur. | . So where do we go from here? There are two options. The next (and final) page in this series is about replicating the bug described by the Facebook paper. | Next: Reproducing Facebook’s bug | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/working-cache-invalidation/#retrospective",
    "relUrl": "/caching/working-cache-invalidation/#retrospective"
  },"44": {
    "doc": "A naive model of caching",
    "title": "A naive model of caching",
    "content": ". | Designing a naive cache | Success criteria | Modeling the cache | Verifying the cache | Summary | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/naive-model/",
    "relUrl": "/caching/naive-model/"
  },"45": {
    "doc": "A naive model of caching",
    "title": "Designing a naive cache",
    "content": "In addition to the parameters described previously, we will make a few design decisions: . | Caches will only be filled during reads (as pictured below). | We will not worry about cache invalidation. | We will only model a single cache. We are assuming it is either one server, or one consistent replica set. Note: While there are generally many cache servers, the complexity of cache invalidation (at this level) can be modeled with just one cache and one database. | . So essentially the only operation we are implementing is the read described in the last section. | | Web ServerWeb ServerCacheCacheDatabaseDatabase | Requests queryalt[cache miss] | Requests query result | Returns data | | Caches query result | Returns data Now we have all our design parameters. Let’s model! . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/naive-model/#designing-a-naive-cache",
    "relUrl": "/caching/naive-model/#designing-a-naive-cache"
  },"46": {
    "doc": "A naive model of caching",
    "title": "Success criteria",
    "content": "Because caches are so well understood, we can come up with our success criteria before modeling. Note how it defines certain key data models, so success can be defined. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ------------------------- MODULE cacherequirements ------------------------- EXTENDS Naturals CONSTANTS KEYS \\* The full set of keys in the database VARIABLES database, \\* database[key] = DataVersion cache \\* cache[key] = CacheValue \\* The maximum number of versions a key can have in this model MaxVersions == 4 \\* Data versions are scoped to an individual key DataVersion == Nat \\* Represents the absence of a value in a cache CacheMiss == [type: {\"miss\"}] \\* Represents the presence of a value in a cache, as well as the value CacheHit == [type : {\"hit\"}, version: DataVersion] DatabaseAndCacheConsistent == \\A k \\in KEYS: \\* If the key is in cache \\/ /\\ cache[k] \\in CacheHit \\* It should be the same version as the database /\\ cache[k].version = database[k] \\* A cache miss is also okay. A cache won't hold everything \\/ cache[k] \\in CacheMiss \\* This means that at some point, the database and cache are consistent. \\* It is important to note that this is not eventual consistency. \\* This only says it needs to be eventually consistent once. EventuallyDatabaseAndCacheConsistent == &lt;&gt;DatabaseAndCacheConsistent \\* The cache must be always eventually consistent. AlwaysEventuallyDatabaseAndCacheConsistent == []EventuallyDatabaseAndCacheConsistent \\* Used as a state constraint to prevent unbounded testing \\* with infinite versions. DatabaseRecordsDoNotExceedMaxVersion == \\A k \\in KEYS: database[k] &lt; MaxVersions ============================================================================= \\* Modification History \\* Last modified Tue Jun 14 22:44:55 MST 2022 by elliotswart \\* Created Tue Jun 14 21:36:26 MST 2022 by elliotswart . Note: the requirements are their own TLA+ module. In all our models, we will import it. We can think of it a bit like an interface in a standard programming language. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/naive-model/#success-criteria",
    "relUrl": "/caching/naive-model/#success-criteria"
  },"47": {
    "doc": "A naive model of caching",
    "title": "Modeling the cache",
    "content": "We model the cache, importing the cache requirements module rather than redefining the expressions it provides. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ----------------------------- MODULE naivecache ----------------------------- EXTENDS Naturals CONSTANTS KEYS \\* The full set of keys in the database VARIABLES database, \\* database[key] = DataVersion cache \\* cache[key] = CacheValue \\* Imports cache requirements to test against INSTANCE cacherequirements vars == &lt;&lt;database, cache&gt;&gt; \\* A cache can hold a hit or a miss for any given key CacheValue == CacheMiss \\union CacheHit TypeOk == \\* database is a mapping of keys to a data version /\\ database \\in [KEYS -&gt; DataVersion] \\* cache is a mapping of kets to a cache value /\\ cache \\in [KEYS -&gt; CacheValue] Init == \\* All keys in the database are initialized to their first version /\\ database = [k \\in KEYS |-&gt; 0] \\* All keys in the cache are initialized to a miss, i.e. no data in cache /\\ cache = [k \\in KEYS |-&gt; [type |-&gt; \"miss\"]] DatabaseUpdate(k) == \\* The version of that key is incremented, representing a write /\\ database' = [database EXCEPT ![k] = database[k] + 1] /\\ UNCHANGED cache CacheRead(k) == \\* The data is already in the cache /\\ cache[k] \\in CacheHit \\* So the cache remains the same /\\ UNCHANGED cache /\\ UNCHANGED database CacheReadThrough(k) == \\* The data is not in the cache /\\ cache[k] \\in CacheMiss \\* So it is read from the database /\\ cache' = [cache EXCEPT ![k] = [ \\* Cache value is now a hit type |-&gt; \"hit\", \\* Set to whatever version is in database version |-&gt; database[k] ] ] /\\ UNCHANGED database CacheEvict(k) == \\* The data is in cache, so can be evicted /\\ cache[k] \\in CacheHit \\* cache[k]is turned into a miss /\\ cache' = [cache EXCEPT ![k] = [type |-&gt; \"miss\"]] /\\ UNCHANGED database (***************************************************************************) (* Fairness: Normally no operation is guaranteed to happen; it just may. *) (* However, that means that the cache could just stop reading forever. *) (* And so it would never update. Now that doesn't seem reasonable. *) (***************************************************************************) \\* The cache will always be able to... CacheFairness == \\E k \\in KEYS: \\/ CacheRead(k) \\* Read \\/ CacheReadThrough(k) \\* Write \\* CacheEvict(k) is not here, because CacheEvict is something that \\* may happen. It is not guaranteed (***************************************************************************) (* Specification *) (***************************************************************************) Next == \\E k \\in KEYS: \\* Database states \\/ DatabaseUpdate(k) \\* Cache states \\/ CacheRead(k) \\/ CacheReadThrough(k) \\/ CacheEvict(k) \\* Cache fairness is included as part of the specification of system behavior. \\* This is just how the system works. Spec == Init /\\ [][Next]_vars /\\ WF_vars(CacheFairness) ============================================================================= \\* Modification History \\* Last modified Tue Jun 14 22:51:06 MST 2022 by elliotswart \\* Created Tue Jun 14 20:36:02 MST 2022 by elliotswart . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/naive-model/#modeling-the-cache",
    "relUrl": "/caching/naive-model/#modeling-the-cache"
  },"48": {
    "doc": "A naive model of caching",
    "title": "Verifying the cache",
    "content": "First let’s try setting DatabaseAndCacheConsistent as an invariant and see what happens. This says that the cache and the database must always be consistent with each other. | Next Section | . Invariant DatabaseAndCacheConsistent is violated. | 1. Initial predicate . | cache . | k1 . | type: miss | . | . | database . | k1 : 0 | . | . | 2. CacheReadThrough The cache reads through and gets version 0 of key 1 . | cache . | k1 . | type: hit | version: 0 | . | . | database . | k1 : 0 | . | . | 3. DatabaseUpdate The database updates to version 1 of key 1. No longer consistent with cache. | cache . | k1 . | type: hit | version: 0 | . | . | database . | k1 : 1 | . | . | . This is what we’d expect. The Cache and the Database are not always consistent with each other. If this passed, we should doubt the model. What if we use the eventually consistent property AlwaysEventuallyDatabaseAndCacheConsistent? We get another error. Temporal property violations are not as clear as logical ones. | Next Section | . Temporal properties were violated. | 1. Initial predicate . | cache . | k1 . | type: miss | . | . | database . | k1 : 0 | . | . | 2. CacheReadThrough The cache reads through and gets version 0 of key 1 . | cache . | k1 . | type: hit | version: 0 | . | . | database . | k1 : 0 | . | . | 3. DatabaseUpdate Database updated state . | cache . | k1 . | type: hit | version: 0 | . | . | database . | k1 : 1 | . | . | 4. DatabaseUpdate . | cache . | k1 . | type: hit | version: 0 | . | . | database . | k1 : 2 | . | . | 5. DatabaseUpdate Database updated state for the last time . | cache . | k1 . | type: hit | version: 0 | . | . | database . | k1 : 3 | . | . | Stuttering Cache could do nothing, and remained inconsistent | . Because we have no way of guaranteeing that a key will be evicted from the cache, as soon as the key is set, the cache will not change. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/naive-model/#verifying-the-cache",
    "relUrl": "/caching/naive-model/#verifying-the-cache"
  },"49": {
    "doc": "A naive model of caching",
    "title": "Summary",
    "content": "As we can see, our current model of cache is not eventually consistent with the database. We need to systematically clear the cache of outdated values. We need cache invalidation. | Next: Adding cache invalidation | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/naive-model/#summary",
    "relUrl": "/caching/naive-model/#summary"
  },"50": {
    "doc": "Adding cache invalidation",
    "title": "Adding cache invalidation",
    "content": ". | Designing an initial cache invalidation solution . | Initial cache invalidation | . | Initial cache invalidation solution . | Modeling | Verification | . | Updated cache invalidation solution . | An updated design . | Updated cache invalidation | . | Modeling | Verification | . | Summary | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/cache-invalidation/",
    "relUrl": "/caching/cache-invalidation/"
  },"51": {
    "doc": "Adding cache invalidation",
    "title": "Designing an initial cache invalidation solution",
    "content": "As we determined earlier, we need to be able to systematically evict out-of-date values from the cache. We do that with cache invalidation. Whenever the database updates a value, it put an invalidation message on a queue. The cache will process messages from that queue: if it contains the key it will evict the value, otherwise it will do nothing. Assumptions: . | Our invalidation queue does not guarantee in-order delivery. | Our invalidation queue is durable and guarantees at-least-once delivery. | . Initial cache invalidation . | | WriterWriterDatabaseDatabaseCache Invalidation QueueCache Invalidation QueueCacheCache | Updates data | Adds updated key to queue | Polls queue | Returns invalidation item | | Evicts invalidated key from queuealt[Key not in Cache] | | Does nothing ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/cache-invalidation/#designing-an-initial-cache-invalidation-solution",
    "relUrl": "/caching/cache-invalidation/#designing-an-initial-cache-invalidation-solution"
  },"52": {
    "doc": "Adding cache invalidation",
    "title": "Initial cache invalidation solution",
    "content": "Modeling . We are now dealing with multiple processes, cache fill and invalidation, that may interact. Therefore it is necessary to break the processes down into their component steps, which may be executed simultaneously. Also, for context, a Cache Fill describes the process of the Cache requesting data from the Database, the Database responding, and the Cache incorporating that data. It is now worthwhile to model the cache’s state machine. InactiveCacheStartReadThroughFillDatabaseRespondToCacheFillCacheCompleteFillCacheFailFill There is also a very simple message-handling state machine: . InvalidationMessageOnQueueCacheHandleInvalidationMessage Note that the cache requirements and the underlying data models that are checked stay the same. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ----------------------------- MODULE cacheinvalidationv1 ----------------------------- EXTENDS Naturals CONSTANTS KEYS VARIABLES database, cache, cacheFillStates, \\* cacheFillStatus[key] = Fill state invalidationQueue INSTANCE cacherequirements vars == &lt;&lt;database, cache, cacheFillStates, invalidationQueue&gt;&gt; InvalidationMessage == [key: KEYS] CacheFillState == [state: {\"inactive\", \"started\", \"respondedto\"}, version: DataVersion] CacheValue == CacheMiss \\union CacheHit TypeOk == /\\ database \\in [KEYS -&gt; DataVersion] /\\ cache \\in [KEYS -&gt; CacheValue] \\* We track the cache fill state for each key. It is a multipart process /\\ cacheFillStates \\in [KEYS -&gt; CacheFillState] \\* We model invalidationQueue as a set, because we cannot guarantee in-order delivery /\\ invalidationQueue \\in SUBSET InvalidationMessage Init == /\\ database = [k \\in KEYS |-&gt; 0] /\\ cache = [k \\in KEYS |-&gt; [type |-&gt; \"miss\"]] \\* Cache fill states start inactive /\\ cacheFillStates = [k \\in KEYS |-&gt; [ state |-&gt; \"inactive\", \\* Version set to earliest possible version version |-&gt; 0] ] \\* The invalidation queue starts empty /\\ invalidationQueue = {} DatabaseUpdate(k) == \\* The version of that key is incremented, representing a write /\\ database' = [database EXCEPT ![k] = database[k] + 1] \\* Adds invalidation message to queue. \\* We don't need to model a delay in adding message as the cache can \\* always delay handling message to similar effect. /\\ invalidationQueue' = invalidationQueue \\union {[key |-&gt; k]} /\\ UNCHANGED &lt;&lt;cache, cacheFillStates&gt;&gt; \\* Cache Fill behavior CacheStartReadThroughFill(k) == \\* Read-through only occurs when the cache is unset for that value /\\ cache[k] \\in CacheMiss \\* One cache fill request at a time /\\ cacheFillStates[k].state = \"inactive\" /\\ cacheFillStates' = [cacheFillStates EXCEPT ![k].state = \"started\"] /\\ UNCHANGED &lt;&lt;database, cache, invalidationQueue&gt;&gt; \\* This is the moment the database provides a value for cache fill DatabaseRespondToCacheFill(k) == /\\ cacheFillStates[k].state = \"started\" /\\ cacheFillStates' = [cacheFillStates EXCEPT ![k].state = \"respondedto\", ![k].version = database[k] ] /\\ UNCHANGED &lt;&lt;database, cache, invalidationQueue&gt;&gt; \\* Cache incorporates the data CacheCompleteFill(k) == /\\ cacheFillStates[k].state = \"respondedto\" /\\ cacheFillStates' = [cacheFillStates EXCEPT \\* Reset to 0 ![k].state = \"inactive\", ![k].version = 0 ] /\\ cache' = [cache EXCEPT ![k] = [ \\* Cache value is now a hit type |-&gt; \"hit\", \\* Set to whatever came back in response version |-&gt; cacheFillStates[k].version ] ] /\\ UNCHANGED &lt;&lt;database, invalidationQueue&gt;&gt; \\* Cache fails to fill CacheFailFill(k) == /\\ cacheFillStates[k].state = \"respondedto\" \\* Cache fill state is reset, having not filled cache /\\ cacheFillStates' = [cacheFillStates EXCEPT ![k].state = \"inactive\", ![k].version = 0 ] /\\ UNCHANGED &lt;&lt;database, cache, invalidationQueue&gt;&gt; \\* Handle invalidation message. Assume it is not taken off queue in case of \\* failure. Therefore failure modeled as CacheHandleInvalidationMessage not \\* occurring. CacheHandleInvalidationMessage == /\\ \\E message \\in invalidationQueue: \\* Dequeue invalidation queue in any order \\* Remove message from queue /\\ invalidationQueue' = invalidationQueue \\ {message} \\* Evict item from cache /\\ cache' = [cache EXCEPT ![message.key] = [type |-&gt; \"miss\"]] /\\ UNCHANGED &lt;&lt;cacheFillStates, database&gt;&gt; \\* Cache eviction model is unchanged CacheEvict(k) == /\\ cache[k] \\in CacheHit /\\ cache' = [cache EXCEPT ![k] = [type |-&gt; \"miss\"]] /\\ UNCHANGED &lt;&lt;database, cacheFillStates, invalidationQueue&gt;&gt; \\* The cache will always be able to... CacheFairness == \\E k \\in KEYS: \\* Complete the cache fill process \\/ CacheStartReadThroughFill(k) \\/ DatabaseRespondToCacheFill(k) \\* Write \\/ CacheCompleteFill(k) \\* Process invalidation messages \\/ CacheHandleInvalidationMessage (***************************************************************************) (* Specification *) (***************************************************************************) Next == \\E k \\in KEYS: \\* Database states \\/ DatabaseUpdate(k) \\* Cache states \\/ CacheStartReadThroughFill(k) \\/ DatabaseRespondToCacheFill(k) \\/ CacheCompleteFill(k) \\/ CacheHandleInvalidationMessage \\/ CacheEvict(k) \\* Cache fairness is included as part of the specification of system behavior. \\* This is just how the system works. Spec == Init /\\ [][Next]_vars /\\ WF_vars(CacheFairness) ============================================================================= \\* Modification History \\* Last modified Wed Jun 15 12:45:25 MST 2022 by elliotswart \\* Created Tue Jun 14 20:36:02 MST 2022 by elliotswart . Verification . When we go to verify it we get an error: . | Next Section | Download Configuration | . Temporal property violated. | 1. Initial predicate . | cache . | k1 . | type: miss | . | . | cacheFillStates . | k1 . | state: inactive | version: 0 | . | . | database . | k1 : 0 | . | invalidationQueue : | . | 2. CacheStartReadThroughFill Cache fill starts . | cache . | k1 . | type: miss | . | . | cacheFillStates . | k1 . | state: started | version: 0 | . | . | database . | k1 : 0 | . | invalidationQueue : | . | 3. DatabaseRespondToCacheFill Database responds with k1:v0 . | cache . | k1 . | type: miss | . | . | cacheFillStates . | k1 . | state: respondedto | version: 0 | . | . | database . | k1 : 0 | . | invalidationQueue : | . | 4. DatabaseUpdate Value changes to k1:v2, triggering invalidation . | cache . | k1 . | type: miss | . | . | cacheFillStates . | k1 . | state: respondedto | version: 0 | . | . | database . | k1 : 1 | . | invalidationQueue . | . | key : k1 | . | . | . | 5. CacheHandleInvalidationMessage Key isn't in cache, does nothing . | cache . | k1 . | type: miss | . | . | cacheFillStates . | k1 . | state: respondedto | version: 0 | . | . | database . | k1 : 1 | . | invalidationQueue : | . | 6. CacheCompleteFill Cache completes fill with old value. k1:v0 . | cache . | k1 . | version: 0 | type: hit | . | . | cacheFillStates . | k1 . | state: inactive | version: 0 | . | . | database . | k1 : 1 | . | invalidationQueue : | . | Stuttering No more updates, and cache remains inconsistent | . Clearly we have a race condition between cache invalidation and cache fill. Let’s try to rectify that. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/cache-invalidation/#initial-cache-invalidation-solution",
    "relUrl": "/caching/cache-invalidation/#initial-cache-invalidation-solution"
  },"53": {
    "doc": "Adding cache invalidation",
    "title": "Updated cache invalidation solution",
    "content": "An updated design . So our data has been versioned all along for observability. It’s time to start using the versions in our solution. This isn’t unrealistic, as databases can send snapshot times along with results and invalidations. Let’s also start sending the data along with the invalidations, so that we can update the cache when things change. Whenever a cache fill comes back, or an invalidation message is received, we will compare the version we just received to the version in the cache. We will only modify the cache if the version is higher. That way we don’t need to be concerned with race conditions of that sort. Whichever comes back first will be compared to the one that comes back second, and the cache will eventually have the same value. Updated cache invalidation . | | WriterWriterDatabaseDatabaseCache Invalidation QueueCache Invalidation QueueCacheCache | Updates data | Adds updated key andversioned data to queue | Polls queue | Returns invalidation itemalt[Key not in Cache] | | Does nothingalt[Key in Cache] | | Does nothingalt[Cache data olderthan invalidation] | | Replaces old versionwith data from message Modeling . We should update the state machines to: . InactiveCacheStartReadThroughFillDatabaseRespondToCacheFillCacheCompleteFillCacheFailFillCacheIgnoreFillfill version is older than stored version InvalidationMessageOnQueueCacheHandleInvalidationMessageCacheIgnoreInvalidationMessagemessage version is older than stored version This is reflected in the code below. | Next Section | Download Code | Download PDF | . Show Code Show LaTex -------------------- MODULE cacheinvalidationv2 -------------------- \\* Cache incorporates the data CacheCompleteFill(k) == /\\ cacheFillStates[k].state = \"respondedto\" \\* Either the cache is empty for that key /\\ \\/ cache[k] \\in CacheMiss \\* or we are filling a newer version \\/ /\\ cache[k] \\notin CacheMiss /\\ cache[k].version &lt; cacheFillStates[k].version /\\ cacheFillStates' = [cacheFillStates EXCEPT \\* Reset to 0 ![k].state = \"inactive\", ![k].version = 0 ] /\\ cache' = [cache EXCEPT ![k] = [ type |-&gt; \"hit\", version |-&gt; cacheFillStates[k].version ] ] /\\ UNCHANGED &lt;&lt;database, invalidationQueue&gt;&gt; CacheIgnoreFill(k) == /\\ cacheFillStates[k].state = \"respondedto\" \\* If we have a newer version in cache, ignore fill /\\ /\\ cache[k] \\in CacheHit /\\ cache[k].version &gt;= cacheFillStates[k].version /\\ cacheFillStates' = [cacheFillStates EXCEPT \\* Reset to 0 ![k].state = \"inactive\", ![k].version = 0 ] \\* Don't update cache /\\ UNCHANGED &lt;&lt;cache, database, invalidationQueue&gt;&gt; CacheHandleInvalidationMessage == /\\ \\E message \\in invalidationQueue: \\* Dequeue invalidation queue in any order \\* Key must be in cache /\\ /\\ cache[message.key] \\in CacheHit \\* Message needs to be newer than the cache /\\ cache[message.key].version &lt; message.version \\* Update item in cache /\\ cache' = [cache EXCEPT ![message.key] = [ type |-&gt; \"hit\", \\* Update to version in invalidation message version |-&gt; message.version ]] \\* Remove message from queue because handled /\\ invalidationQueue' = invalidationQueue \\ {message} /\\ UNCHANGED &lt;&lt;cacheFillStates, database&gt;&gt; CacheIgnoreInvalidationMessage == /\\ \\E message \\in invalidationQueue: \\* Dequeue invalidation queue in any order \\* Ignore invalidation messages for messages not in cache /\\ \\/ cache[message.key] \\in CacheMiss \\* Or when the cache already has the same or larger version \\/ /\\ cache[message.key] \\notin CacheMiss /\\ cache[message.key].version &gt;= message.version \\* Remove message from queue to ignore /\\ invalidationQueue' = invalidationQueue \\ {message} \\* Don't update cache /\\ UNCHANGED &lt;&lt;cacheFillStates, database, cache&gt;&gt; ============================================================================= \\* Modification History \\* Last modified Wed Jun 15 13:58:25 MST 2022 by elliotswart \\* Created Wed Jun 15 13:58:13 MST 2022 by elliotswart . Verification . We run it and experience a different error. | Next Section | Download Configuration | . Temporal property violated. | 1. Initial predicate A cache fill starts for k1 . | cache . | k1 . | type: miss | . | . | cacheFillStates . | k1 . | version: 0 | state: inactive | . | . | database . | k1 : 0 | . | invalidationQueue : | . | 2. CacheStartReadThroughFill . | cache . | k1 . | type: miss | . | . | cacheFillStates . | k1 . | version: 0 | state: started | . | . | database . | k1 : 0 | . | invalidationQueue : | . | 3. DatabaseRespondToCacheFill . | cache . | k1 . | type: miss | . | . | cacheFillStates . | k1 . | version: 0 | state: respondedto | . | . | database . | k1 : 0 | . | invalidationQueue : | . | 4. DatabaseUpdate An invalidation message is sent with k1:v1 . | cache . | k1 . | type: miss | . | . | cacheFillStates . | k1 . | version: 0 | state: respondedto | . | . | database . | k1 : 1 | . | invalidationQueue . | . | key : k1 | version : 1 | . | . | . | 5. CacheIgnoreInvalidationMessage The invalidation message is ignored because k1 is not in cache . | cache . | k1 . | type: miss | . | . | cacheFillStates . | k1 . | version: 0 | state: respondedto | . | . | database . | k1 : 1 | . | invalidationQueue : | . | 6. CacheCompleteFill The outdated k1:v0 is loaded as fill comes back . | cache . | k1 . | version: 0 | type: hit | . | . | cacheFillStates . | k1 . | version: 0 | state: inactive | . | . | database . | k1 : 1 | . | invalidationQueue : | . | Stuttering No more updates, and cache remains inconsistent | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/cache-invalidation/#updated-cache-invalidation-solution",
    "relUrl": "/caching/cache-invalidation/#updated-cache-invalidation-solution"
  },"54": {
    "doc": "Adding cache invalidation",
    "title": "Summary",
    "content": "Our main problem remaining is that cache invalidation messages are ignored if the key is not in the cache. In this case, a cache fill can be completed incorrectly with the old value. More broadly, the solution doesn’t take ongoing cache fills into consideration. We should address this in our next design. | Next: Working cache invalidation | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/cache-invalidation/#summary",
    "relUrl": "/caching/cache-invalidation/#summary"
  },"55": {
    "doc": "Reproducing Facebook's bug",
    "title": "Reproducing Facebook’s bug",
    "content": ". | Introduction | Detective work . | The bug report | Deriving Assumptions | . | The model | Can we find the bug? | Retrospective | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/reproducing-the-bug/#reproducing-facebooks-bug",
    "relUrl": "/caching/reproducing-the-bug/#reproducing-facebooks-bug"
  },"56": {
    "doc": "Reproducing Facebook's bug",
    "title": "Introduction",
    "content": "The Facebook blog post that inspired this series ended with a bug caught by Polaris, Facebook’s cache inconsistency observability tool. Like any bug found in production, it would be better if it could be caught in the design process. In this post, we’ll try to make a model with sufficient detail to catch this bug. This reconstruction is best thought of as historical fiction, the “what if the British won the Revolutionary War” version of Facebook’s cache behavior. Take it with a bag of salt. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/reproducing-the-bug/#introduction",
    "relUrl": "/caching/reproducing-the-bug/#introduction"
  },"57": {
    "doc": "Reproducing Facebook's bug",
    "title": "Detective work",
    "content": "The bug report . Taken directly from this blog post. Precondition: The cache filled metadata. 1. The cache tried to fill the metadata with version. 2. In the first round, the cache first filled the old metadata. 3. Next, a write transaction updated both the metadata table and the version table atomically. 4. In the second round, the cache filled the new version data. Here, the cache fill operation interleaved with the database transaction. It happens very rarely because the racing window is tiny. You might be thinking, “This is the bug.”. No. Actually, so far everything worked as expected because cache invalidation is supposed to bring the cache to a consistent state. 5. Later, cache invalidation came during an attempt to update the cache entry to both the new metadata and the new version. This almost always works, but this time it didn’t. 6. The cache invalidation ran into a rare transient error on the cache host, which triggered the error handling code. 7. The error handler dropped the item in cache. The pseudocode looks like this: drop_cache(key, version); It says drop the item in cache, if its version is less than specified. However, the inconsistent cache item contained the latest version. So this code did nothing, leaving stale metadata in cache indefinitely. This is the bug. We simplified the example quite a bit here. The actual bug has even more intricacy, with database replication and cross region communication involved. The bug gets triggered only when all steps above occur and happen specifically in this sequence. The inconsistency gets triggered very rarely. The bug hides in the error handling code behind interleaving operations and transient errors. Deriving Assumptions . | Assumption | Evidence | . | Database updates metadata and version transactionally | Step 3 | . | The metadata stored in cache, and the version of that metadata, are filled separately (non-transactionally) | Steps 1 and 4 | . | The metadata stored in cache, and the version of that metadata are filled with separate database requests | Steps 1 and 4 | . | The cache fill of metadata or version can fail | Step 5 | . | Cache invalidation messages contain both the version and the metadata | Step 5 | . | Cache invalidation message processing can fail in a way that is not automatically resumed | Step 6 | . | When cache invalidation fails, an error handler is called that conditionally drops keys lower than the version on the message | Step 7 | . Additionally, we can gather information from other sources. | Assumption | Evidence | . | The cache invalidation messages are guaranteed to be eventually delivered | TAO design paper | . The main question it raised: How exactly does Facebook use versions in the cache, if they are allowed to get out of sync? The answer seems to be: leaning heavily on their cache invalidation solution (Steps 4 and 5). Because the cache will get every invalidation message, no matter how far the version and metadata are out of sync, the LATEST cache invalidation message should fix it. From that we must infer: . Cache invalidation replaces metadata values of at most equal or lesser version. The fundamental bug is therefore the fact that the error handler that handles cache invalidation errors drops only lesser versions, while the cache invalidation contract requires replacing equal or lesser versions. Let’s see if we can catch this with a model. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/reproducing-the-bug/#detective-work",
    "relUrl": "/caching/reproducing-the-bug/#detective-work"
  },"58": {
    "doc": "Reproducing Facebook's bug",
    "title": "The model",
    "content": "All the descriptions and assumptions are done at a simplified level, as in the blog post. Therefore we will model this level of detail. Note: Simplification in of itself does not make a model invalid or even less helpful. Models should be constructed to catch bugs at a particular level of abstraction. It is possible that a system may need multiple models, at different levels of abstraction, to describe it. Sometimes you can even connect them together to find bugs in their interactions, though this is very advanced. As we create a model in an attempt to recreate a system, our biggest risk is overfitting—that is, tailoring our implementation too exactly to get our expected result. We can mitigate this somewhat with Occam’s Razor: trying to find the simplest model that fits the assumptions . The other assumption we make is that the reported bug is the only bug in Facebook’s logic at this level of abstraction. Where data is not available from Facebook’s caching papers, we may substitute a fix from the prior articles in this series. We get state machines that look like this: . InactiveCacheStartFillMetadataDatabaseRespondWithMetadataCacheFillMetadataCacheFailFillCacheStartFillVersionDatabaseRespondWithVersionCacheFillVersionCacheIgnoreFillVersionFill version is less than stored version InvalidationMessageOnQueueUpdateFromInvalidationMessageIgnoreInvalidationMessageFailInvalidationMessageProcessingFailUpdateInvalidationMessageIgnoreFailUpdateInvalidationMessageEvictKeyAn error occursVersion in message less thanor equal to version in cacheVersion in message greaterthan version in cache One thing thing to notice in the model is that we import the same cacherequirements we have used for the entire series. They should be sufficient to help us find the bug. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ----------------------------- MODULE facebookcacheinvalidation ----------------------------- EXTENDS Naturals CONSTANTS KEYS VARIABLES database, \\* Represents metadata version stored in the cache cache, \\* Represents the version stored in the cache. This is what is used for comparisons, \\* to allow our model to decouple ACTUAL metadata version with STORED version cacheVersions, cacheFillStates, invalidationQueue, counter \\* We can still test with the same cache requirements we've been using this whole time INSTANCE cacherequirements vars == &lt;&lt;database, cache, cacheFillStates, invalidationQueue, counter, cacheVersions&gt;&gt; InvalidationMessage == [key: KEYS, version: DataVersion] CacheFillState == [ state: { \"inactive\", \"startfillmetadata\", \"respondedtometadata\", \\* Next: CacheFillMetadata \"startfillversion\", \"respondedtoversion\" \\* Next: CacheFillVersion }, version: DataVersion] CacheValue == CacheMiss \\union CacheHit TypeOk == /\\ database \\in [KEYS -&gt; DataVersion] /\\ cache \\in [KEYS -&gt; CacheValue] \\* Cache versions are typed identically to cache /\\ cacheVersions \\in [KEYS -&gt; CacheValue] /\\ cacheFillStates \\in [KEYS -&gt; CacheFillState] /\\ invalidationQueue \\in SUBSET InvalidationMessage /\\ counter \\in Nat Init == /\\ database = [k \\in KEYS |-&gt; 0] \\* cache (metadata) and cacheVersions start empty together /\\ cache = [k \\in KEYS |-&gt; [type |-&gt; \"miss\"]] /\\ cacheVersions = [k \\in KEYS |-&gt; [type |-&gt; \"miss\"]] /\\ cacheFillStates = [k \\in KEYS |-&gt; [ state |-&gt; \"inactive\", version |-&gt; 0] ] /\\ invalidationQueue = {} /\\ counter = 0 DatabaseUpdate(k) == LET updatedVersion == database[k] + 1 IN /\\ database' = [database EXCEPT ![k] = updatedVersion] /\\ invalidationQueue' = invalidationQueue \\union {[key |-&gt; k, version |-&gt; updatedVersion]} /\\ UNCHANGED &lt;&lt;cache, cacheVersions, cacheFillStates, counter&gt;&gt; CacheStartFillMetadata(k) == \\* Fill only occurs if the cache is unset for that value /\\ cache[k] \\in CacheMiss /\\ cacheFillStates[k].state = \"inactive\" /\\ cacheFillStates' = [cacheFillStates EXCEPT ![k].state = \"startfillmetadata\"] /\\ UNCHANGED &lt;&lt;database, cache, cacheVersions, invalidationQueue, counter&gt;&gt; DatabaseRespondWithMetadata(k) == /\\ cacheFillStates[k].state = \"startfillmetadata\" /\\ cacheFillStates' = [cacheFillStates EXCEPT ![k].state = \"respondedtometadata\", ![k].version = database[k] ] /\\ UNCHANGED &lt;&lt;database, cache, cacheVersions, invalidationQueue, counter&gt;&gt; \\* Metadata updated in cache CacheFillMetadata(k) == /\\ cacheFillStates[k].state = \"respondedtometadata\" /\\ cacheFillStates' = [cacheFillStates EXCEPT ![k].state = \"inactive\" ] \\* Represents cache metadata being updated \\* Does not check version /\\ cache' = [cache EXCEPT ![k] = [ type |-&gt; \"hit\", version |-&gt; cacheFillStates[k].version ] ] /\\ UNCHANGED &lt;&lt;database, cacheVersions, invalidationQueue, counter&gt;&gt; CacheStartFillVersion(k) == \\* Fill only occurs if the cacheVersion is unset for that value /\\ cacheVersions[k] \\in CacheMiss /\\ cacheFillStates[k].state = \"inactive\" /\\ cacheFillStates' = [cacheFillStates EXCEPT ![k].state = \"startfillversion\"] /\\ UNCHANGED &lt;&lt;database, cache, cacheVersions, invalidationQueue, counter&gt;&gt; DatabaseRespondWithVersion(k) == /\\ cacheFillStates[k].state = \"startfillversion\" /\\ cacheFillStates' = [cacheFillStates EXCEPT ![k].state = \"respondedtoversion\", ![k].version = database[k] ] /\\ UNCHANGED &lt;&lt;database, cache, cacheVersions, invalidationQueue, counter&gt;&gt; \\* Version updated in cache CacheFillVersion(k) == /\\ cacheFillStates[k].state = \"respondedtoversion\" \\* Fill empty versions /\\ \\/ cacheVersions[k] \\in CacheMiss \\* or newer versions \\/ /\\ cacheVersions[k] \\in CacheHit /\\ cacheVersions[k].version &lt; cacheFillStates[k].version /\\ cacheFillStates' = [cacheFillStates EXCEPT ![k].state = \"inactive\" ] \\* Represents cache versions being updated /\\ cacheVersions' = [cacheVersions EXCEPT ![k] = [ type |-&gt; \"hit\", version |-&gt; cacheFillStates[k].version ] ] /\\ UNCHANGED &lt;&lt;database, invalidationQueue, cache, counter&gt;&gt; CacheIgnoreFillVersion(k) == /\\ cacheFillStates[k].state = \"respondedtoversion\" \\* If we have a newer version in cache, ignore fill /\\ /\\ cacheVersions[k] \\in CacheHit /\\ cacheVersions[k].version &gt;= cacheFillStates[k].version /\\ cacheFillStates' = [cacheFillStates EXCEPT \\* Reset to 0 ![k].state = \"inactive\", ![k].version = 0 ] /\\ counter' = counter + 1 /\\ UNCHANGED &lt;&lt;cache, cacheVersions, database, invalidationQueue&gt;&gt; CacheFailFill(k) == /\\ cacheFillStates[k].state \\in {\"respondedtometadata\", \"respondedtoversion\"} /\\ cacheFillStates' = [cacheFillStates EXCEPT ![k].state = \"inactive\", ![k].version = 0 ] /\\ counter' = counter + 1 /\\ UNCHANGED &lt;&lt;database, cache, cacheVersions, invalidationQueue&gt;&gt; CacheEvict(k) == /\\ cache[k] \\in CacheHit /\\ cacheFillStates[k].state = \"inactive\" /\\ cache' = [cache EXCEPT ![k] = [type |-&gt; \"miss\"]] /\\ cacheVersions' = [cache EXCEPT ![k] = [type |-&gt; \"miss\"]] /\\ counter' = counter + 1 /\\ UNCHANGED &lt;&lt;database, cacheFillStates, invalidationQueue&gt;&gt; (***************************************************************************) (* Invalidation message handling *) (***************************************************************************) UpdateFromInvalidationMessage == \\E message \\in invalidationQueue: \\* Can update with no version /\\ \\/ /\\ cache[message.key] \\in CacheHit /\\ cacheVersions[message.key] \\in CacheMiss \\* or with greater or equal version \\/ /\\ cacheVersions[message.key] \\in CacheHit /\\ cacheVersions[message.key].version &lt;= message.version \\* Kills pending fill request /\\ cacheFillStates[message.key].state = \"inactive\" (***********************************************************************) (* Unlike fills from the database, the invalidation message contains *) (* both version and metadata. *) (***********************************************************************) /\\ cache' = [cache EXCEPT ![message.key] = [ type |-&gt; \"hit\", version |-&gt; message.version ]] /\\ cacheVersions' = [cache EXCEPT ![message.key] = [ type |-&gt; \"hit\", version |-&gt; message.version ]] /\\ invalidationQueue' = invalidationQueue \\ {message} /\\ UNCHANGED &lt;&lt;cacheFillStates, database, counter&gt;&gt; FailUpdateInvalidationMessageEvictKey == \\E message \\in invalidationQueue: \\* Can update with no version /\\ \\/ /\\ cache[message.key] \\in CacheHit /\\ cacheVersions[message.key] \\in CacheMiss \\* or with greater version \\/ /\\ cacheVersions[message.key] \\in CacheHit /\\ cacheVersions[message.key].version &lt; message.version \\* Kills pending fill request /\\ cacheFillStates[message.key].state = \"inactive\" \\* Key is evicted from cache, to allow fresh cache fill /\\ cache' = [cache EXCEPT ![message.key] = [type |-&gt; \"miss\"]] /\\ cacheVersions' = [cacheVersions EXCEPT ![message.key] = [type |-&gt; \"miss\"]] /\\ invalidationQueue' = invalidationQueue \\ {message} /\\ UNCHANGED &lt;&lt;cacheFillStates, database, counter&gt;&gt; FailUpdateInvalidationMessageIgnore == \\E message \\in invalidationQueue: \\* If message version is lower or equal than cache version, do nothing /\\ cacheVersions[message.key] \\in CacheHit /\\ cacheVersions[message.key].version &gt;= message.version /\\ counter' = counter + 1 /\\ invalidationQueue' = invalidationQueue \\ {message} /\\ UNCHANGED &lt;&lt;cacheFillStates, database, cache, cacheVersions&gt;&gt; IgnoreInvalidationMessage == \\E message \\in invalidationQueue: \\* Ignore invalidation messages if a key is not in cache /\\ \\/ /\\ cache[message.key] \\in CacheMiss \\* and a fill is not occurring /\\ cacheFillStates[message.key].state = \"inactive\" \\* or when the cache already has a larger version \\/ /\\ cacheVersions[message.key] \\in CacheHit /\\ cacheVersions[message.key].version &gt; message.version /\\ invalidationQueue' = invalidationQueue \\ {message} /\\ counter' = counter + 1 \\* Don't update cache /\\ UNCHANGED &lt;&lt;cacheFillStates, database, cache, cacheVersions&gt;&gt; CacheFairness == \\/ \\E k \\in KEYS: \\/ CacheStartFillMetadata(k) \\/ DatabaseRespondWithMetadata(k) \\/ CacheFillMetadata(k) \\/ CacheStartFillVersion(k) \\/ DatabaseRespondWithVersion(k) \\/ CacheFillVersion(k) \\/ CacheIgnoreFillVersion(k) \\/ UpdateFromInvalidationMessage \\/ FailUpdateInvalidationMessageEvictKey \\/ FailUpdateInvalidationMessageIgnore \\/ IgnoreInvalidationMessage (***************************************************************************) (* Specification *) (***************************************************************************) Next == \\/ \\E k \\in KEYS: \\* Database states \\/ DatabaseUpdate(k) \\* Cache states \\/ CacheStartFillMetadata(k) \\/ DatabaseRespondWithMetadata(k) \\/ CacheFillMetadata(k) \\/ CacheStartFillVersion(k) \\/ DatabaseRespondWithVersion(k) \\/ CacheFillVersion(k) \\/ CacheIgnoreFillVersion(k) \\/ CacheEvict(k) \\/ CacheFailFill(k) \\/ UpdateFromInvalidationMessage \\/ FailUpdateInvalidationMessageEvictKey \\/ FailUpdateInvalidationMessageIgnore \\/ IgnoreInvalidationMessage Spec == Init /\\ [][Next]_vars /\\ WF_vars(CacheFairness) CounterBound == counter =&lt; 2 ============================================================================= \\* Modification History \\* Last modified Thu Jun 16 16:19:54 MST 2022 by elliotswart \\* Created Tue Jun 14 20:36:02 MST 2022 by elliotswart . Note how the entire Facebook model fits in 320 lines of code. Also, note how similar it looks to the models we’ve been using this whole series. It feels like the whole model is at the same level of abstraction; we haven’t had to disproportionately model certain pieces just to model our assumptions. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/reproducing-the-bug/#the-model",
    "relUrl": "/caching/reproducing-the-bug/#the-model"
  },"59": {
    "doc": "Reproducing Facebook's bug",
    "title": "Can we find the bug?",
    "content": "And when we run it we get a bug report that we can actually map, item by item, to the bug reported by Facebook. | Next Section | Download Configuration | . Temporal properties were violated. | 1. Initial predicate Database at v0 . | cache . | k1 . | type: miss | . | . | cacheFillStates . | k1 . | version: 0 | state: inactive | . | . | cacheVersions . | k1 . | type: miss | . | . | counter : 0 | database . | k1 : 0 | . | invalidationQueue : | . | 2. CacheStartFillMetadata First round start . | cache . | k1 . | type: miss | . | . | cacheFillStates . | k1 . | version: 0 | state: startfillmetadata | . | . | cacheVersions . | k1 . | type: miss | . | . | counter : 0 | database . | k1 : 0 | . | invalidationQueue : | . | 3. DatabaseRespondWithMetadata . | cache . | k1 . | type: miss | . | . | cacheFillStates . | k1 . | version: 0 | state: respondedtometadata | . | . | cacheVersions . | k1 . | type: miss | . | . | counter : 0 | database . | k1 : 0 | . | invalidationQueue : | . | 4. CacheFillMetadata \"In the first round, the cache first filled the old metadata\" . | cache . | k1 . | version: 0 | type: hit | . | . | cacheFillStates . | k1 . | version: 0 | state: inactive | . | . | cacheVersions . | k1 . | type: miss | . | . | counter : 0 | database . | k1 : 0 | . | invalidationQueue : | . | 5. DatabaseUpdate \"Next, a write transaction updated both the metadata table and the version table atomically\" . | cache . | k1 . | version: 0 | type: hit | . | . | cacheFillStates . | k1 . | version: 0 | state: inactive | . | . | cacheVersions . | k1 . | type: miss | . | . | counter : 0 | database . | k1 : 1 | . | invalidationQueue . | . | key : k1 | version : 1 | . | . | . | 6. CacheStartFillVersion Second round started . | cache . | k1 . | version: 0 | type: hit | . | . | cacheFillStates . | k1 . | version: 0 | state: startfillversion | . | . | cacheVersions . | k1 . | type: miss | . | . | counter : 0 | database . | k1 : 1 | . | invalidationQueue . | . | key : k1 | version : 1 | . | . | . | 7. DatabaseRespondWithVersion . | cache . | k1 . | version: 0 | type: hit | . | . | cacheFillStates . | k1 . | version: 1 | state: respondedtoversion | . | . | cacheVersions . | k1 . | type: miss | . | . | counter : 0 | database . | k1 : 1 | . | invalidationQueue . | . | key : k1 | version : 1 | . | . | . | 8. CacheFillVersion \"In the second round, the cache filled the new version data.\" . | cache . | k1 . | version: 0 | type: hit | . | . | cacheFillStates . | k1 . | version: 1 | state: inactive | . | . | cacheVersions . | k1 . | version: 1 | type: hit | . | . | counter : 0 | database . | k1 : 1 | . | invalidationQueue . | . | key : k1 | version : 1 | . | . | . | 9. FailUpdateInvalidationMessageIgnore \"The cache invalidation ran into a rare transient error on the cache host, which triggered the error handling code. However, the inconsistent cache item contained the latest version. So this code did nothing\" . | cache . | k1 . | version: 0 | type: hit | . | . | cacheFillStates . | k1 . | version: 1 | state: inactive | . | . | cacheVersions . | k1 . | version: 1 | type: hit | . | . | counter : 1 | database . | k1 : 1 | . | invalidationQueue : | . | Stuttering \"leaving stale metadata in cache indefinitely\" | . This trace (or some version of it) is the first thing that comes up when you run the model above. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/reproducing-the-bug/#can-we-find-the-bug",
    "relUrl": "/caching/reproducing-the-bug/#can-we-find-the-bug"
  },"60": {
    "doc": "Reproducing Facebook's bug",
    "title": "Retrospective",
    "content": "There are several key takeaways: . | Implementing another module: Again we used the exact same cacherequirements module for all iterations of our caches. This shows the power of writing requirements in TLA+ and having other modules implement them. | Compactness of specifications: The entire set of requirements and implementation was 370 lines of code with plentiful comments. The detail and level of abstraction remained relatively consistent, supporting the representativeness of the spec. | Potential to catch bugs before production: The specification is of sufficient detail that the coder of the error handler could have ensured (and even unit tested) conformance to the spec. | . While this is obviously a simplified model of the actual behavior, there are two potential conclusions to draw: . | Modeling at this level of abstraction is useful, and other verification methods could be used to account for the additional complexity such as regions, network partitions, database replication, etc. | The model could be enhanced to a higher level of detail that reflects those complexities, modularized to allow for testing at different levels of abstraction, and then holistically tested (likely over days on a high end machine). | . A final reminder that this is still historical fiction, and likely deviates from the Facebook implementation (even at this level of abstraction) in a number of ways. | Next: Time for some Business Logic | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/reproducing-the-bug/#retrospective",
    "relUrl": "/caching/reproducing-the-bug/#retrospective"
  },"61": {
    "doc": "Reproducing Facebook's bug",
    "title": "Reproducing Facebook's bug",
    "content": " ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/reproducing-the-bug/",
    "relUrl": "/caching/reproducing-the-bug/"
  },"62": {
    "doc": "Cache Invalidation",
    "title": "Cache Invalidation",
    "content": ". | Introduction | A simple explainer on caching . | Data Access | Cached Data Access | CPU Caches | Browser Cache | Database / Data Service Caching . | Cache-Aside | Read-Through | Advantages of Database Caching | . | . | Key concepts and assumptions in database caching . | Modeling assumptions | Cache eviction | Cache invalidation | . | Initial parameters for all exercises | Summary | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/",
    "relUrl": "/caching/"
  },"63": {
    "doc": "Cache Invalidation",
    "title": "Introduction",
    "content": "Caching is everywhere. Handling caches is one of the more complex and error prone parts of a developer’s life, especially when maintaining web applications. Here we will attempt to explain why, and create and debug formal models for caching strategies. Why is the title of this article “Cache Invalidation”? As it turns out, that’s the tricky part. Don’t worry if that doesn’t ring a bell yet! We’ll explain it step by step. This article was inspired by this Facebook blog post on cache invalidation. As they mention, caching behavior is best thought of as a state machine, which makes it a perfect fit for modeling. I’d recommend you read the post twice: once before and once after you read this article. It is a short and well-written intro to the nuances of caching and cache consistency testing. It’s also written by people who run caches that serve one quadrillion queries a day. One quadrillion is 1,000,000,000,000,000. Statistically speaking, if a problem can happen, it will happen to them. Note: We’ll be focusing on cache reads for this article. However, we will absolutely address what happens when the underlying data is written to (which is where cache invalidation comes up). ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/#introduction",
    "relUrl": "/caching/#introduction"
  },"64": {
    "doc": "Cache Invalidation",
    "title": "A simple explainer on caching",
    "content": "The simplest model of data access involves a Data Consumer and a Data Store. When the consumer wants information, it asks the store, which gives it the most up to data information it has. How simple is that? . Data Access . | Data ConsumerData ConsumerData StoreData Store | Requests piece of data | Returns data Cached Data Access . For a number of reasons, especially if the data is going to be accessed often, we put a cache between the data consumer and the data store. | | Data ConsumerData ConsumerCacheCacheData StoreData Store | Requests piece of dataalt[cache doesn't have data (cache miss)] | Requests piece of data | Returns data | Returns data Wow, that’s way more complicated! Spoiler alert, there are way more failures that can occur due to that complexity. So why do we use it? Did Big Cache lobby Congress? Actually, there are profound benefits to caching. The main ones are higher speed and lower cost. Let’s look at different examples of caches. CPU Caches . | | CPU CoreCPU CoreL1-L3 CachesL1-L3 CachesMemoryMemory | Requests data from memory addressalt[cache miss] | Requests data from memory address | Returns data | Returns data Note: L1-L3 caches are grouped in the diagram. Actual data access goes from Core -&gt; L1 -&gt; L2 -&gt; L3 -&gt; Memory . Perhaps the most important caches in all of computer engineering are those located on the CPU and used to access Memory. The caches are located on the CPU, with L1 and L2 caches generally located on each individual core. The closer a cache is to a core, the faster it is to access: (credit) . Advantages: . | Higher speed: Getting data from an L1 cache is approximately 100x faster than getting it from memory. That matters a lot for data that is actively worked on by the processor. | Lower cost: Caching reduces the amount of times the core needs to access memory. However, lowering cost is not the primary reason for this kind of cache. | . CPU caches are an example of Read Through caches because the CPU talks to the cache that talks to the memory. They are also Write Through caches, though that is not covered here. If you are interested in this kind of caching, check out Specifying Systems: Pages 56-64. It also addresses writing, which is the more complicated use case. Browser Cache . | | Web PageWeb PageBrowserBrowserBrowser CacheBrowser CacheWeb ServerWeb Server | Accesses image.jpg | Checks if image.jpg in cache | Doesn't find in cache | Requests image.jpg | Returns image.jpg | Returns image.jpg | Accesses image.jpg | Checks if image.jpg in cache | Returns image.jpg | Returns image.jpgBrowser caches are the type of cache with which your average person has the most interaction. Web browsers such as Chrome maintain a cache of assets they download from the web. Advantages: . | Higher speed: Don’t need to download large files every time you visit a website or change pages. | Lower cost: Reduces the load on the servers because they don’t need to repeatedly serve the largest, and thus most expensive, files. | . Browser caching is an example of a Cache-aside pattern, where the application is responsible for managing the cache. While this is critical to the modern web, it can cause strange problems if it is used even slightly incorrectly. There’s a reason the first suggestion when a website stops working is to clear your cache. Database / Data Service Caching . This is the type of cache we’ll be focusing on in this article. Databases are expensive and hard to scale, and they are also generally a performance bottleneck. So you put a cache in between your web servers and your database. You see both Cache-Aside and Read Through caching here. Cache-Aside . This is the most common. We are trying to cache database queries, and there is no “right” way to do that. For a simple example, let’s say we wanted to get the names of all employees located in Palo Alto. The query might look like: . Query.SQL: SELECT Names FROM EMPLOYEES WHERE Location=’Palo Alto’ . Ok, that’s probably not going to meaningfully change on a second by second basis, so there’s no need to keep hitting the database. Our system looks like this: . Web ServerMemcachedDatabaseDatabase ConnectionRead/Write Cache The database is a standard relational database. Memcached is a key value store. We use the entire query string as the key, and the result of the query as the value. | | Web ServerWeb ServerMemcachedMemcachedDatabaseDatabase | Checks if contents of Query.SQL is a key in cache | Doesn't find in cache | Runs Query.SQL on database | Returns the query result | Writes the pair &lt;&lt;contents of Query.SQL, query result&gt;&gt; | Checks if contents of Query.SQL is a key in cache | Returns query result While potentially you could program a cache like this one to be Read Through, maybe using the query string as a key, it could be a really bad design decision for your workload. Maybe it’s better to break it up. This is an application level decision. Read-Through . If you have more homogenous ways of accessing your data, a read through cache becomes possible. The biggest example of this is the TAO graph cache developed by Facebook. While the query language for TAO is not GraphQL, it’s probably not a bad way to think of it. A more semantic, structured lookup language allows you to make company-wide decisions on how to cache, rather than just application-level. To steal an example from the paper, if you wanted to know the number of location checkins at the Golden Gate Bridge, the query might look like this: . assoc count(534, CHECKIN) . Facebook’s system looks like this: . Web ServersTao CacheDatabase(s) and Data StoresConnectionsObject APIAssociation API The TAO cache is the only actor the web servers talk to. It caches the data required to answer the query and returns it to the server. Because it understands the semantics of the query, it might be able to answer more with the data it just cached, like: “Has Debra been to the golden gate bridge?” . | | Web ServerWeb ServerTao CacheTao CacheDatabasesDatabases | Requests \"query assoc count(534, CHECKIN)\"alt[cache miss] | Requests all needed data from all applicable databases | Returns data | | Intelligently caches graph data | Returns data Read Through caching is much better than Cache-aside if you can use it. It’s also cleaner to model and analyze, so we’ll be using it for the following models. In addition, Facebook allows Write-Through with the Tao cache, which, is out of the scope of this article to preserve the reader’s sanity. Advantages of Database Caching . Why is this type of caching so important to backend engineers? . | Higher performance: A database query can take 3ms to 5 seconds depending on its structure. A memcached query can take &lt; 1ms and is consistently fast. | Lower cost: This is the big one! Let’s do some back of the envelope calculations on cost: . Facebook handles 1e15 queries per day. There are 86,400 seconds per day. We can round that to 1e10 queries per second. A 3 node postgres cluster, tuned for performance, can perform 5,000 queries per second. Let’s call it 2,000 queries per second per node. We’re going to ignore the difficulties of scaling databases and assume we have REALLY good sharding. If we were serving everything from the database, we would need about 5 million servers. If we say each node costs $2,000 per year to run, that’s $10 billion per year. A memcached node can handle approx 200,000 queries per second. We would need a much more manageable 50,000 servers. At $2,000 per node a year, that comes out to the positively bargain price of $100 million dollars per year. Caching may be a hard problem, but it is absolutely critical to making SaaS products cost-effective. Your company may not be playing for Facebook-level stakes, but it can absolutely make a difference once a reasonable level of scale has been reached. xkcd gets it: . | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/#a-simple-explainer-on-caching",
    "relUrl": "/caching/#a-simple-explainer-on-caching"
  },"65": {
    "doc": "Cache Invalidation",
    "title": "Key concepts and assumptions in database caching",
    "content": "Note: Some of this can apply to other kinds of caches, but extrapolate at your own risk. While we covered the read case in some detail, there are several other considerations that will need to make it into every model. Modeling assumptions . We will be assuming a Read-Through cache for the following models. While this is not the most common type of cache for this purpose, all the cache consistency issues that apply to Read-Through caches also apply to Cache-aside caches. This choice lets us skip past the application-level decisions made by Cache-aside caches. With that said, this article may still help you if you want to model a Cache-aside cache for your specific application. Cache eviction . Ok, I cached an item. Does it live in my cache forever? No, and there are two main reasons for this: . | Your cache is full: Imagine a 10GB cache fronting a 1TB database. At any one time 1/100th of the data can be cached for quick access. What happens when you need to cache something new? It depends on the caching strategy, but Least-Recently-Used (LRU) is a standard one. When you need to remove data to add new data, remove the data that has been least recently read. Generally, that will let more relevant data stay in the cache, while less relevant data is evicted. This is important even for giant cache systems spanning thousands of machines. Maybe the North American cache can hold 95% of all the data North Americans want to see, but that 95% keeps changing, so the cache must change with it. | Time to Live (TTL): One simple way to keep your cache up to date is to set a TTL policy. Imagine you never wanted your data to be more than 1 hour out of date. Set a TTL of 1 hour, and after an hour, the data will be retrieved again. This is a blunt but powerful tool. | Accidental Eviction: Caches are generally not built for durability. A cache server can fail, potentially removing the keys it held from the cache. Replication can help with this, but in general caches choose to give up durability for performance. Durability is what the database is for. | . In general, we should assume a cached item could be evicted at any time for any reason. That doesn’t mean we can’t model specific reasons for eviction, but we also need to account for random eviction. Cache invalidation . As convenient as it would be if people only read from databases, it turns out that people write to them too. Which means the database values change. Which means the cache can become out of date. If the cache needed to be immediately consistent with the database it would effectively need to be an extension of the database, with all the accompanying complexity and CAP theorem scaling difficulties. Databases do this, but it is hidden behind the standard database interface, and not what we’re discussing right now. The standard database caches and caching strategies aim to be eventually consistent, meaning that given time, the data in the cache will reflect the data in the database (unless of course the database changes again). Theoretically, eventual consistency means your cache could be minutes, hours, or even days behind the database as long as it would eventually catch up. In practice, seconds to minutes are considered acceptable. However, setting a very short TTL reduces the benefit of caching. Some applications can work with a longer TTL if updates that depend on old versions of the data are detected and cause a user error and a cache refresh. For example, choosing a seat on a air flight might show a out of date seat map, but an attempt to book seat that is filled will be caught and the user will be asked to rebook. In many systems, though, this is not a desirable property. Twitter wants to show you the latest Tweets. For that reason, automatic cache invalidation systems exist. Generally, one or more applications read the database logs and look for changes. The application then broadcasts to the caches that a change has occurred and they should evict their old value. The next time someone queries for that data, the cache will read through to the database and get the latest value. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/#key-concepts-and-assumptions-in-database-caching",
    "relUrl": "/caching/#key-concepts-and-assumptions-in-database-caching"
  },"66": {
    "doc": "Cache Invalidation",
    "title": "Initial parameters for all exercises",
    "content": "We will work with the simple Read-Through cache below: . Web ServersCacheDatabaseConnectionQuery API . This will be how reads are executed for all the exercises, as this behavior is inherent to a Read-Through cache: . | | Web ServerWeb ServerCacheCacheDatabaseDatabase | Requests queryalt[cache miss] | Requests query result | Returns data | | Caches query result | Returns data Finally, our eviction strategy will be modeled by cache keys randomly being evicted. This covers both the cache running out of space and the cache failing for other reasons. As our primary concern is cache consistency with the database, and not cache availability, it’s not necessary to model capacity or more complex eviction strategies. Note: If we were testing cache eviction strategies, modeling capacity would be essential. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/#initial-parameters-for-all-exercises",
    "relUrl": "/caching/#initial-parameters-for-all-exercises"
  },"67": {
    "doc": "Cache Invalidation",
    "title": "Summary",
    "content": "Now that we have our caching basics covered, let’s model them, test them, and handle the problems that arise! As usual, we will start simple and work our way up. | Next: A naive model of caching | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/caching/#summary",
    "relUrl": "/caching/#summary"
  },"68": {
    "doc": "Learning Material",
    "title": "Learning Material",
    "content": " ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/learning-material/",
    "relUrl": "/learning-material/"
  },"69": {
    "doc": "Learning Material",
    "title": "Getting Started",
    "content": "The best way to start learning TLA+ is with the TLA+ Video Course, which is actually very engaging. Then read the first 80 pages of the Specifying Systems book, which is somewhat less engaging, but very helpful. The official repository of TLA+ learning material can be found here. Note: there’s also a language that compiles into TLA+ called PlusCal. It is slightly less powerful (and in fact you may need to use TLA+ expressions inline); however, it looks more like a programming language.Practical TLA+ is a good book if you want to learn it. I’m sure it’s sufficiently powerful to work the examples on this site. AWS uses both TLA+ and PlusCal for different algorithms. However, as PlusCal compiles to TLA+, understanding TLA+ is generally considered a good idea, regardless of which one you use. The TLA+ Language Manual for Engineers provides a semi-comprehensive guide to the TLA+ language. The Learn TLA Website has both TLA+ and PlusCal information. It is less comprehensive, but somewhat more accessible, than the TLA+ Language Manual for Engineers. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/learning-material/#getting-started",
    "relUrl": "/learning-material/#getting-started"
  },"70": {
    "doc": "Learning Material",
    "title": "Advanced Concepts",
    "content": "Want structured learning? . | Specifying Systems: Pages 81-227: Advanced but well-explained examples | Weeks of Debugging Can Save You Hours of TLA+ (Video) | Blocking Queue | Using TLA+ in the Real World to Understand a Glibc Bug | . Know what you’re looking for? . | TLA+ Examples Repository: Highly advise you read each algorithm along with a paper or explainer, to correlate concepts to code. | Advanced Concepts from TLA+ Website: Provide references for very specific parts of TLA+. | Specifying Systems: Pages 228-End. Basically a reference manual. | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/learning-material/#advanced-concepts",
    "relUrl": "/learning-material/#advanced-concepts"
  },"71": {
    "doc": "Enterprise Architect gets us started",
    "title": "Enterprise Architect gets us started",
    "content": ". | Introduction . | Your bio | Your assignment | . | Creating the requirements document . | Functional requirements | Non-Functional requirements | . | Requirements summary | Architecture | Creating the Formal Specification Model . | The state machine | Data Model | Specification | Stubs | . | Summary | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/enterprise-architect/",
    "relUrl": "/business-logic/enterprise-architect/"
  },"72": {
    "doc": "Enterprise Architect gets us started",
    "title": "Introduction",
    "content": "Your bio . You’re the kind of person who uses acronyms like OLTP, OLAP and OAuth in a sentence and knows what they mean. Whenever your company gets together for a game of Whiteboard, you win hands down. It’s been a little while since you’ve coded anything, but it’s like riding a bike: terrifying and dangerous. Modeling languages are fair game though! . Your assignment . | Clarify the customers requirements into a requirements document | Distill the requirements document down into a formal specification | Come up with an architecture based on the requirements | . By the end of this, coding the solution should be a piece of cake. Note: The client has only contracted us to build the backend software and expose APIs. A different firm is handling the frontend. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/enterprise-architect/#introduction",
    "relUrl": "/business-logic/enterprise-architect/#introduction"
  },"73": {
    "doc": "Enterprise Architect gets us started",
    "title": "Creating the requirements document",
    "content": "Through conversations with the customers, you have distilled their requirements into a standard format. Functional requirements . | ID | Requirement | . | 1 | The system SHALL have a Start Subscription endpoint | . | 1.1 |         that is web accessible as an HTTP endpoint | . | 2 | When a request is received by the Start Subscription endpoint | . | 2.1 |         if the requesting User is Subscribed, the request SHALL return with 409 Conflict | . | 2.2 |         if the requesting User is In Trial, the trial SHALL end and the requesting User SHALL be Subscribed | . | 2.3 |         if the requesting User is Not Subscribed the requesting User SHALL be Subscribed | . | 2.4 |         if the requesting User is scheduled to be Not Subscribed due to cancellation the requesting User SHALL remain Subscribed | . | 3 | The system SHALL have a Cancel Subscription endpoint | . | 3.1 |         that is web accessible as an HTTP endpoint | . | 4 | When a request is received by the Cancel Subscription endpoint | . | 4.1 |         if the requesting User is not Subscribed, the request SHALL return with 409 Conflict | . | 4.2 |         if the requesting User is Subscribed | . | 4.2.1 |                 the User SHALL be Not Subscribed at the end of the current month | . | 4.2.2 |                 if the user is Not Subscribed at the end of the current month they SHALL be Billed a Cancellation Fee | . | 5 | The system SHALL have a Start Trial endpoint | . | 5.1 |         that is web accessible as an HTTP endpoint | . | 6 | When a request is received by the Start Trial endpoint | . | 6.1 |         if the requesting User is Subscribed, or In Trial the request SHALL return with 409 Conflict | . | 6.2 |         if the requesting User has previously been Subscribed or In Trial the request SHALL return with 409 Conflict | . | 6.3 |         if the requesting User is has never been Subscribed or In Trial, that User SHALL be In Trial. Justification: we only want new users to be able to start a trial | . | 7 | The system SHALL have a Cancel Trial Endpoint endpoint | . | 7.1 |         that is web accessible as an HTTP endpoint | . | 8 | When a request is received by the Cancel Trial endpoint | . | 8.1 |         if the requesting User is not In Trial the request SHALL return with 409 Conflict | . | 8.2 |         if the requesting User is In Trial the User SHALL be Not Subscribed | . | 9 | The system SHALL have a Watch Video endpoint | . | 9.1 |         that is web accessible as an HTTP endpoint | . | 10 | When a request is received by the Watch Video endpoint | . | 10.1 |         if the requesting User is not In Trial or Subscribed the request SHALL return with 409 Conflict | . | 10.2 |         if the requesting User is In Trial or Subscribed the system SHALL allow the User to Watch Video | . | 11 | When a User is In Trial at the end of the month that the trial was started they SHALL be Subscribed | . | 12 | When a User becomes Subscribed | . | 12.1 |         they SHALL be Billed the Subscription Fee before the end of the month | . | 12.2 |         if the requesting User has Post Due Payments they SHALL be Billed in that amount before the end of the month, and Post Due Payments SHALL be zeroed | . | 13 | When a User is Subscribed at the start of a month, they SHALL be Billed the Subscription Fee | . | 14 | The system SHALL be able to interface with the Payment Processor | . | 14.1 |         it SHALL be able to call the Bill endpoint of the Payment Processor | . | 14.2 |         it SHALL have a Payment Failed endpoint that can accept the Payment Processor callback | . | 15 | When a User is Billed the system SHALL call the Bill endpoint of the Payment Processor | . | 16 | When a callback is received to the Payment Failed endpoint for a User the system SHALL | . | 16.1 |         mark the User as Not Subscribed | . | 16.2 |         set Post Due Payments for the User to: (failed payment amount) + Failed Payment Fee | . Non-Functional requirements . | ID | Requirement | . | 1 | The latency of all endpoints SHOULD be &lt; 1 second | . | 2 | Data SHALL be encrypted at rest | . | 3 | Data SHALL be encrypted in transit | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/enterprise-architect/#creating-the-requirements-document",
    "relUrl": "/business-logic/enterprise-architect/#creating-the-requirements-document"
  },"74": {
    "doc": "Enterprise Architect gets us started",
    "title": "Requirements summary",
    "content": "You feel confident that you’ve gathered all the necessary requirements to ensure successful delivery on the contract. There are 44 requirements including sub-clauses, which is not that many, but you’re worried some might be forgotten due to the tight deliverable schedule. Formal modeling seems like a good way to ensure that doesn’t happen, but first you need to come up with an architecture. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/enterprise-architect/#requirements-summary",
    "relUrl": "/business-logic/enterprise-architect/#requirements-summary"
  },"75": {
    "doc": "Enterprise Architect gets us started",
    "title": "Architecture",
    "content": "Based on the requirements, it’s safe to chose a simple architecture, with an autoscaling group of Business Logic Servers that access a Database hosted in a replica set. There is also an external Payment Processor that can accept bills, and occasionally provide Payment Failed callbacks. Payment ProcessorDatabaseDatabase ConnectionBusiness Logic ServersClientsPayment Failed(user)Bill(user, amount)Start Subscription(user)Cancel Subscription(user)Start Trial(user)Cancel Trial(user)Watch Video(user)uses Now that you’ve come up with the architecture, you’re satisfied that it will work within the requirements and your team won’t have any trouble with it. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/enterprise-architect/#architecture",
    "relUrl": "/business-logic/enterprise-architect/#architecture"
  },"76": {
    "doc": "Enterprise Architect gets us started",
    "title": "Creating the Formal Specification Model",
    "content": "Looking over the requirements, it’s clear that only the Functional Requirements can be modeled. That might not always be true, but in this case they only influence implementation details and not the Business Logic itself. You don’t want to provide the implementation details; after all, that’s not your job. You need to write the spec in an implementation-agnostic way. The state machine . You create a state machine of the user workflow. The state machine here will not necessarily translate directly to a model, but it’s still useful to have. NotSubscribedSubscriptionStartedTrialStartedMonthElapsedTrialCanceledSubscriptionCanceledPaymentFailedOnly if not subscribed or had trial Data Model . The data model is shared between the specification and all the implementations. It lays out all the event types used for observability. | Next Section | Download Code | Download PDF | . Show Code Show LaTex --------------------------- MODULE specdatamodels --------------------------- \\* This module will be imported into every implementation EXTENDS Sequences (***************************************************************************) (* An ordered event stream of every event that occurs in the system. *) (* All the specifications will be written based on it. *) (* This is an observability value that you wouldn't have access to in the *) (* implementation. We'll only have the API method stubs write to it; no *) (* implementation may read from it. This will be enforced with code review *) (***************************************************************************) VARIABLE events \\* Represents every potential user in the system CONSTANT USERS \\* Constants that should be set to single model values to allow comparisons. \\* Only equality comparisons will be made. CONSTANTS SubscriptionFee, CancellationFee, FailedPaymentFee Fees == {SubscriptionFee, CancellationFee, FailedPaymentFee} (***************************************************************************) (* Event Types: Describes everything that can happen in the system *) (***************************************************************************) MonthPassEvent == [type : {\"monthpass\"}] StartSubscriptionEvent == [type : {\"startsubscription\"}, user: USERS] CancelSubscriptionEvent == [type : {\"cancelsubscription\"}, user: USERS] StartTrialEvent == [type : {\"starttrial\"}, user: USERS] CancelTrialEvent == [type : {\"canceltrial\"}, user: USERS] WatchVideoEvent == [type : {\"watchvideo\"}, user: USERS] BillEvent == [type : {\"bill\"}, user: USERS, fee: Fees] PaymentFailedEvent == [type : {\"paymentfailed\"}, user: USERS, fee: Fees] Event == MonthPassEvent \\union StartSubscriptionEvent \\union CancelSubscriptionEvent \\union StartTrialEvent \\union CancelTrialEvent \\union WatchVideoEvent \\union BillEvent \\union PaymentFailedEvent EventsOk == events \\in Seq(Event) ============================================================================= \\* Modification History \\* Last modified Fri Jun 17 00:07:38 MST 2022 by elliotswart \\* Created Thu Jun 16 20:19:00 MST 2022 by elliotswart . Specification . You trace every requirement above to the specification. This is to ensure that every requirement is either represented formally or deliberately excluded. | Next Section | Download Code | Download PDF | . Show Code Show LaTex -------------------------------- MODULE speccannonical -------------------------------- EXTENDS Naturals, Sequences, FiniteSets (***************************************************************************) (* Redeclaration of specdatamodels variables *) (***************************************************************************) VARIABLE events CONSTANT USERS CONSTANTS SubscriptionFee, CancellationFee, FailedPaymentFee (***************************************************************************) (* Logic to Test *) (* Replace stubs below with implementation. Because there is no forward *) (* declaration, we invert what we'd ideally like to do, which is to import *) (* the requirements into each implementation. Our logic testing relies on *) (* determining if a given state is enabled or not. *) (***************************************************************************) VARIABLE database, month INSTANCE stubs Spec == Init /\\ [][Next]_vars (***************************************************************************) (* Trace requirements to specification *) (* *) (* Not Traceable *) (* Functional: 1,2,3,6,7,9,14 *) (* NonFunctional: 1,2,3 *) (***************************************************************************) (***************************************************************************) (* Definitions *) (***************************************************************************) InTrial(u, end) == \\E i \\in 1..end: /\\ events[i] \\in StartTrialEvent \\* Has started trial /\\ events[i].user = u (*******************************************************************) (* 6. Start Trial endpoint request *) (* 6.3 If the requesting User has never been Subscribed or In *) (* Trial, that User SHALL be In Trial *) (*******************************************************************) /\\ ~\\E j \\in i..end: \\* And not canceled /\\ events[j] \\in (************************************************************) (* 8 Cancel Trial endpoint request *) (* 8.2 [Partial] If the requesting User is In Trial, the *) (* User SHALL be Not Subscribed *) (************************************************************) CancelTrialEvent \\union (************************************************************) (* 2. Start Subscription endpoint request *) (* 2.2 If the requesting User is In Trial, the trial SHALL *) (* end and the requesting User SHALL be Subscribed *) (************************************************************) StartSubscriptionEvent /\\ events[j].user = u (*******************************************************************) (* 11 [Partial] When a User is In Trial at the end of the month *) (* that the trial was started, they SHALL be Subscribed *) (*******************************************************************) /\\ ~\\E j \\in i..end: /\\ events[j] \\in MonthPassEvent UnsubscribedAfterEvent(u, i, end) == \\E j \\in i..end: \\* And not unsubscribed after /\\ events[j] \\notin MonthPassEvent /\\ events[j].user = u (************************************************************) (* Cancel Subscription endpoint request *) (* 4.2.1 User SHALL be Not Subscribed at the end of the *) (* current month *) (************************************************************) /\\ \\/ /\\ events[j] \\in CancelSubscriptionEvent /\\ \\E k \\in j..end: events[k] \\in MonthPassEvent (************************************************************) (* 16. User has payment failed *) (* 16.1 mark the User as Not Subscribed *) (************************************************************) \\/ events[j] \\in PaymentFailedEvent SubscribedFromStartSubscription(u, end) == (*******************************************************************) (* 2.4 If the requesting User is scheduled to be Not Subscribed *) (* due to cancellation, the requesting User SHALL remain *) (* Subscribed *) (* Implemented because a StartSubscriptionEvent after Cancel *) (* undoes the cancel. *) (*******************************************************************) \\E i \\in 1..end: /\\ events[i] \\in StartSubscriptionEvent \\* Has subscribed /\\ events[i].user = u /\\ ~UnsubscribedAfterEvent(u, i, end) AboutToCancel(u, end) == \\E i \\in 1..end: /\\ events[i] \\in CancelSubscriptionEvent /\\ ~\\E j \\in i..end: events[j] \\in MonthPassEvent \\union StartSubscriptionEvent SubscribedFromTrial(u, end) == (*******************************************************************) (* 11 [Partial] When a User is In Trial at the end of the month *) (* that the trial was started, they SHALL be Subscribed *) (*******************************************************************) \\E i \\in 1..end: /\\ events[i] \\in StartTrialEvent \\* Has started trial /\\ events[i].user = u /\\ ~InTrial(u, end) \\* Requirement fulfilled through InTrial /\\ ~UnsubscribedAfterEvent(u, i, end) (************************************************************) (* Cancel Trial endpoint request *) (* 8.2 [Partial] If the requesting User is In Trial, the *) (* User SHALL be Not Subscribed *) (************************************************************) /\\ ~\\E j \\in i..end: \\* And not canceled /\\ events[j] \\in CancelTrialEvent /\\ events[j].user = u Subscribed(u, end) == \\/ SubscribedFromStartSubscription(u, end) \\/ SubscribedFromTrial(u, end) (***************************************************************************) (* Invariants *) (***************************************************************************) (***************************************************************************) (* 2 When a request is received by the Start Subscription endpoint *) (***************************************************************************) StartSubscriptionAccessControl == \\A u \\in USERS: LET authorized == ~Subscribed(u, Now) \\/ AboutToCancel(u, Now) IN (*******************************************************************) (* 2.1: If the requesting User is Subscribed, the request SHALL *) (* return with 409 Conflict *) (*******************************************************************) \\/ /\\ ~authorized /\\ ~ENABLED StartSubscription(u) (*******************************************************************) (* 2.2 [Partial]: If the requesting User is In Trial, the trial *) (* SHALL end and the requesting User SHALL be Subscribed *) (*******************************************************************) (*******************************************************************) (* 2.3: If the requesting User is Not Subscribed, the requesting *) (* User SHALL be Subscribed *) (*******************************************************************) \\/ /\\ authorized /\\ ENABLED StartSubscription(u) (***************************************************************************) (* 4 When a request is received by the Cancel Subscription endpoint *) (***************************************************************************) CancelSubscriptionAccessControl == \\A u \\in USERS: LET authorized == Subscribed(u, Now) /\\ ~AboutToCancel(u, Now) IN (*******************************************************************) (* 4.1 If the requesting User is not Subscribed, the request SHALL *) (* return with 409 Conflict *) (*******************************************************************) \\/ /\\ ~authorized /\\ ~ENABLED CancelSubscription(u) (*******************************************************************) (* 4.2 [Partial]: If the requesting User is Subscribed, the User *) (* SHALL ... [Cancellation Requirements] *) (*******************************************************************) \\/ /\\ authorized /\\ ENABLED CancelSubscription(u) (***************************************************************************) (* 6.3 [Partial] If the requesting User is has never been Subscribed, *) (* or is In Trial *) (***************************************************************************) EligibleForTrial(u) == ~\\E i \\in 1..Len(events): /\\ events[i] \\in StartSubscriptionEvent \\union StartTrialEvent /\\ events[i].user = u (***************************************************************************) (* 6 When a request is received by the Start Trial endpoint *) (***************************************************************************) StartTrialAccessControl == \\A u \\in USERS: (*******************************************************************) (* 6.1 If the requesting User is Subscribed or In Trial, the *) (* request SHALL return with 409 Conflict *) (*******************************************************************) (*******************************************************************) (* 6.2 If the requesting User has previously been Subscribed or *) (* In Trial, the request SHALL return with 409 Conflict *) (*******************************************************************) \\/ /\\ ~EligibleForTrial(u) /\\ ~ENABLED StartTrial(u) (*******************************************************************) (* 6.3 If the requesting User has never been Subscribed or *) (* In Trial, that User SHALL be In Trial *) (*******************************************************************) \\/ /\\ EligibleForTrial(u) /\\ ENABLED StartTrial(u) (***************************************************************************) (* 8 When a request is received by the Cancel Trial endpoint *) (***************************************************************************) CancelTrialAccessControl == \\A u \\in USERS: (*******************************************************************) (* 8.1 If the requesting User is not In Trial, the request SHALL *) (* return with 409 Conflict *) (*******************************************************************) \\/ /\\ ~InTrial(u, Now) /\\ ~ENABLED CancelTrial(u) (*******************************************************************) (* 8.2 [Partial] If the requesting User is In Trial, the User *) (* SHALL be Not Subscribed *) (*******************************************************************) \\/ /\\ InTrial(u, Now) /\\ ENABLED CancelTrial(u) (***************************************************************************) (* 10 When a request is received by the Watch Video endpoint *) (***************************************************************************) WatchVideoAccessControl == \\A u \\in USERS: (*******************************************************************) (* 10.1 If the requesting User is not In Trial or Subscribed, the *) (* request SHALL return with 409 Conflict *) (*******************************************************************) \\/ /\\ ~InTrial(u, Now) /\\ ~Subscribed(u, Now) /\\ ~ENABLED WatchVideo(u) (*******************************************************************) (* 10.2 If the requesting User is In Trial or Subscribed, the *) (* system SHALL allow the User to Watch Video *) (*******************************************************************) \\/ /\\ InTrial(u, Now) \\/ Subscribed(u, Now) /\\ ENABLED WatchVideo(u) (***************************************************************************) (* Runs a given operation between: 1 - first month for the first month, *) (* and month i - month i + 1 *) (***************************************************************************) TrueForEveryUserMonth(op(_,_,_), checkFirstMonth) == LET numMonthPass == Cardinality({i \\in 1..Len(events): events[i] \\in MonthPassEvent}) IN \\* If checking the first month /\\ \\/ ~checkFirstMonth \\/ /\\ checkFirstMonth \\* There does not exist /\\ ~\\E i \\in 1..Len(events): \\* a first month /\\ events[i] \\in MonthPassEvent /\\ ~\\E j \\in 1..i: events[j] \\in MonthPassEvent \\* Where the op is false for any user /\\ \\E u \\in USERS: ~op(u,1,i) \\* There does not exist a pair of consecutive months /\\ ~\\E i \\in 1..Len(events): /\\ events[i] \\in MonthPassEvent /\\ \\E j \\in i+1..Len(events): /\\ events[j] \\in MonthPassEvent /\\ ~\\E k \\in (i + 2)..(j-1): events[k] \\in MonthPassEvent \\* where op is not true for all users /\\ \\E u \\in USERS: ~op(u,i,j) (***************************************************************************) (* 15 When a User is Billed the system SHALL call the Bill endpoint *) (* of the Payment Processor. *) (* This requirement is satisfied by how requirements 4.2.2, 12 and 13 *) (* are tested. They test that appropriate Bill message was dispatched *) (***************************************************************************) (***************************************************************************) (* 12 When a User becomes Subscribed *) (***************************************************************************) (***************************************************************************) (* 12.1 they shall be Billed the Subscription Fee before the end of the *) (* month *) (***************************************************************************) SubscribedThisMonth(u, start, end) == /\\ ~Subscribed(u, start) /\\ Subscribed(u, end-1) UserSubscribedThisMonthBilledSubscriptionFee(u, start, end) == LET shouldBill == SubscribedThisMonth(u, start, end) IN \\* Only applies if subscribed this month \\/ ~shouldBill \\/ /\\ shouldBill /\\ \\E i \\in start..end: /\\ events[i] \\in BillEvent /\\ events[i].user = u /\\ events[i].fee = SubscriptionFee SubscribedNewUsersBilledSubscriptionFee == TrueForEveryUserMonth(UserSubscribedThisMonthBilledSubscriptionFee, TRUE) (***************************************************************************) (* 13 When a User is Subscribed at the start of a month, they shall be *) (* Billed the Subscription Fee *) (***************************************************************************) SubscribedUserBilledThisMonth(u, start, end) == LET subscribed == Subscribed(u, start) IN \\* Only applies if subscribed at start of month \\/ ~subscribed \\/ /\\ subscribed /\\ \\/ \\E i \\in start..end: /\\ events[i] \\in BillEvent /\\ events[i].user = u /\\ events[i].fee = SubscriptionFee \\* If the user failed a payment this is a separate workflow \\/ \\E i \\in start..end: /\\ events[i] \\in PaymentFailedEvent /\\ events[i].user = u SubscribedUsersBilledStartOfMonth == TrueForEveryUserMonth(SubscribedUserBilledThisMonth, FALSE) (***************************************************************************) (* 12.2 If the requesting User has Post Due Payments they SHALL be *) (* Billed in that amount before the end of the month, and *) (* Post Due Payments shall be zeroed *) (***************************************************************************) (***************************************************************************) (* 16 When a callback is received to the Payment Failed endpoint for a *) (* User, the system SHALL *) (* 16.2 set Post Due Payment for the User to: *) (* (failed payment amount) + CancellationFee *) (***************************************************************************) PotentialStartingEvent(u, event) == /\\ event \\in StartSubscriptionEvent \\union StartTrialEvent /\\ event.user = u IsPaymentFailedEvent(u, event) == /\\ event \\in PaymentFailedEvent /\\ event.user = u UserBilledForFailureBetweenRange(u, start, end, fee) == \\E i \\in start..end: /\\ events[i] \\in BillEvent /\\ events[i].user = u /\\ events[i].fee = FailedPaymentFee UserBilledForPostDuePaymentsIfSubscribed(u, start, end) == LET starts == {i \\in 1..start: PotentialStartingEvent(u, events[i])} IN LET paymentFailed == {i \\in 1..start:IsPaymentFailedEvent(u, events[i])} IN \\A p \\in paymentFailed: LET resubscribedAfterFailedPayment == \\E i \\in p..end: /\\ i \\in starts IN \\/ ~resubscribedAfterFailedPayment \\/ /\\ resubscribedAfterFailedPayment \\* There doesn't exist a failed payment /\\ ~\\E i \\in p..end: \\* That has a subscription directly after it /\\ i \\in starts /\\ ~\\E j \\in p..i: j \\in starts \\* Where the user was not billed for the failed payment /\\ ~UserBilledForFailureBetweenRange(u, i, end, events[p].fee) SubscribedUsersBilledPostDuePayements == TrueForEveryUserMonth(UserBilledForPostDuePaymentsIfSubscribed, TRUE) (***************************************************************************) (* 4 Cancel Subscription endpoint *) (* 4.2.2 if the user is Not Subscribed at the end of the current month, *) (* they SHALL be Billed a Cancellation Fee *) (***************************************************************************) UserCancelledLastMonth(u, start, end) == \\* start - 1 because it doesn't count cancellations that take effect \\* at start /\\ Subscribed(u, start-1) /\\ ~Subscribed(u, start) UserCancelledLastMonthBilled(u, start, end) == \\* Only applies if user cancelled this month \\/ ~UserCancelledLastMonth(u, start, end) \\/ /\\ UserCancelledLastMonth(u, start, end) /\\ \\/ \\E i \\in start..end: /\\ events[i] \\in BillEvent /\\ events[i].user = u /\\ events[i].fee = CancellationFee \\* If the user failed a payment this is a separate workflow \\/ \\E i \\in start..end: /\\ events[i] \\in PaymentFailedEvent /\\ events[i].user = u CancelingUsersBilledCancelationFees == TrueForEveryUserMonth(UserCancelledLastMonthBilled, FALSE) (***************************************************************************) (* State Constraints *) (***************************************************************************) EventLengthLimit == Len(events) &lt; 10 MonthLimit == LET monthPassEvents == SelectSeq(events, LAMBDA x: x.type = \"monthpass\") IN Len(monthPassEvents) &lt; 5 StateLimit == /\\ EventLengthLimit /\\ MonthLimit ============================================================================= \\* Modification History \\* Last modified Sun Jun 19 17:43:11 MST 2022 by elliotswart \\* Created Thu Jun 16 19:34:18 MST 2022 by elliotswart . Stubs . You write initial stubs for all the API calls such that you can add appropriate observability. You also provide the basic architecture of the spec to keep the assignment bounded. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ------------------------------- MODULE stubs ------------------------------- (***************************************************************************) (* Redeclaration of specdatamodels variables *) (***************************************************************************) EXTENDS Sequences, Naturals, FiniteSets CONSTANT USERS CONSTANTS SubscriptionFee, CancellationFee, FailedPaymentFee VARIABLES \\* Represents the current month month, \\* Represents the status of the database. Design requirements require \\* that all persistant application state be stored here database, \\* Required by spec events vars == &lt;&lt;events, month, database&gt;&gt; \\* Provides all the data models required by the spec INSTANCE specdatamodels Now == Len(events) Months == 0..10 (***************************************************************************) (* Strong Typing *) (***************************************************************************) Month == Nat (***************************************************************************) (* Database Rows *) (***************************************************************************) TypeOk == /\\ EventsOk /\\ month \\in Month \\* Additional type definitions (***************************************************************************) (* API endpoints *) (***************************************************************************) StartSubscription(u) == \\* Add logic here \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"startsubscription\", user |-&gt; u]) /\\ UNCHANGED month CancelSubscription(u) == \\* Add logic here \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"cancelsubscription\", user |-&gt; u]) /\\ UNCHANGED &lt;&lt;month&gt;&gt; StartTrial(u) == \\* Add logic here \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"starttrial\", user |-&gt; u]) /\\ UNCHANGED &lt;&lt;month&gt;&gt; CancelTrial(u) == \\* Add logic here \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"canceltrial\", user |-&gt; u]) /\\ UNCHANGED &lt;&lt;month&gt;&gt; WatchVideo(u) == \\* Add logic here \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"watchvideo\", user |-&gt; u]) /\\ UNCHANGED &lt;&lt;month, database&gt;&gt; \\* Stub method, do not change Bill(u, fee) == /\\ events' = Append(events, [type |-&gt; \"bill\", user |-&gt; u, fee |-&gt; fee]) PaymentFailed(u, fee) == \\* Add logic here \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"paymentfailed\", user |-&gt; u , fee |-&gt; fee]) /\\ UNCHANGED &lt;&lt;month&gt;&gt; (***************************************************************************) (* Recurring Operations *) (***************************************************************************) \\* This the the state that calls the Payment Failed API ExistingBillFailed == \\/ \\E i \\in 1..Len(events): \\* Only a past bill can fail /\\ events[i] \\in BillEvent /\\ PaymentFailed(events[i].user, events[i].fee) (***************************************************************************) (* Stub method that prevents the month from passing until all operations *) (* are complete. Represent worker methods, etc *) (***************************************************************************) HandledMonth == \\* Replace logic here /\\ True \\* DO NOT MODIFY MonthPasses == /\\ HandledMonth /\\ month' = month + 1 /\\ events' = Append(events, [type |-&gt; \"monthpass\"]) /\\ UNCHANGED &lt;&lt;database&gt;&gt; (***************************************************************************) (* Specification *) (***************************************************************************) Init == /\\ events = &lt;&lt;&gt;&gt; \\* Events must be initialized empty, per stub /\\ month = 0 /\\ database = [] \\* Add record here Next == \\* Required by stub \\/ MonthPasses \\* State modified below \\/ \\E u \\in USERS: \\/ StartSubscription(u) \\/ CancelSubscription(u) \\/ StartTrial(u) \\/ CancelTrial(u) \\/ WatchVideo(u) \\* Add more user based states \\* Payment failing behavior is part of spec not implementation \\/ ExistingBillFailed \\* Add more global states ============================================================================= \\* Modification History \\* Last modified Sun Jun 19 15:35:00 MST 2022 by elliotswart \\* Created Thu Jun 16 19:34:32 MST 2022 by elliotswart . Note: Generally you expect the first formal spec you write won’t be perfect. If failures are being reported when they shouldn’t, the spec may need to be revised. There’s a collaborative process as the spec gets refined and becomes accurate. We’ve removed that from this narrative for simplicity. Assume there was a back-and-forth and you’re seeing the 3rd revision of the spec above. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/enterprise-architect/#creating-the-formal-specification-model",
    "relUrl": "/business-logic/enterprise-architect/#creating-the-formal-specification-model"
  },"77": {
    "doc": "Enterprise Architect gets us started",
    "title": "Summary",
    "content": "Satisfied that you have specified and architected the system about as well as you can, you pass it off to a junior developer to implement. You work for a contracting firm. How else are you supposed to pay the bills? . | Next: Junior Developer tries their best | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/enterprise-architect/#summary",
    "relUrl": "/business-logic/enterprise-architect/#summary"
  },"78": {
    "doc": "Principal Engineer saves the day",
    "title": "Principal Engineer saves the day",
    "content": ". | Your bio | The assignment | Modeling the solution | Verifying the solution | Design and its effect on automated testing | Retrospective | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/principal-eng/",
    "relUrl": "/business-logic/principal-eng/"
  },"79": {
    "doc": "Principal Engineer saves the day",
    "title": "Your bio",
    "content": "At the age of three you killed Python and wore it as a hat. You have a resume a mile long from all your successfully completed projects, and a thousand yard stare from the ones you couldn’t save. You’ll probably be a programmer forever, if only because semi-pro competitive tap dance just doesn’t pay the bills. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/principal-eng/#your-bio",
    "relUrl": "/business-logic/principal-eng/#your-bio"
  },"80": {
    "doc": "Principal Engineer saves the day",
    "title": "The assignment",
    "content": ". | Simplify the junior developer’s solution. | Use the model checker to verify that your elegant solution is, as Einstein would say, “as simple as possible but no simpler.” | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/principal-eng/#the-assignment",
    "relUrl": "/business-logic/principal-eng/#the-assignment"
  },"81": {
    "doc": "Principal Engineer saves the day",
    "title": "Modeling the solution",
    "content": "Using the model checker as a guide, you refactor the solution to denormalize the data model somewhat. Whenever possible, you convert logic to simple database transactions. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ----------------------------- MODULE principal ----------------------------- (***************************************************************************) (* Redeclaration of specdatamodels variables *) (***************************************************************************) EXTENDS Sequences, Naturals, FiniteSets CONSTANT USERS CONSTANTS SubscriptionFee, CancellationFee, FailedPaymentFee VARIABLES month, database, events vars == &lt;&lt;events, month, database&gt;&gt; INSTANCE specdatamodels Now == Len(events) Months == 0..10 (***************************************************************************) (* Strong Typing *) (***************************************************************************) Month == Nat (***************************************************************************) (* Database Rows *) (***************************************************************************) VideoAccessRow == [type : {\"enabled\", \"disabled\"}] \\union [ type : {\"disabledasoftimestamp\"}, disabledtime: Month ] TrialStatusRow == [type: {\"eligible\", \"ineligible\", \"cancelled\"}] \\union [ type : {\"started\"}, endtime: Month ] SubscriptionStatusRow == [ type: {\"notsubscribed\", \"subscribed\", \"tocancel\"}] \\union [ type: {\"tocancel\"}, canceltime: Month ] UpcomingChargeItem == [fee : Fees, event: Nat] TypeOk == /\\ EventsOk /\\ month \\in Month \\* Represents a singleton record type tracking the billing month /\\ database.billingMonth \\in Month \\* Table with VideoAccessRow definition /\\ database.videoAccess \\in [USERS -&gt; VideoAccessRow] \\* Table with TrialStatusRow definition /\\ database.trial \\in [USERS -&gt; TrialStatusRow] \\* Table with SubscriptionStatusRow definition /\\ database.subscription \\in [USERS -&gt; SubscriptionStatusRow] \\* A row index, by user and month, that holds UpcomingCharges /\\ database.upcomingCharges \\in [USERS -&gt; [Months -&gt; SUBSET UpcomingChargeItem]] \\* Table with PastDueStatus row definition /\\ database.inGoodStanding \\in [USERS -&gt; BOOLEAN] (***************************************************************************) (* API endpoints *) (***************************************************************************) \\* Database query: IsSubscribed(u) == \\/ database.subscription[u].type = \"subscribed\" \\* A converted trial that hasn't been processed in database \\/ /\\ database.trial[u].type = \"started\" /\\ database.trial[u].endtime &lt;= month StartSubscription(u) == LET paymentFailedCharges == IF database.inGoodStanding[u] = TRUE THEN {} ELSE {[event |-&gt; Now, fee |-&gt; FailedPaymentFee]} IN LET thisMonthsCharges == database.upcomingCharges[u][month] \\union \\* Add payment failed fee if applicable paymentFailedCharges IN \\* Remove cancellation fee for next month LET nextMonthsCharges == { c \\in database.upcomingCharges[u][month+1]: c.fee # CancellationFee } IN \\* Transaction precondition /\\ ~IsSubscribed(u) \\* Transaction /\\ database' = [database EXCEPT ![\"inGoodStanding\"][u] = TRUE, ![\"subscription\"][u] = [type |-&gt; \"subscribed\"], ![\"trial\"][u] = [type |-&gt; \"ineligible\"], ![\"videoAccess\"][u] = [type |-&gt; \"enabled\"], \\* Add charges ![\"upcomingCharges\"][u][month] = thisMonthsCharges, ![\"upcomingCharges\"][u][month+1] = nextMonthsCharges ] \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"startsubscription\", user |-&gt; u]) /\\ UNCHANGED month CancelSubscription(u) == LET cancelTime == month + 1 IN LET cancellationFee == [ event |-&gt; Now, fee |-&gt; CancellationFee] IN LET subscriptionFee == [event |-&gt; Now, fee |-&gt; SubscriptionFee] IN \\* Adds subscription fee for this month if not already added LET thisMonthsCharges == IF ~\\E charge \\in database.upcomingCharges[u][month]: charge.fee = SubscriptionFee THEN database.upcomingCharges[u][month] \\union {subscriptionFee} ELSE database.upcomingCharges[u][month] IN \\* Transaction precondition /\\ IsSubscribed(u) \\* Transaction /\\ database' = [database EXCEPT ![\"trial\"][u] = [type |-&gt; \"ineligible\"], ![\"subscription\"][u] = [type |-&gt; \"tocancel\", canceltime |-&gt; cancelTime], ![\"videoAccess\"][u] = [type |-&gt; \"disabledasoftimestamp\", disabledtime |-&gt; cancelTime], ![\"upcomingCharges\"][u][month] = thisMonthsCharges, \\* Queue up cancellation fee for next month ![\"upcomingCharges\"][u][month + 1] = database.upcomingCharges[u][month] \\union {cancellationFee} ] \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"cancelsubscription\", user |-&gt; u]) /\\ UNCHANGED &lt;&lt;month&gt;&gt; StartTrial(u) == LET endTime == month + 1 IN \\* Transaction precondition /\\ database.trial[u].type = \"eligible\" \\* Transaction /\\ database' = [database EXCEPT ![\"trial\"][u] = [type |-&gt; \"started\", endtime |-&gt; endTime], ![\"videoAccess\"][u] = [type |-&gt; \"enabled\"] ] \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"starttrial\", user |-&gt; u]) /\\ UNCHANGED &lt;&lt;month&gt;&gt; CancelTrial(u) == \\* Transaction precondition /\\ database.trial[u].type = \"started\" \\* The trial has not already ended /\\ database.trial[u].endtime &gt; month \\* Transaction /\\ database' = [database EXCEPT ![\"trial\"][u] = [type |-&gt; \"cancelled\"], ![\"videoAccess\"][u] = [type |-&gt; \"disabled\"] ] \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"canceltrial\", user |-&gt; u]) /\\ UNCHANGED &lt;&lt;month&gt;&gt; \\* Database query WatchVideoAuthorized(u) == \\/ database.videoAccess[u].type = \"enabled\" \\/ /\\ database.videoAccess[u].type = \"disabledasoftimestamp\" /\\ database.videoAccess[u].disabledtime &gt; month WatchVideo(u) == /\\ WatchVideoAuthorized(u) \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"watchvideo\", user |-&gt; u]) /\\ UNCHANGED &lt;&lt;month, database&gt;&gt; Bill(u, fee) == /\\ events' = Append(events, [type |-&gt; \"bill\", user |-&gt; u, fee |-&gt; fee]) PaymentFailed(u, fee) == /\\ database' = [database EXCEPT ![\"inGoodStanding\"][u] = FALSE, ![\"subscription\"][u] = [type |-&gt; \"notsubscribed\"], ![\"trial\"][u] = [type |-&gt; \"ineligible\"], ![\"videoAccess\"][u] = [type |-&gt; \"disabled\"], \\* Remove all upcoming changes ![\"upcomingCharges\"][u][month] = {}, ![\"upcomingCharges\"][u][month+1] = {} ] /\\ events' = Append(events, [type |-&gt; \"paymentfailed\", user |-&gt; u , fee |-&gt; fee]) /\\ UNCHANGED &lt;&lt;month&gt;&gt; (***************************************************************************) (* Recurring Operations *) (***************************************************************************) \\* This the the state that calls the Payment Failed API ExistingBillFailed == \\/ \\E i \\in 1..Len(events): \\* Only a past bill can fail /\\ events[i] \\in BillEvent /\\ PaymentFailed(events[i].user, events[i].fee) \\* Trial users that have passed trial period are subscribed ConvertTrialUser(u) == /\\ database.trial[u].type = \"started\" /\\ database.trial[u].endtime &lt;= month \\* The trial has ended \\* Transaction /\\ database' = [database EXCEPT ![\"subscription\"][u] = [type |-&gt; \"subscribed\"], ![\"trial\"][u] = [type |-&gt; \"ineligible\"], ![\"videoAccess\"][u] = [type |-&gt; \"enabled\"] ] /\\ UNCHANGED &lt;&lt;month, events&gt;&gt; \\* Cancelled users that have passed cancellation period are unsubscribed ProcessCancelledUser(u) == /\\ database.subscription[u].type = \"tocancel\" /\\ database.subscription[u].canceltime &lt;= month /\\ database' = [database EXCEPT \\* unsubscribe ![\"subscription\"][u] = [type |-&gt; \"notsubscribed\"] ] /\\ UNCHANGED &lt;&lt;month, events&gt;&gt; \\* Any subscribed user is billed this month BillUserForSubscription(u) == LET subscriptionFee == [event |-&gt; Now, fee |-&gt; SubscriptionFee] IN /\\ database.subscription[u].type = \"subscribed\" \\* Add subscription fee for this month /\\ database' = [database EXCEPT ![\"upcomingCharges\"][u][month] = database.upcomingCharges[u][month] \\union {subscriptionFee} ] /\\ UNCHANGED &lt;&lt;month, events&gt;&gt; \\* Bill users for their current month charges ProcessCharges == /\\ \\E u \\in USERS: LET monthlyCharges == database.upcomingCharges[u][month] IN \\* If there are upcoming charges for this month /\\ Cardinality(monthlyCharges) &gt; 0 \\* Dequeue a bill /\\ \\E charge \\in monthlyCharges: \\* Submit to payment processor /\\ Bill(u, charge.fee) \\* Delete from queue /\\ database' = [database EXCEPT ![\"upcomingCharges\"][u][month] = monthlyCharges \\ {charge} ] /\\ UNCHANGED month (***************************************************************************) (* Stub method that prevents the month from passing until all operations *) (* are complete. Represent worker methods, etc. *) (***************************************************************************) HandledMonth == /\\ ~ENABLED ProcessCharges /\\ \\A u \\in USERS: /\\ ~ENABLED ConvertTrialUser(u) /\\ ~ENABLED ProcessCancelledUser(u) /\\ ~ENABLED BillUserForSubscription(u) \\* DO NOT MODIFY MonthPasses == /\\ HandledMonth /\\ month' = month + 1 /\\ events' = Append(events, [type |-&gt; \"monthpass\"]) /\\ UNCHANGED &lt;&lt;database&gt;&gt; (***************************************************************************) (* Specification *) (***************************************************************************) Init == /\\ events = &lt;&lt;&gt;&gt; \\* Events must be intialized empty, per stub /\\ month = 0 /\\ database = [ \\* No months have been billed for yet billingMonth |-&gt; 0, \\* No user starts with access videoAccess |-&gt; [u \\in USERS |-&gt; [type |-&gt; \"disabled\"]], \\* Every user starts eligible for trial trial |-&gt; [u \\in USERS |-&gt; [type |-&gt; \"eligible\"]], \\* Every user starts not subscribed subscription |-&gt; [u \\in USERS |-&gt; [type |-&gt; \"notsubscribed\"]], \\* All users start in good standing inGoodStanding |-&gt; [u \\in USERS |-&gt; TRUE], \\* No bills to submit upcomingCharges |-&gt; [u \\in USERS |-&gt; [x \\in Months |-&gt; {}]] ] (* Next == \\* Required by stub \\/ MonthPasses \\* State modified below \\/ \\E u \\in USERS: \\/ StartSubscription(u) \\/ CancelSubscription(u) \\/ StartTrial(u) \\/ CancelTrial(u) \\/ WatchVideo(u) \\/ ConvertTrialUser(u) \\/ ProcessCancelledUser(u) \\/ ConvertTrialUser(u) \\/ BillUserForSubscription(u) \\* Payment failing behavior is part of spec, not implementation \\/ ExistingBillFailed \\/ ProcessCharges *) ============================================================================= \\* Modification History \\* Last modified Sun Jun 19 17:45:52 MST 2022 by elliotswart \\* Created Fri Jun 17 00:28:26 MST 2022 by elliotswart . You use the model checker periodically to ensure that the simplified design still hit requirements. Once you’re confident the design is sufficiently simple, you run a final test on your solution. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/principal-eng/#modeling-the-solution",
    "relUrl": "/business-logic/principal-eng/#modeling-the-solution"
  },"82": {
    "doc": "Principal Engineer saves the day",
    "title": "Verifying the solution",
    "content": "It passes. | Next Section | Download Configuration | . | State Name | Total States | Distinct States | . | All States | 7995363 | 1115416 | . Time to start building! . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/principal-eng/#verifying-the-solution",
    "relUrl": "/business-logic/principal-eng/#verifying-the-solution"
  },"83": {
    "doc": "Principal Engineer saves the day",
    "title": "Design and its effect on automated testing",
    "content": "When testing requirements, the standard approach is to map each requirement to one or more specific programmatic tests. For straightforward requirements with immediate triggers and effects, this is not a problem. An integration test can trigger the relevant action and observe the effect. For more complex requirements, those that are more woven into the design, this is challenging. Generally, you trace those requirements to a design document which describes how they are to be fulfilled. Senior engineers and/or architects sign off that the design meets the requirements. Then tests are planned to show conformance with the design. Formal modeling helps us with this process in two ways: . | The requirements can be explicitly mapped to a model | A specific design model can be tested against the requirement model | . The requirements can therefore be straightforwardly verified to be implemented by the design model. It’s far easier to test for sub-system and component compliance with the design model than with textual requirements. Automated requirement testing can often turn into glorified regression tests if a team is not careful. By testing to the design model instead, a team can ensure that critical system characteristics are maintained without over-specifying behavior. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/principal-eng/#design-and-its-effect-on-automated-testing",
    "relUrl": "/business-logic/principal-eng/#design-and-its-effect-on-automated-testing"
  },"84": {
    "doc": "Principal Engineer saves the day",
    "title": "Retrospective",
    "content": "Key takeaways from this series: . | Precise requirements documents can be modeled formally. | Sloppy logic and design are much more apparent in modeled designs than in code. | Modeled specifications allow you to refactor business logic confidently. | Modeling business requirements means that you can focus unit and integration testing on testing critical behavior. | . | Next: You made it to the end! Time to learn TLA+ | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/principal-eng/#retrospective",
    "relUrl": "/business-logic/principal-eng/#retrospective"
  },"85": {
    "doc": "Junior Developer tries their best",
    "title": "Junior Developer tries their best",
    "content": ". | Introduction . | Your bio | Your assignment | . | The first attempt . | Modeling | Verification | . | The second attempt . | Modeling | Verification | . | The working attempt . | Modeling | Verification | . | Next steps | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/junior-dev/",
    "relUrl": "/business-logic/junior-dev/"
  },"86": {
    "doc": "Junior Developer tries their best",
    "title": "Introduction",
    "content": "Your bio . You recently graduated from a good computer science program. Not only do you have a firm grasp on CS fundamentals, you’ve also taken electives in operating system and compiler design. None of that has been much help here, though. You keep waiting for someone to ask you to traverse a tree or write a new lexer for C, but you’re starting to fear that day will never come. Your assignment . | Try to create a solution that implements the Enterprise Architect’s specification. | Use the model checker to get your solution working. | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/junior-dev/#introduction",
    "relUrl": "/business-logic/junior-dev/#introduction"
  },"87": {
    "doc": "Junior Developer tries their best",
    "title": "The first attempt",
    "content": "Modeling . Note: We are assuming the junior programmer is fully competent in TLA+ and code style. Only the architectural and/or requirements knowledge will be lacking. You start with a simple and clean solution that meets the requirements as you understood them: . | Next Section | Download Code | Download PDF | . Show Code Show LaTex ------------------------------- MODULE juniorv1 ------------------------------- (***************************************************************************) (* Redeclaration of specdatamodels variables *) (***************************************************************************) EXTENDS Sequences, Naturals, FiniteSets CONSTANT USERS CONSTANTS SubscriptionFee, CancellationFee, FailedPaymentFee VARIABLES month, database, events vars == &lt;&lt;events, month, database&gt;&gt; INSTANCE specdatamodels Now == Len(events) Months == 0..10 (***************************************************************************) (* Strong Typing *) (***************************************************************************) Month == Nat (***************************************************************************) (* Database Rows *) (***************************************************************************) UserRow == [ subscribed: BOOLEAN, \\* Forget canceled inTrial: BOOLEAN, trialStartTime: Nat, billedForMonth: Nat ] BillQueueItem == [ user: USERS, fee: Fees ] TypeOk == /\\ EventsOk /\\ month \\in Month /\\ database.users \\in [USERS -&gt; UserRow] /\\ database.billQueue \\in Seq(BillQueueItem) (***************************************************************************) (* API endpoints *) (***************************************************************************) StartSubscription(u) == /\\ database.users[u].subscribed = FALSE /\\ database' = [database EXCEPT ![\"users\"][u].subscribed = TRUE ] \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"startsubscription\", user |-&gt; u]) /\\ UNCHANGED month CancelSubscription(u) == /\\ database.users[u].subscribed = TRUE /\\ database' = [database EXCEPT ![\"users\"][u].subscribed = FALSE, \\* Charge cancellation fee ![\"billQueue\"] = Append(database.billQueue, [user |-&gt; u, fee |-&gt; CancellationFee]) ] \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"cancelsubscription\", user |-&gt; u]) /\\ UNCHANGED &lt;&lt;month&gt;&gt; StartTrial(u) == /\\ database.users[u].inTrial = FALSE /\\ database.users[u].subscribed = FALSE /\\ database' = [database EXCEPT ![\"users\"][u].inTrial = TRUE] \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"starttrial\", user |-&gt; u]) /\\ UNCHANGED &lt;&lt;month&gt;&gt; CancelTrial(u) == /\\ database.users[u].inTrial = TRUE /\\ database' = [database EXCEPT ![\"users\"][u].inTrial = FALSE ] \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"canceltrial\", user |-&gt; u]) /\\ UNCHANGED &lt;&lt;month&gt;&gt; WatchVideo(u) == /\\ \\/ database.users[u].subscribed = TRUE \\/ database.users[u].inTrial = TRUE \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"watchvideo\", user |-&gt; u]) /\\ UNCHANGED &lt;&lt;month, database&gt;&gt; \\* Stub method, do not change Bill(u, fee) == /\\ events' = Append(events, [type |-&gt; \"bill\", user |-&gt; u, fee |-&gt; fee]) PaymentFailed(u, fee) == /\\ database' = [database EXCEPT ![\"users\"][u].subscribed = FALSE ] \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"paymentfailed\", user |-&gt; u , fee |-&gt; fee]) /\\ UNCHANGED &lt;&lt;month&gt;&gt; (***************************************************************************) (* Recurring Operations *) (***************************************************************************) \\* This the the state that calls the Payment Failed API ExistingBillFailed == \\/ \\E i \\in 1..Len(events): \\* Only a past bill can fail /\\ events[i] \\in BillEvent /\\ PaymentFailed(events[i].user, events[i].fee) BillSubscribedUsers == \\E u \\in USERS: \\* That is subscribed /\\ \\/ database.users[u].subscribed = TRUE \\* Subscribed from a trial so bill \\/ /\\ database.users[u].inTrial = TRUE /\\ database.users[u].trialStartTime &lt; month \\* Ensure users are not double billed /\\ database.users[u].billedForMonth &lt; month /\\ database' = [database EXCEPT \\* Add subscription fee ![\"billQueue\"] = Append(database.billQueue, [user |-&gt; u, fee |-&gt; SubscriptionFee]), ![\"users\"][u].billedForMonth = month ] ProcessBills == /\\ Len(database.billQueue) &gt; 0 /\\ LET bill == Head(database.billQueue) IN \\* Bills user /\\ Bill(bill.user, bill.fee) /\\ database' = [database EXCEPT \\* Removes head of queue ![\"billQueue\"] = SubSeq(database.billQueue, 2, Len(database.billQueue)) ] (***************************************************************************) (* Stub method that prevents the month from passing until all operations *) (* are complete. Represent worker methods, etc. *) (***************************************************************************) HandledMonth == /\\ ~ENABLED BillSubscribedUsers /\\ ~ENABLED ProcessBills \\* DO NOT MODIFY MonthPasses == /\\ HandledMonth /\\ month' = month + 1 /\\ events' = Append(events, [type |-&gt; \"monthpass\"]) /\\ UNCHANGED &lt;&lt;database&gt;&gt; (***************************************************************************) (* Specification *) (***************************************************************************) Init == /\\ events = &lt;&lt;&gt;&gt; \\* Events must be initialized empty, per stub /\\ month = 0 /\\ database = [ \\* Users start with everything unset users |-&gt; [u \\in USERS |-&gt; [ subscribed |-&gt; FALSE, inTrial |-&gt; FALSE, trialStartTime |-&gt; 0, billedForMonth |-&gt; 0 ] ], \\* Bill queue starts empty billQueue |-&gt; &lt;&lt;&gt;&gt; ] (* Next == \\* Required by stub \\/ MonthPasses \\* State modified below \\/ \\E u \\in USERS: \\/ StartSubscription(u) \\/ CancelSubscription(u) \\/ StartTrial(u) \\/ CancelTrial(u) \\/ WatchVideo(u) \\* Add more user based states \\* Payment failing behavior is part of spec not implementation \\/ ExistingBillFailed \\/ BillSubscribedUsers *) ============================================================================= \\* Modification History \\* Last modified Sun Jun 19 17:39:21 MST 2022 by elliotswart \\* Created Fri Jun 17 00:43:20 MST 2022 by elliotswart . Verification . Your solution does not hold up under test. | Next Section | Download Configuration | . Invariant StartSubscriptionAccessControl is violated. | 1. Initial predicate . | database . | users . | u1: {\"subscribed\"=&gt;false, \"inTrial\"=&gt;false, \"trialStartTime\"=&gt;0, \"billedForMonth\"=&gt;0} | . | billQueue : | . | events : | month : 0 | . | 2. StartTrial A trial starts, but user can still subscribe. | database . | users . | u1: {\"subscribed\"=&gt;false, \"inTrial\"=&gt;true, \"trialStartTime\"=&gt;0, \"billedForMonth\"=&gt;0} | . | billQueue : | . | events . | . | user : u1 | type : starttrial | . | . | month : 0 | . | 3. MonthPasses A month passes, converting trial into a full subscription. Now you shouldn't be able to start a subscription, but you still can. | database . | users . | u1: {\"subscribed\"=&gt;false, \"inTrial\"=&gt;true, \"trialStartTime\"=&gt;0, \"billedForMonth\"=&gt;0} | . | billQueue : | . | events . | . | user : u1 | type : starttrial | . | . | type : monthpass | . | . | month : 1 | . | . There are basic logical errors that need to be fixed. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/junior-dev/#the-first-attempt",
    "relUrl": "/business-logic/junior-dev/#the-first-attempt"
  },"88": {
    "doc": "Junior Developer tries their best",
    "title": "The second attempt",
    "content": "Modeling . For this next attempt you work through all the standard logical errors around access control. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ------------------------------ MODULE juniorv2 ------------------------------ (***************************************************************************) (* Database Rows *) (***************************************************************************) UserRow == [ subscribed: BOOLEAN, \\* Forget canceled inTrial: BOOLEAN, trialStartTime: Nat, billedForMonth: Nat, hasHadTrialOrSubscription: BOOLEAN, hasCancelled: BOOLEAN, cancelMonth: Nat ] StartSubscription(u) == \\* Not subscribed /\\ /\\ database.users[u].subscribed = FALSE /\\ \\/ database.users[u].inTrial = FALSE \\/ database.users[u].trialStartTime = month /\\ database' = [database EXCEPT ![\"users\"][u].subscribed = TRUE, ![\"users\"][u].hasHadTrialOrSubscription = TRUE, ![\"users\"][u].hasCancelled = FALSE ] \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"startsubscription\", user |-&gt; u]) /\\ UNCHANGED month CancelSubscription(u) == \\* Subscribed /\\ \\/ database.users[u].subscribed = TRUE \\/ /\\ database.users[u].inTrial = TRUE /\\ database.users[u].trialStartTime &lt; month /\\ database' = [database EXCEPT ![\"users\"][u].subscribed = FALSE, ![\"users\"][u].inTrial = FALSE, ![\"users\"][u].hasCancelled = TRUE, ![\"users\"][u].cancelMonth = month, \\* Charge cancellation fee ![\"billQueue\"] = Append(database.billQueue, [user |-&gt; u, fee |-&gt; CancellationFee]) ] \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"cancelsubscription\", user |-&gt; u]) /\\ UNCHANGED &lt;&lt;month&gt;&gt; StartTrial(u) == /\\ database.users[u].inTrial = FALSE /\\ database.users[u].subscribed = FALSE /\\ database.users[u].hasHadTrialOrSubscription = FALSE /\\ database' = [database EXCEPT ![\"users\"][u].inTrial = TRUE, ![\"users\"][u].trialStartTime = month, ![\"users\"][u].hasHadTrialOrSubscription = TRUE ] \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"starttrial\", user |-&gt; u]) /\\ UNCHANGED &lt;&lt;month&gt;&gt; CancelTrial(u) == \\* In active trial /\\ database.users[u].inTrial = TRUE /\\ database.users[u].trialStartTime = month \\* And not subscribed /\\ database.users[u].subscribed = FALSE /\\ database' = [database EXCEPT ![\"users\"][u].inTrial = FALSE ] \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"canceltrial\", user |-&gt; u]) /\\ UNCHANGED &lt;&lt;month&gt;&gt; WatchVideo(u) == /\\ \\/ database.users[u].subscribed = TRUE \\/ database.users[u].inTrial = TRUE \\* Remove video access at the end of canceled month \\/ /\\ database.users[u].hasCancelled = TRUE /\\ database.users[u].cancelMonth = month \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"watchvideo\", user |-&gt; u]) /\\ UNCHANGED &lt;&lt;month, database&gt;&gt; (***************************************************************************) (* Recurring Operations *) (***************************************************************************) BillSubscribedUsers == /\\ \\E u \\in USERS: \\* That is subscribed /\\ \\/ database.users[u].subscribed = TRUE \\* Subscribed from a trial so bill \\/ /\\ database.users[u].inTrial = TRUE /\\ database.users[u].trialStartTime &lt; month \\* Ensure users are not double billed /\\ database.users[u].billedForMonth &lt; month /\\ database' = [database EXCEPT \\* Add subscription fee ![\"billQueue\"] = Append(database.billQueue, [user |-&gt; u, fee |-&gt; SubscriptionFee]), ![\"users\"][u].billedForMonth = month ] /\\ UNCHANGED &lt;&lt;events, month&gt;&gt; ============================================================================= \\* Modification History \\* Last modified Sun Jun 19 17:44:01 MST 2022 by elliotswart \\* Created Sun Jun 19 16:56:29 MST 2022 by elliotswart . Verification . You test again, running into a billing issue. | Next Section | Download Configuration | . Invariant SubscribedUsersBilledStartOfMonth is violated. | 1. Initial predicate . | database . | users . | u1: {\"subscribed\"=&gt;false, \"inTrial\"=&gt;false, \"trialStartTime\"=&gt;0, \"billedForMonth\"=&gt;0, \"hasHadTrialOrSubscription\"=&gt;false, \"hasCancelled\"=&gt;false, \"cancelMonth\"=&gt;0} | . | billQueue : | . | events : | month : 0 | . | 2. StartSubscription Subscription states. | database . | users . | u1: {\"subscribed\"=&gt;true, \"inTrial\"=&gt;false, \"trialStartTime\"=&gt;0, \"billedForMonth\"=&gt;0, \"hasHadTrialOrSubscription\"=&gt;true, \"hasCancelled\"=&gt;false, \"cancelMonth\"=&gt;0} | . | billQueue : | . | events . | . | user : u1 | type : startsubscription | . | . | month : 0 | . | 3. MonthPasses Month passes, and you assume user should be billed. | database . | users . | u1: {\"subscribed\"=&gt;true, \"inTrial\"=&gt;false, \"trialStartTime\"=&gt;0, \"billedForMonth\"=&gt;0, \"hasHadTrialOrSubscription\"=&gt;true, \"hasCancelled\"=&gt;false, \"cancelMonth\"=&gt;0} | . | billQueue : | . | events . | . | user : u1 | type : startsubscription | . | . | type : monthpass | . | . | month : 1 | . | 4. CancelSubscription User cancels subscription before monthly billing could take place. | database . | users . | u1: {\"subscribed\"=&gt;false, \"inTrial\"=&gt;false, \"trialStartTime\"=&gt;0, \"billedForMonth\"=&gt;0, \"hasHadTrialOrSubscription\"=&gt;true, \"hasCancelled\"=&gt;true, \"cancelMonth\"=&gt;1} | . | billQueue . | : {\"user\"=&gt;\"u1\", \"fee\"=&gt;\"CancellationFee\"} | . | . | events . | . | user : u1 | type : startsubscription | . | . | type : monthpass | . | . | user : u1 | type : cancelsubscription | . | . | month : 1 | . | 5. ProcessBills User is not billed. | database . | users . | u1: {\"subscribed\"=&gt;false, \"inTrial\"=&gt;false, \"trialStartTime\"=&gt;0, \"billedForMonth\"=&gt;0, \"hasHadTrialOrSubscription\"=&gt;true, \"hasCancelled\"=&gt;true, \"cancelMonth\"=&gt;1} | . | billQueue : | . | events . | . | user : u1 | type : startsubscription | . | . | type : monthpass | . | . | user : u1 | type : cancelsubscription | . | . | user : u1 | fee : CancellationFee | type : bill | . | . | month : 1 | . | 6. MonthPasses A month passes, and our system hasn't billed. Out of compliance. | database . | users . | u1: {\"subscribed\"=&gt;false, \"inTrial\"=&gt;false, \"trialStartTime\"=&gt;0, \"billedForMonth\"=&gt;0, \"hasHadTrialOrSubscription\"=&gt;true, \"hasCancelled\"=&gt;true, \"cancelMonth\"=&gt;1} | . | billQueue : | . | events . | . | user : u1 | type : startsubscription | . | . | type : monthpass | . | . | user : u1 | type : cancelsubscription | . | . | user : u1 | fee : CancellationFee | type : bill | . | . | type : monthpass | . | . | month : 2 | . | . This is a much more complex business logic error, and it’s of the sort that conventional testing may not catch. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/junior-dev/#the-second-attempt",
    "relUrl": "/business-logic/junior-dev/#the-second-attempt"
  },"89": {
    "doc": "Junior Developer tries their best",
    "title": "The working attempt",
    "content": "Modeling . In the final attempt there you add significantly more billing logic. | Next Section | Download Code | Download PDF | . Show Code Show LaTex ------------------------------ MODULE juniorv3 ------------------------------ (***************************************************************************) (* Database Rows *) (***************************************************************************) UserRow == [ subscribed: BOOLEAN, \\* Forget canceled inTrial: BOOLEAN, trialStartTime: Nat, billedForMonth: Nat, hasHadTrialOrSubscription: BOOLEAN, hasCancelled: BOOLEAN, cancelMonth: Nat, subscribeMonth: Nat ] (***************************************************************************) (* API endpoints *) (***************************************************************************) StartSubscription(u) == \\* Not subscribed /\\ /\\ database.users[u].subscribed = FALSE /\\ \\/ database.users[u].inTrial = FALSE \\/ database.users[u].trialStartTime = month /\\ database' = [database EXCEPT ![\"users\"][u].subscribed = TRUE, ![\"users\"][u].hasHadTrialOrSubscription = TRUE, ![\"users\"][u].hasCancelled = FALSE, ![\"users\"][u].inTrial = FALSE, ![\"users\"][u].subscribeMonth = month, ![\"billQueue\"] = Append(database.billQueue, [user |-&gt; u, fee |-&gt; SubscriptionFee, when |-&gt; month]) ] \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"startsubscription\", user |-&gt; u]) /\\ UNCHANGED month CancelSubscription(u) == LET updatedBillQueue == IF \\E i \\in 1..Len(database.billQueue): /\\ database.billQueue[i].user = u /\\ database.billQueue[i].fee = SubscriptionFee THEN database.billQueue ELSE Append(database.billQueue, [user |-&gt; u, fee |-&gt; SubscriptionFee, when |-&gt; month]) IN \\* Subscribed /\\ \\/ database.users[u].subscribed = TRUE \\/ /\\ database.users[u].inTrial = TRUE /\\ database.users[u].trialStartTime &lt; month /\\ database' = [database EXCEPT ![\"users\"][u].subscribed = FALSE, ![\"users\"][u].inTrial = FALSE, ![\"users\"][u].hasCancelled = TRUE, ![\"users\"][u].cancelMonth = month, \\* Charge cancellation fee ![\"billQueue\"] = Append(updatedBillQueue, [user |-&gt; u, fee |-&gt; CancellationFee, when |-&gt; month + 1]) ] \\* Observability required by stub /\\ events' = Append(events, [type |-&gt; \"cancelsubscription\", user |-&gt; u]) /\\ UNCHANGED &lt;&lt;month&gt;&gt; (***************************************************************************) (* Recurring Operations *) (***************************************************************************) BillSubscribedUsers == /\\ \\E u \\in USERS: \\* That is subscribed /\\ \\/ database.users[u].subscribed = TRUE \\* Subscribed from a trial so bill \\/ /\\ database.users[u].inTrial = TRUE /\\ database.users[u].trialStartTime &lt; month \\* Ensure users are not double billed /\\ database.users[u].billedForMonth &lt; month /\\ database' = [database EXCEPT \\* Add subscription fee ![\"billQueue\"] = Append(database.billQueue, [user |-&gt; u, fee |-&gt; SubscriptionFee, when |-&gt; month]), ![\"users\"][u].billedForMonth = month ] /\\ UNCHANGED &lt;&lt;events, month&gt;&gt; ProcessBills == /\\ Len(database.billQueue) &gt; 0 /\\ \\E i \\in 1..Len(database.billQueue): LET bill == database.billQueue[i] IN /\\ bill.when = month \\* Charge cancellation fees only a month after canceled \\* and still canceled /\\ \\/ bill.fee # CancellationFee \\/ /\\ bill.fee = CancellationFee /\\ \\/ database.users[bill.user].subscribed = FALSE \\* Subscribed too late to cancel cancellation fee \\/database.users[bill.user].subscribeMonth &gt;= bill.when /\\ Bill(bill.user, bill.fee) /\\ database' = [database EXCEPT \\* Removes head of queue ![\"billQueue\"] = SubSeq(database.billQueue, 1, i-1) \\o SubSeq(database.billQueue, i+1, Len(database.billQueue)) ] /\\ UNCHANGED &lt;&lt;month&gt;&gt; ============================================================================= \\* Modification History \\* Last modified Sun Jun 19 17:55:27 MST 2022 by elliotswart \\* Created Sun Jun 19 16:56:29 MST 2022 by elliotswart . The code is starting to look like a nightmare, but hopefully it will work. Verification . Testing it leads to success! . | Next Section | Download Configuration | . | State Name | Total States | Distinct States | . | All States | 772157 | 153504 | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/junior-dev/#the-working-attempt",
    "relUrl": "/business-logic/junior-dev/#the-working-attempt"
  },"90": {
    "doc": "Junior Developer tries their best",
    "title": "Next steps",
    "content": "So you’ve gotten a solution working, but frankly, it looks like it’ll be a nightmare to implement. Nested if statements all over the place. The database schema is sloppy. It’s time to ask for help. Note: A valid criticism of the above would be that no one would model business logic like that. And it’s true, no one would model something that badly. But people push solutions much worse than this one to production every day. Maybe if they took the time to model, they wouldn’t. | Next: Principal Engineer saves the day | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/junior-dev/#next-steps",
    "relUrl": "/business-logic/junior-dev/#next-steps"
  },"91": {
    "doc": "Business Logic",
    "title": "Business Logic",
    "content": ". | Introduction | The scenario | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/",
    "relUrl": "/business-logic/"
  },"92": {
    "doc": "Business Logic",
    "title": "Introduction",
    "content": "We’ve previously used TLA+ mostly for distributed systems problems, but you can also used it to model business logic. First we’ll go from requirements to a mathematical specification. Then we’ll show two implementations of the specification that lead to the satisfaction of the scenario requirements. Those implementations will be the model for the business logic code to be developed. We’ll demonstrate how formal specifications can be used to perform tests of implementations, as well as high confidence refactors. ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/#introduction",
    "relUrl": "/business-logic/#introduction"
  },"93": {
    "doc": "Business Logic",
    "title": "The scenario",
    "content": "A software design/consulting firm has been contracted to build a website that allows users to watch instructional workout videos online. Let’s say it’s called MuscleMovies.com. It was founded by former gym and magazine executives, so they have lots of ideas on how to maximize their profits (or gains, if you will). We’re talking trial memberships that convert into paid memberships, payment processing and cancellation penalties! . In the following pages, we’ll get to be three different people: . | The Enterprise Architect: who distills the requirements into standard form, makes the architectural choices and writes the formal interface specification. | The Junior Developer: who is dropped into this project and struggles through the requirements piece by piece. | The Principal Engineer: who jumps in and saves the day by reimplementing the requirements in a cleaner fashion. | . It’s basically Rashomon, but presented clearly and in chronological order. And with higher stakes, at least according to the MuscleMovies.com CEO. Don’t worry: despite the tone, we’re going rigorous with requirements. | Next: Enterprise Architect gets us started | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/business-logic/#the-scenario",
    "relUrl": "/business-logic/#the-scenario"
  },"94": {
    "doc": "Tools and Additional Citations",
    "title": "Tools and Additional Citations",
    "content": " ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/tools/",
    "relUrl": "/tools/"
  },"95": {
    "doc": "Tools and Additional Citations",
    "title": "Tools for TLA+",
    "content": ". | TLA+ Toolbox: The fully featured (if somewhat outdated) IDE for TLA+. Includes modeling, document generation, and live syntax checking. | VSCode TLA+: Lighter weight IDE with textfile based model configuration. Generally more responsive. The latest alpha version, found here, has a debugger that might be useful to you while getting a handle on the language. | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/tools/#tools-for-tla",
    "relUrl": "/tools/#tools-for-tla"
  },"96": {
    "doc": "Tools and Additional Citations",
    "title": "Tools for TLA+ display",
    "content": ". | tla2json: Used to turn trace output from toolbox into json for automatic trace widget generation. | LaTex: Used to render the LaTex output of TLA+ to dvi format. | dvisvgm: Used to convert the dvi formatted TLA+ specifications into SVGs that could be displayed inline in the website. | Code highlighting: Improved / repackaged for Jekyll, but the majority of the code came from this pull request by Tom Lee. | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/tools/#tools-for-tla-display",
    "relUrl": "/tools/#tools-for-tla-display"
  },"97": {
    "doc": "Tools and Additional Citations",
    "title": "Tools for the website",
    "content": ". | Jekyll: A static site generator. This website heavily relied on the templating functionality Jekyll provides. | PlantUML: Used to generate UML diagrams from text. | Kramdown::PlantUml: Allows rendering it in Jekyll. | . | Just the Docs: The theme that was used and modified for this website. | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/tools/#tools-for-the-website",
    "relUrl": "/tools/#tools-for-the-website"
  },"98": {
    "doc": "Tools and Additional Citations",
    "title": "Assets",
    "content": ". | Favicon: Diamond icons created by Vaadin - Flaticon. | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/tools/#assets",
    "relUrl": "/tools/#assets"
  },"99": {
    "doc": "Tools and Additional Citations",
    "title": "Acknowledgments",
    "content": ". | To Liza Knipscher for editing and proofreading tons of text and code. | To all the people who wrote the learning material and the tools above, your work was invaluable to the completion of this project. | . ",
    "url": "https://elliotswart.github.io/pragmaticformalmodeling/tools/#acknowledgments",
    "relUrl": "/tools/#acknowledgments"
  }
}
